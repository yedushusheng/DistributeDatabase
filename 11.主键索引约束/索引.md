# 索引

## 背景

我们知道，数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。最基本的查询算法当然是顺序查找（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如二分查找（binary search）、二叉树查找（binary tree search）等。如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上，例如二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。

## 定义

MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。

​	索引是帮助MySQL高效获取数据的**排好序**的数据结构，用于快速找出某个列中有一***\*特定值\****的行。

***\*实际上，一个表的存储是由两部分组成的，一部分用来存放表的数据页面，另一部分存放索引页面，索引就存放在索引页面上\****。通常，索引页面相对于数据页面来说小得多。当进行数据检索时，系统先搜索索引页面，从中找到所需数据的指针，再通过指针从数据页面中读取数据。

​	索引保存的数据：索引列的值，指向数据行的指针

索引与排序，排序可能发生两种情况：

1、对于覆盖索引，直接在索引上查询时，就是有顺序的Using index；

2、先取出数据，形成临时表做filesort（文件排序，文件可能在磁盘也可能在内存）。

我们的目标，就是取出来的数据就是有序的。

 

​	不使用索引，MySQL必须从第一条记录开始读完整个表，直到找到相关的行，表越大，查询数据所花费的时间就越多（全表扫描）。

​	如果表中查询的列有一个索引，MySQL能够快速到达一个表搜索数据文件，而不必查看所有数据，那么将会节省很大一部分时间。

 

​	***\*重复索引：\****是指在同一个列或者顺序相同的几个列建立了多个索引，称为重复索引。重复索引没有任何帮助，只会增大索引文件，拖慢查询速度，应该去掉。

​	***\*冗余索引\*******\*：\****是指两个索引所覆盖的列有重叠，称为冗余索引。

## 最左前缀原则**/ABC问题

​	***\*即便表建立了索引，where查询语句中存在索引，也不一定走索引\****，是不是走索引遵循最左前缀原则：

​	**索引对应的数据结构B+树生成的时候就是按照最左的字段排序生成的**，如果不指明该字段的取值，那么就无法确定走索引B+树的左还是右，进而只能全表扫描。

​	注：对于索引a,b,c，where查询语句b=1,c=2;或a like ‘%s’,b=1,c=2这是不走索引的，因为此时也不知道走B+树的左侧还是右侧。

 

***\*不需要考虑=、in等的顺序，mysql会自动优化这些条件的顺序，以匹配尽可能多的索引列。\****

## 索引覆盖

​	索引覆盖是指，如果查询的列恰好是索引的一部分，那么查询只需要在索引文件上进行，不需要回行到磁盘再找数据（即***\*避免回表操作\****），这种***\*查询速度非常快\****，称为“索引覆盖”。

 

覆盖索引是一个非常有用的工具，可以极大提升性能。试想一下，如果一个查询只需要扫描索引而无需二次回表查询，会带来什么好处：

1、索引行通常远小于数据行的大小，所以如果只需要索引，那么MySQL就会极大地减少数据访问量。

2、因为索引是按照顺序存储的，所以对于I/O密集型的范围查询会比随机从磁盘读取每一行数据的I/O要少的多。

3、由于InnoDB的聚簇索引，所以覆盖索引对InnoDB特别有用。

当发起一个覆盖查询的时候，在Explain中的Extra列中可以看到“Using index”的信息。让我们回到select*这个问题上：没有任何一个索引能够覆盖所有列，所以select*可能会导致原本可以用到覆盖索引的查询而无法使用覆盖索引。

 

## 优/劣势

### 优势	

类似大学图书馆建书目索引，提高数据检索效率，**降低数据库的IO成本**。

通过索引对数据进行排序，降低数据排序的成本，**降低了CPU的消耗**。

### 劣势

实际上索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录，所以索引也是要占空间的（**空间换时间**）。

虽然索引大大提高了查询速度，同时会**降低更新表的速度**，如对表进行INSERT、UPDATE、DELETE操作（因为除了需要更新正常数据外还需要维护索引信息）。

## 隐式索引

隐式索引由数据库服务器在创建某些对象的时候自动生成。例如，对于主键约束和唯一约束，数据库服务器就会自动创建索引。

之所以会存在隐式索引，是因为数据库总是优先考虑使用索引的这种情况，除非索引失效，但是前提是需要有字段建立索引，如果用户不手动显式指定索引字段，那么数据库就自动添加一个。一切都是为了尽可能的将能优化的情况都考虑到。

***\*8.0新特性\****

### 隐藏索引/不可见索引

### 反向/倒序索引

### 函数索引

参考：

https://www.cnblogs.com/gjc592/p/13233377.html

 

#### 概述

#### 特点

#### 操作

#### 优化

 

***\*应用场景\****

***\*需要创建索引\****

​	1、主键自动创建唯一索引

​	2、频繁作为where查询条件的字段应该创建索引

​	3、查询中与其他表关联的字段，外键关系建立索引

​	4、查询中排序的字段（order by），排序的字段若通过索引区访问将大大提高排序速度

​	5、查询中统计或者分组字段（group by）

​	注：order by/group by是先做排序再分组，因此可以建索引

***\*不需要创建索引\****

​	1、频繁更新的字段不适合建立索引，因为每次更新不单单是更新了记录还会更新索引

​	2、WHERE条件里用不到的字段不创建索引

​	3***\*、\*******\*表记录太少\*******\*，\*******\*即小的数据表不应当使用索引\****

​	4、***\*经常增删改的表\****

​	5、如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果

​	6、数据值分布比较均匀的不适合建索引，比如性别

7、***\*如果列中包含大数或者NULL值，不宜创建索引\****

 

# 分类

## 索引字段类型

### 主键索引**/聚簇索引

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4DE8.tmp.jpg) 

​	注：对于这种主键索引，如果叶子节点从左到右遍历，就是全表扫描。如果表中建立了其他索引，也可能走索引也可能全表扫描。

 

聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。聚簇索引总是把数据行存储在叶子页中，因此一个表中只能有一个聚簇索引。

并不是所有的存储引擎都支持聚簇索引，这里我们主要讨论InnoDB。***\*在InnoDB中，聚簇索引其实就是主键索引\****。如果表中没有定义主键，InnoDB会选择一个唯一的非空索引作为主键；如果没有这样的索引，InnoDB会隐式的定义一个主键来作为聚簇索引。聚簇索引的优点如下：

1、可以把相关数据保存在一起；

2、数据访问更快；

3、使用覆盖索引扫描的查询可以直接使用页节点中的主键值。

如果表在设计和查询的时候能充分利用以上特点，将会极大提高性能。当然，聚簇索引也有它的缺点：

1、聚簇索引最大限度提高了I/O密集型应用的性能，但如果所有的数据都存放在内存中，聚簇索引就没有优势了。

2、插入速度严重依赖插入顺序。这也是为什么InnoDB一般都会设置一个自增的int列作为主键。

3、更新聚簇索引的代价很高，因为会强制InnoDB将每个被更新的行移到新的位置。

4、如果不按顺序插入新数据时，可能会导致“页分裂”。

5、二级索引可能会比想象的更大。因为在二级索引的叶子节点中包含了引用行的主键列。

6、二级索引访问可能会需要进行回表查询。

### 唯一索引

​	索引列的值必须唯一，但允许有空值。

​	UNIQUE就是唯一索引，即要求每一行的数据必须唯一，但可以为空。

### 普通索引/二级索引/辅助索引

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4DE9.tmp.jpg) 

​	注：上述红色部分存储的是索引字段b，c，d，下面黄色的部分是主键。这里之所以不是存储整个行所有的字段，是因为我们的***\*主键会默认创建索引\****，而且***\*其叶子节点已经冗余了该记录的所有字段值，所以我们建立的普通索引只需要在叶子节点冗余一个主键值，然后通过这个主键值快速找到对应的主键索引的叶子节点即可\****，这样可以减少数据的冗余。

InnoDB 中的辅助索引在叶子节点中并不存储实际的数据，只会包含主索引的值。这就意味着***\*如果使用辅助索引进行数据的查找，只能查到主索引，然后根据这个主索引再次扫描以下主索引的树，进行一次回表操作\*******\*。\****

​	这种索引也可以叫***\*二级索引\****或者***\*辅助索引\****。

 

​	**注：**即便是建立索引，但是explain的时候也不一定走索引，可能会全表扫描，比如select * from tb where b>1（b为普通索引），这里就是从最左侧开始顺序打印所有字段，这时候explain中会显示possible key，即可能走的索引，但实际是全表扫描ALL，因为InnoDB会做优化。***\*因为如果采用普通索引，需要查找到每个叶子节点对应的主键叶子节点，然后取值，这样就需要回表操作，即获取左侧4个叶子节点的主键叶子节点，这样IO性能差，还不如直接全表扫描。但是对于\*******\*b>5\*******\*这种情况就可以走索引了\****。

​	对于select b from tb（b为普通索引）；这种SQL貌似不会走索引，但是实际是走索引的，具体分析：对于主键索引而言，叶子节点存储所有数据，占空间较大，因此数据的页很多，数据查找慢，而对于普通索引而言，叶子节点存储一部分数据，这样页非常少，查找较少的页就可以定位数据（前提是查询字段在叶子节点上，即查询字段为索引）。

 

***\*SELECT(\*)/SELECT(1)\****

对于SQL：

SELECT COUNT(*) FROM tb;

SELECT COUNT(1) FROM tb;

会造成全表扫描，但是这种说法是有问题的，实际上针对无where_clause的 COUNT(*)，MySQL是有优化的，优化器会选择成本最小的辅助索引查询计数，其实反而性能最高。

找一个大表explain查看：

EXPLAIN SELECT COUNT(*) FROM tb;

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4DEA.tmp.jpg) 

发现确实此条语句在此例中用到的并不是主键索引，而是辅助索引，不管是COUNT(1)，还是COUNT(*)，MySQL都会用成本最小的辅助索引查询方式来计数，也就是使用COUNT(*) 由于MySQL的优化已经保证了它的查询性能是最好的！随带提一句，COUNT(*)是SQL92定义的标准统计行数的语法，并且效率高，所以请直接使用COUNT(*)查询表的行数！

但有个前提，在MySQL 5.6之后的版本中才有这种优化。

 

### 全文索引

​	全文索引只有在MyISAM索引上才能使用，只能在CHAR、VARCHAR、TEXT类型字段上使用全文索引。

### 空间索引

​	空间索引是对空间数据类型的字段建立的索引。

 

按照索引的个数可以划分：

## 索引字段个数

### 单值索引

​	单值索引即一个索引只包含单个列，一个表可以有多个单列索引。

### 复合/联合索引

​	一个索引包含多个列。

​	例如：INDEX Multidx(id,name.age)

创建单列索引还是复合索引，要看每次查询中，哪些列在作为过滤条件的WHERE子句中最常出现。

如果只需要一列，那么就应当创建单列索引。如果作为过滤条件的WHERE子句用到了两个或者更多的列，那么复合索引就是最好的选择。

 

​	除了上述分类方法，还可以分为聚集索引和非聚集索引：

## 存储结构

从存储结构上来划分：BTree索引（B-Tree或B+Tree索引），Hash索引，full-index全文索引，R-Tree索引。

### B Tree索引

MongoDB采用B Tree作为索引数据结构。

### B+ Tree索引

### T树索引

### R-Tree索引

### Hash索引

### Bitmap

### LSM索引

OceanBase、TiDB采用LSM作为索引数据结构。

### full-index全文索引

### k-d tree

### Point Quadtree

参考：https://www.cnblogs.com/liuning8023/archive/2012/11/15/2728536.html

## 索引和数据存储形式

### 聚集索引**/主键索引

#### 概述

簇索引对表的物理数据页中的数据按列进行排序，然后再重新存储到磁盘上，即簇索引与数据是混为一体的，它的叶节点中存储的是实际的数据。

簇索引对表中的数据一一进行了排序，因此用簇索引查找数据很快。但由于簇索引将表的所有数据完全重新排列了，所需要的空间也就特别大，大概相当于表中数据所占空间的120%。

 

聚集索引就是以主键创建的索引。

​	***\*索引和数据\****在一个文件存储（相当于字典的页码）。

单索引是聚集索引。

 

***\*InnoDB只有一个聚集索引\*******\*（表的数据行只能以一种排序方式存储在磁盘上，所以一个表只能有一个簇索引。）\****：

1、 默认会拿主键id作为聚集索引；

2、 如果没有主键，会取非空的唯一索引作为聚集索引；

**3、** ***\*如果没有主键和非空唯一索引，则InnoDB会自己维护一个唯一row\*******\*_\*******\*id作为聚集索引\****。

​	注：**MyISAM是非聚集索引（MYI和MYD），InnoDB是聚集索引**。

​	**My****ISAM****（不论是主索引还是次索引）索引指向磁盘的物理行。InnoDB主索引叶子节点下面直接放置该行数据，称为聚集索引，次索引指向主键的引用**。

​	

​	对于聚集索引，如果是查询主键，则直接可以找到数据，如果是其他字段，则需要经过一步查找主键，然后获取行数据的过程。

#### 特点

​	***\*如果插入新的索引值，叶子节点会分裂，对于InnoDB聚簇索引影响比较严重\****，节点下存储了行数据，分裂的时候，除了移动索引还需要移动行数据（所以对于InnoDB的主键尽量使用有规律递增的整型，如果是无规律的整型将会产生页的分裂，影响速度）；对于MyISAM非聚簇索引，节点存储的是物理行地址，内容较小，又缓存在内存里，分裂速度很快，影响较小。

 

与非簇索引不同，簇索引改变了表中数据存放的物理位置。在带有簇索引的表中，行是以索引顺序存放的。簇索引不仅对索引中的键字值进行排序，而且对表中的行排序，以便使其与索引的排序相匹配。使用簇集索引主要有三点优势。

• 使用簇集索引的表将占用最小的磁盘空间。因为DBMS在插入新行时，会自动地重用以前分配给删除行的空间。

• 对基于簇集索引的列值进行查询时，会有更快的执行速度，因为所有值在物理磁盘上相互靠近。

• 基于簇集索引的列以升序显示数据查询，不再需要ORDER BY子句，因为表的数据本身已经按所要求的输出顺序排列。当检索带有连续键值的多行时，如查询姓王的所有学生时，簇索引就显示出很多优势。一旦找到了第一个键值，后续索引值的行必定物理地排在后面，这样就无需进一步访问磁盘了。

 

#### 故障分析

 

### 非聚集索引**/二级索引

#### 概述

非簇索引具有与表的数据完全分离的结构，使用非簇索引不必将物理数据页中的数据按列排序。非簇索引的叶节点中存储了关键字的值和行定位器。行定位器的结构和存储内容取决于数据的存储方式。如果数据是以簇索引方式存储的，则行定位器中存储的是簇索引的索引键；如果数据不是以簇索引方式存储的，则行定位器存储的是指向数据行的指针，这种方式又称为堆存储方式（HeapStructure）。非簇索引将行定位器按关键字进行排序，这个顺序与表的行在数据页中的排序是不匹配的。

由于非簇索引使用索引页存储，比簇索引需要更多的存储空间，且检索效率较低。但一个表只能建一个簇索引，当用户需要建立多个索引时，就需要使用非簇索引了。从理论上讲，一个表最多可以建249个非簇索引。

 

​	非聚集索引就是以非主键创建的索引。

索引和数据存储在不同文件（相当于字典的目录）。MyISAM使用的是非聚集索引。

联合索引是非聚集索引。

#### 联合索引

非聚集索引在建立的时候也未必是单列的，可以多个列来创建索引。

此时就涉及到了哪个列会走索引，哪个列不走索引的问题了(最左匹配原则)

创建多个单列(非聚集)索引的时候，会生成多个索引树(所以过多创建索引会占用磁盘空间)

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4DEB.tmp.jpg) 

#### 覆盖索引

在创建多列索引中也涉及到了一种特殊的索引：覆盖索引

如果不是聚集索引，叶子节点存储的是主键+列值，最终还是要“回表”，也就是要通过主键再查找一次，这样就会比较慢。

覆盖索引就是把要查询出的列和索引是对应的，不做回表操作！

比如说：

现在我创建了索引 (username,age)，在查询数据的时候：

Select username,age from user where username='Java3y' and age=20。

很明显地知道，我们上边的查询是走索引的，并且，要查询出的列在叶子节点都存在！所以，就不用回表了。

所以，能使用覆盖索引就尽量使用。

### *区别*

1、聚集索引在叶子节点存储的是表中的数据

2、非聚集索引在叶子节点存储的是主键和索引列

3、使用非聚集索引查询出数据时，拿到叶子上的主键再去查到想要查找的数据。(拿到主键再查找这个过程叫做回表)

## 部分/前缀索引

## 函数索引

## 条件索引

## 反向索引

## 位图索引

# 隐式索引

隐式索引由数据库服务器在创建某些对象的时候自动生成。例如，对于主键约束和唯一约束，数据库服务器就会自动创建索引。

# 前缀索引

参考：

https://www.jianshu.com/p/d3ef22b2469a

https://blog.csdn.net/u011424653/article/details/80151785

https://www.cnblogs.com/studyzy/p/4310653.html

https://www.cnblogs.com/balfish/p/9003794.html

## 概述

前缀索引说白了就是对文本的前几个字符（具体是几个字符在建立索引时指定）建立索引，这样建立起来的索引更小，所以查询更快。有点相当于Oracle中对字段使用Left函数，建立函数索引，只不过MySQL的这个前缀索引在查询时是内部自动完成匹配的，并不需要使用left函数。

## 特点

### 优点

MySQL 前缀索引能有效减小索引文件的大小，提高索引的速度。

### 缺点

但是前缀索引也有它的坏处：MySQL 不能在 ORDER BY 或 GROUP BY 中使用前缀索引，也不能把它们用作覆盖索引(Covering Index)。

## 操作

建立前缀索引的语法为：

ALTER TABLE table_name ADD KEY(column_name(prefix_length));

这里最关键的参数就是prefix_length，这个值需要根据实际表的内容，得到合适的索引选择性（Index Selectivity）。索引选择性就是不重复的个数与总个数的比值。

 

## 选择性

什么情况下使用前缀索引：

字符串列(varchar,char,text等)，需要进行全字段匹配或者前匹配。也就是=‘xxx’ 或者 like ‘xxx%'

字符串本身可能比较长，而且前几个字符就开始不相同。比如我们对中国人的姓名使用前缀索引就没啥意义，因为中国人名字都很短，另外对收件地址使用前缀索引也不是很实用，因为一方面收件地址一般都是以XX省开头，也就是说前几个字符都是差不多的，而且收件地址进行检索一般都是like ’%xxx%’，不会用到前匹配。相反对外国人的姓名可以使用前缀索引，因为其字符较长，而且前几个字符的选择性比较高。同样电子邮件也是一个可以使用前缀索引的字段。

前一半字符的索引选择性就已经接近于全字段的索引选择性。如果整个字段的长度为20，索引选择性为0.9，而我们对前10个字符建立前缀索引其选择性也只有0.5，那么我们需要继续加大前缀字符的长度，但是这个时候前缀索引的优势已经不明显，没有太大的建前缀索引的必要了。

# 索引操作

## 创建索引

​	CREATE INDEX 索引名称 ON table (column1,…);

​	例如：create index salary_index on employ(salary);

 

在不同的数据库管理系统中，创建索引语句有着不同形式的扩展。如在SQL Server中，CREATEINDEX语句创建索引可以有如下的形式。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4DFB.tmp.jpg) 

在Oracle中，CREATE INDEX语句创建索引可以有如下的形式。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4DFC.tmp.jpg) 

在Informix中，CREATE INDEX语句创建索引可以有如下的形式。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4DFD.tmp.jpg) 

用到的几个主要关键字含义如下。

• UNIQUE（DISTINCT）：惟一性索引，不允许表中不同的行在索引列上取相同值。若已有相同值存在，则系统给出相关信息，不建此索引。

• CLUSTERED/ NONCLUSTERED：聚集和非聚集索引，若为CLUSTERED，则为聚集索引，即表中元组按索引项的值排序，并聚集在一起。一个基本表上只能建一个聚集索引。NONCLUSTERED表示创建的索引为非聚集索引。缺省时，创建的索引为非聚集索引。• ASC/DESC：索引表中索引值的排序次序，缺省为ASC（正序排列）。

## 删除索引

​	DROP INDEX 索引名称 ON 表名;

## 查看索引

​	SHOW INDEX FROM 表名;

​	可以在show index查看索引的时候使用字段加速查看的速度：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E0E.tmp.jpg) 

各个字段含义：

Table：

表名。

Non_unique：

0：该索引不含重复值。

1：该索引可含有重复值。

Key_name：

索引名称，如果是注解索引，名称总是为PRIMARY。

Seq_in_index：

该列在索引中的序号，从 1 开始。例如：存在联合索引 idx_a_b_c (a,b,c)，则a的Seq_in_index=1，b=2，c=3。

Column_name：

列名。

Collation：

索引的排列顺序：A（ascending），D (descending)，NULL (not sorted)。

Cardinality：

一个衡量该索引的唯一程度的值，可以使用ANALYZE TABLE（INNODB） 或者 myisamchk -a（MyISAM）更新该值。

如果表记录太少，该字段的意义不大。一般情况下，该值越大，索引效率越高。

Sub_part：

对于前缀索引，用于索引的字符个数。如果整个字段都加上了索引，则显示为NULL。

Null：

YES：该列允许NULL值。

''：该列不允许NULL值。

Index_type：

索引类型，包括(BTREE, FULLTEXT, HASH, RTREE)。

 

## 自动创建索引

​	在表上定义了主键时，会自动创建一个对应的唯一索引。

​	没有定义主键时，表中如果定义唯一约束，会将唯一索引作为主键/索引。

​	没有定义主键和唯一约束时，InnoDB会为每行记录生成一个自增的rowid，生成B+树索引。

​	在表上定义了一个外键时，会自动创建一个普通索引。

​	说明：创建索引也会消耗时间，因此我们在创建表的时候先创建主键，即默认先创建一个索引。

## explain

​	用来查看索引是否正在被使用，并且输出其使用的索引的信息。

​	在未添加索引时：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E0F.tmp.jpg) 

​	在添加索引后：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E10.tmp.jpg) 

​	具体包含的参数：

id：SELECT标识符，这是SELECT的查询序列号，也就是一条语句中，该SELECT是第几次出现，在此语句中，SELECT就只有一个，所以是1。

​	selecy_type：所使用的SELECT查询类型，SIMPLE表示为简单的SELECT，不使用UNION或子查询，就为简单的SELECT。

​	table：数据表的名字，他们按照被读取的先后顺序排序。

​	type：指定本数据表和其他数据表之间的关联关系，该表中所有符合检索值的记录都会被取出来和上一个表中取出来的记录作联合。

​	key：实际选用的索引。

​	possible_keys：

​	key_len：显示了MySQL使用索引的长度（也就是使用索引的个数），当Key字段的值为NULL时，索引的长度就是NULL。

​	ref：

 

# 索引底层实现

​	参考网站：

https://www.cs.usfca.edu/~galles/visualization/Algorithms.html

## 页

### 数据页

首先Mysql的基本存储结构是页(记录都存在页里边)：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E11.tmp.jpg) 

1、各个数据页可以组成一个***\*双向链表\****

2、而每个数据页中的记录又可以组成一个***\*单向链表\****

1）每个数据页都会为存储在它里边儿的记录生成一个页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录

2）以其他列(非主键)作为搜索条件：只能从最小记录开始依次遍历单链表中的每条记录。

所以说，如果我们写 select * from user where username='Java3y'这样没有进行任何优化的sql语句，默认会这样做：

1、定位到记录所在的页

需要遍历双向链表，找到所在的页

2、从所在的页内中查找相应的记录

由于不是根据主键查询，只能遍历所在页的单链表了

很明显，在数据量很大的情况下这样查找会很慢！

 

### 页合并

### 页分裂

## 二叉树

​	如果用二叉树建立索引的数据结构，那么每个节点存储K-V，即索引字段和索引字段所在行的磁盘地址的指针，时间复杂度为O(logN)。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E22.tmp.jpg) 

​	但是，实际应用中数据库不使用二叉树作为索引的数据结构。例如对于col1作为索引，建立二叉树，则会生成非常不平衡的结构（实际上就是一个单边的链表，与逐行查找效率一样），影响查找效率：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E23.tmp.jpg) 

## 红黑树

​	为了应对极端不平衡的情况，尝试使用红黑树作为索引的数据结构。红黑树是二叉**平衡**树。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E24.tmp.jpg) 

​	红黑树不适合作为索引的特殊场景：***\*存储数据非常大的时候，树的高度h太大\****，查找的数据如果在叶子节点，极端的情况下需要查询高度h次才可以。

​	我们需要控制查找次数，即树的高度，而红黑树每个节点只存储一个K，则为了降低高度，可以在一个节点存储多个数据，从而可以将树的高度降低，**而B+树能够控制树的高度在3~****5**。

## B-Tree索引

### 概述

B树也称B-树，是一种多路搜索树（并不是二叉的）：

1、定义任意非叶子结点最多只有M个儿子；且M>2；

2、根结点的儿子数为[2, M]；

3、除根结点以外的非叶子结点的儿子数为[M/2, M]；

4、每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字）

5、非叶子结点的关键字个数=指向儿子的指针个数-1；

6、非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] < K[i+1]；

7、非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树；

8、所有叶子结点位于同一层；

 

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E34.tmp.jpg) 

B类树的一个很鲜明的特点就是树的层数比较少，而每层的节点都非常多，树的每个叶子节点到根节点的距离都是相同的（这也是为什么叫Balance Tree的原因）。

另外，树的每一个节点都是一个***\*数据页\****（B+树是叶子结点是数据页，其余全部为索引页），这样***\*每个节点只需要一次IO就可以全部读取\****。这样的结构保证了查询数据时能尽量少地进行磁盘IO，同时保证IO的稳定性。

 

### 插入

插入的时候，我们需要记住一个规则：判断当前结点key的个数是否小于等于m-1，如果满足，直接插入即可，如果不满足，将节点的中间的key将这个节点分为左右两部分，中间的节点放到父节点中即可。

例子：在5阶B树中，结点最多有4个key,最少有2个key（注意：下面的节点统一用一个节点表示key和value）。

插入18，70，50,40

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E35.tmp.jpg) 

插入22

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E36.tmp.jpg) 

插入22时，发现这个节点的关键字已经大于4了，所以需要进行分裂，分裂的规则在上面已经讲了，分裂之后，如下。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E37.tmp.jpg) 

 

接着插入23，25，39

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E48.tmp.jpg) 

分裂，得到下面的。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E49.tmp.jpg) 

 

### 删除

参考：https://mp.weixin.qq.com/s/f1ZYdmmngjb1bpGnYMCfzw

B树的删除操作相对于插入操作是相对复杂一些的，但是，你知道记住几种情况，一样可以很轻松的掌握的。

现在有一个初始状态是下面这样的B树，然后进行删除操作。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E4A.tmp.jpg) 

删除15，这种情况是删除叶子节点的元素，如果删除之后，节点数还是大于m/2，这种情况只要直接删除即可。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E4B.tmp.jpg) 

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E5C.tmp.jpg) 

接着，我们把22删除，这种情况的规则：22是非叶子节点，对于非叶子节点的删除，我们需要用后继key（元素）覆盖要删除的key，然后在后继key所在的子支中删除该后继key。对于删除22，需要将后继元素24移到被删除的22所在的节点。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E5D.tmp.jpg) 

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E5E.tmp.jpg) 

此时发现26所在的节点只有一个元素，小于2个（m/2），这个节点不符合要求，这时候的规则（向兄弟节点借元素）：如果删除叶子节点，如果删除元素后元素个数少于（m/2），并且它的兄弟节点的元素大于（m/2），也就是说兄弟节点的元素比最少值m/2还多，将先将父节点的元素移到该节点，然后将兄弟节点的元素再移动到父节点。这样就满足要求了。

我们看看操作过程就更加明白了。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E5F.tmp.jpg) 

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E6F.tmp.jpg) 

接着删除28，删除叶子节点，删除后不满足要求，所以，我们需要考虑向兄弟节点借元素，但是，兄弟节点也没有多的节点（2个），借不了，怎么办呢？如果遇到这种情况，首先，还是将先将父节点的元素移到该节点，然后，将当前节点及它的兄弟节点中的key合并，形成一个新的节点。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E70.tmp.jpg) 

移动之后，跟兄弟节点合并。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E71.tmp.jpg) 

删除就只有上面的几种情况，根据不同的情况进行删除即可。

 

由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质。

 

### 搜索过程

由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。

***\*B树结构如下：\****

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E72.tmp.jpg) 

模拟查找关键字29的过程：

1、根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】

2、比较关键字29在区间（17,35），找到磁盘块1的指针P2。

3、根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】

4、比较关键字29在区间（26,30），找到磁盘块3的指针P2。

5、根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】

6、在磁盘块8中的关键字列表中找到关键字29。

分析上面过程，发现需要3次磁盘I/O操作，和3次内存。

但如果我们想进行范围查找，查询10~79之间的数据，就需要从跟节点一个一个往下查，范围跨度越大，则磁盘IO的次数就越多，性能越差。因此在BTree的基础上就有了B+Tree。

 

### 特点

​	B树：

**1、** ***\*叶子节点具有相同的深度，叶子节点的指针为空\****；

2、 所有索引元素不重复；

**3、** ***\*节点中的数据索引从左到右递增排列\****。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E73.tmp.jpg) 

注：为了能够存储足够多的数据的同时控制树的高度，一个节点存储数据的个数由表数据和高度确定。如果数据较多，则每个节点存储数据多一些，这样高度就降下来了。

B树两个存在弊端的地方：

1、树内的每个节点都存储数据

**2、*****\*叶子节点之间无指针相邻\****

***\*由于B树的节点除了存储Key还存储Data，这样每一层存储的Key有限，也就是说这样导致层高不可控，磁盘IO较多\****。如果除了叶子节点都存储Key值，这样就可以很快找到叶子节点，进而找到Data，这就引入B+树。

注意一下B+树的两个明显特点

1、数据只出现在叶子节点

2、所有叶子节点增加了一个链指针

针对上面的B+树和B树的特点，我们做一个总结

1、B树的树内存储数据，因此查询单条数据的时候，B树的查询效率不固定，最好的情况是O(1)。我们***\*可以认为在做单一数据查询的时候，使用B树平均性能更好\****。但是，由于B树中各节点之间没有指针相邻，因此***\*B树不适合做一些数据遍历操作\****。

2、B+树的数据只出现在叶子节点上，因此在查询单条数据的时候，查询速度非常稳定。因此，在做单一数据的查询上，其平均性能并不如B树。但是，***\*B+树的叶子节点上有指针进行相连，因此在做数据遍历的时候，只需要对叶子节点进行遍历即可，这个特性使得B+树非常适合做范围查询\****。

因此，我们可以做一个推论：没准是Mysql中数据遍历操作比较多，所以用B+树作为索引结构。而Mongodb是做单一查询比较多，数据遍历操作比较少，所以用B树作为索引结构。

那么为什么Mysql做数据遍历操作多？而Mongodb做数据遍历操作少呢？
	因为Mysql是关系型数据库，而Mongodb是非关系型数据。

而非关系型数据库，做数据遍历操作少呢？

***\*关系型VS非关系型\****

假设，我们此时有两个逻辑实体:学生(Student)和班级(Class)，这两个逻辑实体之间是一对多的关系。毕竟一个班级有多个学生，一个学生只能属于一个班级。
	***\*关系型数据库\*******\*
\****	我们在关系型数据库中，考虑的是用几张表来表示这二者之间的实体关系。常见的无外乎是，一对一关系，用一张表就行。一对多关系，用两张表。多对多关系，用三张表。
那这里，我们需要用两张表表示二者之间逻辑关系，如下所示

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E84.tmp.jpg) 

那我们，此时要查cname为1班的班级，有多少学生怎么办？
	假设cname这列，我们建了索引！
	执行SQL，如下所示：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E85.tmp.jpg) 

而这，就涉及到了数据遍历操作！

因为但凡做这种关联查询，你躲不开join操作的！既然涉及到了join操作，无外乎从一个表中取一个数据，去另一个表中逐行匹配，如果索引结构是B+树，叶子节点上是有指针的，能够极大的提高这种一行一行的匹配速度！

有的人或许会抬杠说，如果我先执行：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E86.tmp.jpg) 

就可以避开join操作呀？

对此，我想说。你确实避开了join操作，但是你数据遍历操作还是没避开。你还是需要在student的这张表的叶子节点上，一遍又一遍的遍历！

那在非关系型数据库中，我们如何查询cname为1班的班级，有多少学生？

***\*非关系型数据库\*******\*
\****	有人说，你可以这么设计？也就是弄两个集合如下所示：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E87.tmp.jpg) 

然后，执行两次查询去获得结果！一次去class集合查，获得id后再去student集合查。

确实，这么设计是可以的，我没说不行。只是不符合非关系型数据库的设计初衷。在MongoDB中，根本不推荐这么设计。虽然，Mongodb中有一个$lookup操作，可以做join查询。但是理想情况下，这个$lookup操作应该不会经常使用，如果你需要经常使用它，那么你就使用了错误的数据存储了（数据库）：如果你有相关联的数据，应该使用关系型数据库（SQL）。

因此，正规的设计应该如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E97.tmp.jpg) 

假设name这列，我们建了索引！
	我只需执行一次语句：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E98.tmp.jpg) 

这样就能查询出自己想要的结果。

而这，就是一种单一数据查询!毕竟你不需要去逐行匹配，不涉及遍历操作,幸运的情况下，有可能一次IO就能够得到你想要的结果。

因此，***\*由于关系型数据库和非关系型数据的设计方式上的不同。导致在关系型数据中，遍历操作比较常见，因此采用B+树作为索引，比较合适。而在非关系型数据库中，单一查询比较常见，因此采用B树作为索引，比较合适\****。

 

### MongoDB

#### 概述

MySQL和MongoDB两种不同类型的数据库使用了相似却不同的数据结构，为什么MySQL选择使用B+树而MongoDB使用B树呢？

MongoDB是一个通用的、面向文档的分布式数据库，区别于传统的关系型数据库 MySQL、Oracle 和SQL Server，MongoDB最重要的一个特点就是***\*面向文档\****，由于数据存储方式的不同，对外提供的接口不再是被大家熟知的SQL，所以被划分成了NoSQL，NoSQL 是相对SQL而言的，很多我们耳熟能详的存储系统都被划分成了NoSQL，例如：Redis、DynamoDB和 Elasticsearch 等。

NoSQL经常被理解成没有SQL（Non-SQL）或者非关系型（Non-Relational），不过也有人将其理解成不只是SQL（Not Only SQL），深挖这个词的含义和起源可能没有太多意义，这种二次解读很多时候都是为营销服务的，我们只需要知道MongoDB对数据的存储方式与传统的关系型数据库完全不同。

MongoDB的架构与MySQL非常类似，它们底层都使用了可插拔的存储引擎以满足用户的不同需求，用户可以根据数据特征选择不同的存储引擎，最新版本的MongoDB使用了WiredTiger作为默认的存储引擎。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E99.tmp.jpg) 

作为MongoDB 默认的存储引擎，WiredTiger使用B树作为索引底层的数据结构，但是除了B树之外，它还支持LSM树作为可选的底层存储结构，LSM树的全称是 Log-structured merge-tree，你可以在MongoDB中使用如下所示的命令创建一个基于LSM树的集合（Collection）:

db.createCollection(

  "posts",

  { storageEngine: { wiredTiger: {configString: "type=lsm"}}}

)

#### 设计

既然要比较两个不同数据结构与B树的差别，那么在这里我们将分两个小节分别介绍B+树和LSM树为什么没有成为WiredTiger 默认的数据结构：

● 作为非关系型的数据库，MongoDB对于***\*遍历数据\****的需求没有关系型数据库那么强，它追求的是***\*读写单个记录\****的性能；

● 大多数OLTP的数据库面对的都是读多写少的场景，B 树与 LSM 树在该场景下有更大的优势；

上述的两个场景都是MongoDB需要面对和解决的，所以我们会在这两个常见场景下对不同的数据结构进行比较。

 

***\*非关系型\****

我们在上面其实已经多次提到了MongoDB是非关系型的文档数据库，它完全抛弃了关系型数据库那一套体系之后，在设计和实现上就非常自由，它不再需要遵循SQL和关系型数据库的体系，可以更自由对特定场景进行优化，而在MongoDB假设的场景中遍历数据并不是常见的需求。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4E9A.tmp.jpg) 

MySQL中使用B+树是因为B+树只有叶节点会存储数据，将树中的每一个叶节点通过指针连接起来就能实现顺序遍历，而遍历数据在关系型数据库中非常常见，所以这么选择是完全没有问题的。

 

MongoDB和MySQL在多个不同数据结构之间选择的最终目的就是减少查询需要的随机IO次数，MySQL认为遍历数据的查询是常见的，所以它选择B+树作为底层数据结构，而舍弃了通过非叶节点存储数据这一特性，但是MongoDB面对的问题就不太一样了：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EAB.tmp.jpg) 

虽然遍历数据的查询是相对常见的，但是MongoDB认为查询单个数据记录远比遍历数据更加常见，由于B树的非叶结点也可以存储数据，所以查询一条数据所需要的平均随机IO次数会比B+树少，使用B树的MongoDB在类似场景中的查询速度就会比MySQL快。这里并不是说 MongoDB并不能对数据进行遍历，我们在MongoDB中也可以使用范围来查询一批满足对应条件的记录，只是需要的时间会比MySQL长一些。

SELECT * FROM comments WHERE created_at > '2019-01-01'

很多人看到遍历数据的查询想到的可能都是如上所示的范围查询，然而在关系型数据库中更常见的其实是如下所示的 SQL——查询外键或者某字段等于某一个值的全部记录：

SELECT * FROM comments WHERE post_id = 1

上述查询其实并不是范围查询，它没有使用>、< 等表达式，但是它却会在comments表中查询一系列的记录，如果comments表上有索引 post_id，那么这个查询可能就会在索引中遍历相应索引，找到满足条件的comment，这种查询也会受益于MySQL B+树相互连接的叶节点，因为它能减少磁盘的随机IO次数。

 

MongoDB作为非关系型的数据库，它从集合的设计上就使用了完全不同的方法，如果我们仍然使用传统的关系型数据库的表设计思路来思考 MongoDB中集合的设计，写出类似如上所示的查询会带来相对比较差的性能：

db.comments.find( { post_id: 1 } )

因为 B 树的所有节点都能存储数据，各个连续的节点之间没有很好的办法通过指针相连，所以上述查询在 B 树中性能会比 B+ 树差很多，但是这并不是一个 MongoDB 中推荐的设计方法，更合适的做法其实是使用嵌入文档，将 post 和属于它的所有 comments 都存储到一起：

{

  "_id": "...",

  "title": "为什么 MongoDB 使用 B 树",

  "author": "draven",

  "comments": [

​    {

​      "_id": "...",

​      "content": "你这写的不行"

​    },

​    {

​      "_id": "...",

​      "content": "一楼说的对"

​    }

  ]

}

使用上述方式对数据进行存储时就不会遇到 db.comments.find( { post_id: 1 } ) 这样的查询了，我们只需要将 post 取出来就会获得相关的全部评论，这种区别于传统关系型数据库的设计方式是需要所有使用 MongoDB 的开发者重新思考的，这也是很多人使用 MongoDB 后却发现性能不如 MySQL 的最大原因 —— 使用的姿势不对。

 

有人可能会有疑问了，既然MongoDB认为查询单个数据记录远比遍历数据的查询更加常见，那为什么不使用哈希作为底层的数据结构呢？

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EAC.tmp.jpg) 

如果我们使用哈希，那么对于所有单条记录查询的复杂度都会是O(1)，但是遍历数据的复杂度就是O(n)；如果使用B+树，那么单条记录查询的复杂度是O(log n)，遍历数据的复杂度就是O(log n) + X，这两种不同的数据结构一种提供了最好的单记录查询性能，一种提供了最好的遍历数据的性能，但是这都不能满足MongoDB面对的场景 —— 单记录查询非常常见，但是对于遍历数据也需要有相对较好的性能支持，哈希这种性能表现较为极端的数据结构往往只能在简单、极端的场景下使用。

 

***\*读多写少\****

LSM树是一个基于磁盘的数据结构，它设计的主要目的是为长期需要高频率写入操作的文件提供低成本的索引机制。无论是B树还是B+树，向这些数据结构组成的索引文件中写入记录都需要执行的磁盘随机写，LSM树的优化逻辑就是牺牲部分的读性能，将随机写转换成顺序写以优化数据的写入。

我们不详细介绍为什么LSM树有着较好的写入性能，我们只是来分析为什么 WiredTiger使用B树作为默认的数据结构。WiredTiger对LSM树和B树的性能进行了读写吞吐量的基准测试，通过基准测试得到了如下图所示的结果，从图中的结果我们能发现：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EAD.tmp.jpg) 

1、在不限制写入的情况下；

LSM树的写入性能是B树的 1.5 ~ 2 倍；

LSM树的读取性能是B树的 1/6 ~ 1/3；

2、在限制写入的情况下；

LSM树的写入性能与B树的性能基本持平；

LSM树的读取性能是B树的 1/4 ~ 1/2；

在限制写入的情况下，每秒会写入30,000条数据，从这里的分析结果来看，无论那种情况下B树的读取性能是远好于LSM树的。对于大多数的OLTP系统来说，系统的查询会是写的很多倍，所以LSM树在写入方面的优异表现也没有办法让它成为MongoDB默认的数据格式。

 

#### 总结

应用场景永远都是系统设计时首先需要考虑的问题，作为NoSQL的MongoDB，其目标场景就与更早的数据库就有着比较大的差异，我们来简单总结一下MongoDB最终选择使用B树的两个原因：

MySQL使用B+树是因为数据的遍历在关系型数据库中非常常见，它经常需要处理各个表之间的关系并通过范围查询一些数据；但是MongoDB作为面向文档的数据库，与数据之间的关系相比，它更看重以文档为中心的组织方式，所以选择了查询单个文档性能较好的B树，这个选择对遍历数据的查询也可以保证可以接受的时延；

LSM树是一种专门用来优化写入的数据结构，它将随机写变成了顺序写显著地提高了写入性能，但是却牺牲了读的效率，这与大多数场景需要的特点是不匹配的，所以MongoDB最终还是选择读取性能更好的B树作为默认的数据结构；

***\*由于关系型数据库和非关系型数据的设计方式上的不同。导致在关系型数据中，遍历操作比较常见，因此采用B+树作为索引，比较合适。而在非关系型数据库中，单一查询比较常见，因此采用B树作为索引，比较合适\****。

## B+树索引

### 概述

B+树是B-树的变体，也是一种多路搜索树：

1、其定义基本与B-树同，除了：

2、非叶子结点的子树指针与关键字个数相同；

3、非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）；

5、为所有叶子结点增加一个链指针；

6、所有关键字都在叶子结点出现；

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EAE.tmp.jpg) 

B+的搜索与B-树也基本相同，区别是B+树只有达到叶子结点才命中（B-树可以在

非叶子结点命中），其性能也等价于在关键字全集做一次二分查找。

 

B+ Tree和 B Tree不同，***\*B+ Tree中，只能将数据存储在叶子结点中\****，内部节点将只包含指针，而B Tree可以将数据存储在内部的叶节点中。

因此***\*B+ Tree的关键优势是中间节点不包含数据\****，因此B+ Tree的大小远小于B Tree，并且可以将更多数据存储到存储器中。另外，***\*B+ Tree的每一个叶子节点包含了到相邻的节点的链接，这样可以快速地进行范围遍历\****。

***\*B+树结构如下：\****

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EBF.tmp.jpg) 

**MySQL真正使用的数据结构不是B树，而是B树的变种B+树**，B+树是一个平衡二叉树，从根节点到每个叶子节点的高度差值不超过1，而且同层级的节点间有指针相互链接。其特点：

1、 **非叶子节点不存储data**，只存储索引（冗余），可以放更多的索引；

2、 **叶子节点包含****所有索****引字段**（非叶子节点也有一个相同的值，存在冗余，B树则没有冗余）；

3、 叶子节点用指针连接，提高***\*区间访问\****的性能（B树叶子节点是没有这个指针的）。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EC0.tmp.jpg) 

​	注：***\*在非叶子节点不存储data，因为InnoDB对于页大小有限制，1\*******\*6\*******\*KB，所以只存储索引可以在每一行存储更多的索引信息（B树非叶子节点存储data信息，浪费内存），将data放到叶子节点。\****例如，bigint的索引，则15占用8Byte，后面地址信息6Byte，则一个索引占8+6=14Byte，页大小16KB，则大概可以放16KB/14Byte=1170个节点。如果叶子节点data占据1KB，则页大小16KB的时候叶子结点可以存储16个索引，则最终可以存储的索引为1170*1170*16（假设是3层），这是千万级别的数据。

​	***\*根节点一般事先加载到内存\****，所以在根节点可以快速定位加载的页，从磁盘加载对应的数据页到内存，实现快速查找。

在B+树叶子节点保存了所有的索引数据（不是所有的表数据），所有非叶子结点都会在叶子节点保留一份备份，所以B+树节点树比实际存储的数据的个数要多。

 

​	**B树与B+树：**

1、 B树非叶子节点存储data（索引数据的地址），B+树非叶子节点只存储索引信息；

2、 B树不存在数据冗余，B+树存在冗余（普通索引会存储主键，主键索引会存储所有数据，这样就存在数据冗余了），叶子节点存储所有数据。

### 插入

对于插入操作很简单，只需要记住一个技巧即可：当节点元素数量大于m-1的时候，按中间元素分裂成左右两部分，中间元素分裂到父节点当做索引存储，但是，本身中间元素还是分裂右边这一部分的。

下面以一颗5阶B+树的插入过程为例，5阶B+树的节点最少2个元素，最多4个元素。

插入5，10，15，20

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EC1.tmp.jpg) 

插入25，此时元素数量大于4个了，分裂

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EC2.tmp.jpg) 

接着插入26，30，继续分裂

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4ED2.tmp.jpg) 

 

### 删除

对于删除操作是比B树简单一些的，因为叶子节点有指针的存在，向兄弟节点借元素时，不需要通过父节点了，而是可以直接通过兄弟节移动即可（前提是兄弟节点的元素大于m/2），然后更新父节点的索引；如果兄弟节点的元素不大于m/2（兄弟节点也没有多余的元素），则将当前节点和兄弟节点合并，并且删除父节点中的key，下面我们看看具体的实例。

初始状态

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4ED3.tmp.jpg) 

删除10，删除后，不满足要求，发现左边兄弟节点有多余的元素，所以去借元素，最后，修改父节点索引

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4ED4.tmp.jpg) 

删除元素5，发现不满足要求，并且发现左右兄弟节点都没有多余的元素，所以，可以选择和兄弟节点合并，最后修改父节点索引

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4ED5.tmp.jpg) 

发现父节点索引也不满足条件，所以，需要做跟上面一步一样的操作。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4ED6.tmp.jpg) 

### 搜索过程

#### 唯一记录检索

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EE7.tmp.jpg) 

如上图，所有的数据都是唯一的，查询105的记录，过程如下：

1、将P1页加载到内存

2、在内存中采用二分法查找，可以确定105位于[100,150)中间，所以我们需要去加载100关联P4页

3、将P4加载到内存中，采用二分法找到105的记录后退出

 

#### 查询某个值的所有记录

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EE8.tmp.jpg) 

如上图，查询105的所有记录，过程如下：

1、将P1页加载到内存

2、在内存中采用二分法查找，可以确定105位于[100,150)中间，100关联P4页

3、将P4加载到内存中，采用二分法找到最有一个小于105的记录，即100，然后通过链表从100开始向后访问，找到所有的105记录，直到遇到第一个大于100的值为止

#### 范围查找

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EE9.tmp.jpg) 

数据如上图，查询[55,150]所有记录，由于页和页之间是双向链表升序结构，页内部的数据是单项升序链表结构，所以只用找到范围的起始值所在的位置，然后通过依靠链表访问两个位置之间所有的数据即可，过程如下：

1、将P1页加载到内存

2、内存中采用二分法找到55位于50关联的P3页中，150位于P5页中

3、将P3加载到内存中，采用二分法找到第一个55的记录，然后通过链表结构继续向后访问P3中的60、67，当P3访问完毕之后，通过P3的nextpage指针访问下一页P4中所有记录，继续遍历P4中的所有记录，直到访问到P5中所有的150为止。

 

#### 模糊匹配

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EEA.tmp.jpg) 

数据如上图。

查询以`f`开头的所有记录

过程如下：

1、将P1数据加载到内存中

2、在P1页的记录中采用二分法找到最后一个小于等于f的值，这个值是f，以及第一个大于f的，这个值是z，f指向叶节点P3，z指向叶节点P6，此时可以断定以f开头的记录可能存在于[P3,P6)这个范围的页内，即P3、P4、P5这三个页中

3、加载P3这个页，在内部以二分法找到第一条f开头的记录，然后以链表方式继续向后访问P4、P5中的记录，即可以找到所有已f开头的数据

 

***\*查询包含`f`的记录\****

包含的查询在sql中的写法是%f%，通过索引我们还可以快速定位所在的页么？

可以看一下上面的数据，f在每个页中都存在，我们通过P1页中的记录是无法判断包含f的记录在那些页的，只能通过io的方式加载所有叶子节点，并且遍历所有记录进行过滤，才可以找到包含f的记录。

所以如果使用了%值%这种方式，索引对查询是无效的。

 

### 单值索引

​	单值索引的B+树：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EFB.tmp.jpg) 

​	注：数据库索引使用的B+树与数据结构中严格的B+树稍有不同，这里叶子节点有next和prev指针前后相互连接（用于支持大于>和小于<操作），真正的B+树只有next指针。

### 联合索引

​	联合索引的B+树（通过最左的索引字段建立B+树）：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EFC.tmp.jpg) 

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EFD.tmp.jpg) 

​	注：比如索引为b,c,d，查询语句为select * from table;叶子节点红色部分111,222存储的是索引字段的值，即b,c,d的值，通过B+树快速定位到b,c,d对应的节点，但是如果需要查询所有字段，则需要存储除b,c,d以外的其他字段，可以选择在下方的黄色部分存储剩下的字段，比如a,e，但是这样会产生数据冗余（需要复制全部剩下的数据），这里采用存储主键即可，然后通过主键定位到对应的单索引的B+树，找到其他的字段，有效实现数据的复用。

​	如果查询select*，则需要在左侧查询到叶子节点的索引值和主键值，然后根据主键去扫描表，这样是非常耗时的。对于select b from table where b=1;（b为索引），则会走索引，而且比较快。对于select b from table where c=1;（最左索引b未找到，不继续查找索引，直接全表扫描）。对于select b from table where c=1 and d=2 and b=1;（走索引，虽然b不是在最左边，优化器会调整b到最左端的位置，所以仍然符合最左前缀）。对于select b from table where b=1 and c>1;（走索引，虽然c为范围查找，但是此时仍然可以利用最左前缀的b索引）。

由上述的联合索引可知，***\*不一定索引都比全表扫描快，查询优化器会分析索引和全局扫描的时间，哪个快走哪个\****。

联合索引的相关优化：

​	1、联合索引遵循最左前缀原则。

2、不在索引上做任何操作（计算、函数、类型转换），这样会导致索引失效而转向全表扫描。

### MyISAM

​	**MyISAM存储引擎索引底层实现数据结构：B****+****Tree**，索引存储的数据包括：索引列的值，指向数据行的指针。

​	MyISAM存储引擎实现：***\*索引文件和数据文件是分离的（非聚集索引），这与InnoDB本质不同\****。

***\*MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复\****。

​	索引结构：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4EFE.tmp.jpg) 

​	对于SQL：select col1 from where col1=15（col1为索引），查询索引值且where含索引等值链，直接找到对应的索引的值返回；

​	对于SQL：select col1,col3 from where col1=15，查询含有索引和非索引值且where含索引等值链，需要读取索引对应的额数据行的地址，然后取出改行的数据。

MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。

MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。

 

​	这个索引结构其实就是对应的MYI文件，MYI存储的索引字段，叶子节点的数据存储在MYD文件中（即索引和数据是分开存储的）。

​	MyISAM物理存储对应3个文件：

1、 MYI：存储索引

2、 MYD：存储数据

3、 FRM：表结构定义等

### InnoDB

​	**Inno****DB****存储引擎底层数据结构是：B+Tree**。

​	B+树的特点：

1、 非叶子节点不存储data，只存储key，可以增大度；

2、 叶子节点不存储指针；

3、 顺序访问指针，提高区间访问的性能。

#### 聚集索引

​	InnoDB存储引擎：聚集索引

1、 表数据文件本身就是按B+树组织的一个索引结构文件；

2、 聚集索引-叶子结点包含了完整的数据记录；

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F0E.tmp.jpg) 

注：InnoDB存储引擎对应底层文件包括frm（表结构文件），ibd（相当于MYI+MYD合集，即数据和索引合并）。正是因为数据和索引合并在叶子节点，所以最后只对应一个ibd文件（MYISAM存储引擎分来存储，所以对应MYI和MYD两个文件，对于InnoDB存储引擎，**多个索引都会指向公共的聚集索引**）。

 

利用聚集索引查找数据：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F0F.tmp.jpg) 

现在假设我们要查找id>=18并且id<40的用户数据。对应的sql语句为select * from user where id>=18 and id <40，其中id为主键。具体的查找过程如下：

1、一般根节点都是常驻内存的，也就是说页1已经在内存中了，此时不需要到磁盘中读取数据，直接从内存中读取即可。

从内存中读取到页1，要查找这个id>=18 and id <40或者范围值，我们首先需要找到id=18的键值。

从页1中我们可以找到键值18，此时我们需要根据指针p2，定位到页3。

2、要从页3中查找数据，我们就需要拿着p2指针去磁盘中进行读取页3。

从磁盘中读取页3后将页3放入内存中，然后进行查找，我们可以找到键值18，然后再拿到页3中的指针p1，定位到页8。

3、同样的页8页不在内存中，我们需要再去磁盘中将页8读取到内存中。

将页8读取到内存中后。

因为页中的数据是链表进行连接的，而且键值是按照顺序存放的，此时可以根据二分查找法定位到键值18。

此时因为已经到数据页了，此时我们已经找到一条满足条件的数据了，就是键值18对应的数据。

因为是范围查找，而且此时所有的数据又都存在叶子节点，并且是有序排列的，那么我们就可以对页8中的键值依次进行遍历查找并匹配满足条件的数据。

我们可以一直找到键值为22的数据，然后页8中就没有数据了，此时我们需要拿着页8中的p指针去读取页9中的数据。

4、因为页9不在内存中，就又会加载页9到内存中，并通过和页8中一样的方式进行数据的查找，直到将页12加载到内存中，发现41大于40，此时不满足条件。

那么查找到此终止。

最终我们找到满足条件的所有数据为：

(18,kl),(19,kl),(22,hj),(24,io),(25,vg),(29,jk),(31,jk),(33,rt),(34,ty),(35,yu),(37,rt),(39,rt)。

总共12条记录。

 

下面看下具体的查找流程图：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F10.tmp.jpg) 

##### 主键索引/主索引

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F11.tmp.jpg) 

​	注：主索引叶子节点存储所有的主键值。

**为什么InnoDB表必须有主键？并且推荐使用整型的自增主键？**

如果使用uuid，在查找过程中需要做很多比较操作判断走索引左还是右侧，而uuid比较相当麻烦，比整型的慢。整型占用磁盘空间少。

对于这颗主键索引的树：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F22.tmp.jpg) 

如果我们插入ID = 650的一行数据，那么直接在最右边插入就可以了：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F23.tmp.jpg) 

但是如果插入的是ID = 350的一行数据，由于B+树是有序的，那么需要将下面的叶子节点进行移动，腾出位置来插入ID = 350的数据，这样就会比较消耗时间，如果刚好R4所在的数据页已经满了，需要进行页分裂操作，这样会更加糟糕。

但是，如果我们的主键是自增的，每次插入的ID都会比前面的大，那么我们每次只需要在后面插入就行，不需要移动位置、分裂等操作，这样可以提高性能。也就是为什么建议使用主键自增的索引。

 

插入数据的时候会按照值从左到右递增方式，即左子节点<父节点<右子节点。叶子节点的next指针可以根据大小快速实现范围查找。

注：在插入数据的时候，主键可能是无序插入的，但是select pk from tb;的时候查出来的顺序是按照主键排序的，这就是因为底层B+树默认按照主键排序形成链表的原因（插入和查询效率都会提升）。

 

***\*为什么非主键索引结构叶子节点存储的是主键值？\****

一致性和节约存储空间。

 

##### 非主键索引/次索引

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F24.tmp.jpg) 

​	注：非主键索引叶子阶段存储的不再是主键值，而是主键索引的ID，通过这个去找对应的主键索引叶子节点的主键值。

 

##### 比较

主键索引和非主键索引的示意图如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F25.tmp.jpg) 

主键索引和非主键索引的区别是：非主键索引的叶子节点存放的是主键的值，而主键索引的叶子节点存放的是整行数据，其中非主键索引也被称为二级索引，而主键索引也被称为聚簇索引。

根据这两种结构我们来进行下查询，看看他们在查询上有什么区别。

1、如果查询语句是select * from table where ID = 100，即主键查询的方式，则只需要搜索ID这棵 B+树。

2、如果查询语句是 select * from table where k = 1，即非主键的查询方式，则先搜索k索引树，得到ID=100，再到ID索引树搜索一次，这个过程也被称为***\*回表\****。

#### 非聚集索引

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F35.tmp.jpg) 

表结构如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F36.tmp.jpg) 

在叶子节点中，不在存储所有的数据了，存储的是键值和主键。

对于叶子节点中的x-y，比如1-1。左边的1表示的是索引的键值，右边的1表示的是主键值。如果我们要找到幸运数字为33的用户信息，对应的sql语句为select * from user where luckNum=33。

查找的流程跟聚集索引一样，这里就不详细介绍了。我们最终会找到主键值47，找到主键后我们需要再到聚集索引中查找具体对应的数据信息，此时又回到了聚集索引的查找流程。  

下面看下具体的查找流程图：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F37.tmp.jpg) 

在MyISAM中，聚集索引和非聚集索引的叶子节点都会存储数据的文件地址。

#### 比较

对于聚簇索引，节点分裂问题影响比较严重，InnoDB节点下存储了“行数据”，分裂的时候还需要移动行数据；对于MYISAM，节点存储的对物理行地址，内容较小，又缓存在内存中，分裂速度很快。

### 总结

问：为什么官方建议使用自增长主键作为索引。

结合B+Tree的特点，自增主键是连续的，在插入过程中尽量减少页分裂，即使要进行页分裂，也只会分裂很少一部分。并且能减少数据的移动，每次插入都是插入到最后。总之就是减少分裂和移动的频率。

参考：

[https://mp.weixin.qq.com/s?__biz=MzI3NDA4OTk1OQ==&mid=2649902608&idx=1&sn=de0d82da5957f75e522094f7cf2e8dcc&chksm=f31fbc98c468358ed2f77cda85c3c865a50b3e6973495f77baa17cc34bc2638fdef577deb975&scene=0&xtrack=1#rd](#rd)

 

### B与B+树

针对上面的B+树和B树的特点，我们做一个总结：

1、B树的树内存储数据，因此查询单条数据的时候，B树的查询效率不固定，最好的情况是O(1)。我们可以认为在做单一数据查询的时候，使用B树平均性能更好。但是，***\*由于B树中各节点之间没有指针相邻，因此B树不适合做一些数据遍历操作\****。

2、B+树的数据只出现在叶子节点上，因此在查询单条数据的时候，查询速度非常稳定。因此，在做单一数据的查询上，其平均性能并不如B树。但是，B+树的叶子节点上有指针进行相连，因此在做数据遍历的时候，只需要对叶子节点进行遍历即可，这个特性***\*使得B+树非常适合做范围查询\****。

因此，***\*Mysql中数据遍历操作比较多，所以用B+树作为索引结构。而Mongodb是做单一查询比较多，数据遍历操作比较少，所以用B树作为索引结构\****。

 

## T树索引

对于MySQL数据库的NDB Cluster内存存储引擎，在使用它时可将其视为内存数据库（从MySQL 5.1开始NDB Cluster引擎可以将非索引数据存放在磁盘上，这种情况又可以视为混合存储引擎）。在内存数据库中，一般使用T树（T-Tree）作为其索引的数据结构。T树是由平衡二叉树和B树发展而来。NDB Cluster存储引擎中的Order Index，也就是普通索引，使用的就是T树结构。T树的好处是节点不存放数据，只存放指针，这样能减少对内存的使用，这对内存数据库来说显得尤为重要。同时T树也是一棵平衡二叉树，以此保证查找的性能。T树中的T指的是T树中节点的形状。

 

T树节点由3个指针、一个有序数组（array），以及控制信息组成。3个指针分别为指向父节点和左右子树的指针。有序数组保存的是数据指针，而非实际的数据。数组中的第一个数据称为最小元素（minimum element），最后一个数据称为最大元素（maximum element）。控制信息中存放了关于该T树节点的一些额外信息。

## Bitmap

就是用位图表示的索引，对列的每个键值建立一个位图。相对于BTree索引，占用的空间非常小，创建和使用非常快。位图索引由于只存储键值的起止Rowid和位图，占用的空间非常少。

如果用户查询的列的基数非常的小，即只有的几个固定值，如性别、婚姻状况、行政区等等。要为这些基数值比较小的列建索引，就需要建立位图索引。

***\*适合场景：\****

适合决策支持系统；

当select count(XX) 时,可以直接访问索引中一个位图就快速得出统计数据；

当根据键值做and，or或 in(x,y,..)查询时，直接用索引的位图进行或运算,快速得出结果行数据。

***\*不适合场景：\****

不适合键值较多的列(重复值较少的列)；

不适合update、insert、delete频繁的列，代价很高。

 

## Hash索引

基于哈希表实现，只有精确匹配索引所有列的查询才有效，对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（hash code），并且Hash索引将所有的哈希码存储在索引中，同时在索引表中保存指向每个数据行的指针。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F38.tmp.jpg) 

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F49.tmp.jpg) 

​	哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。

 

​	Hash索引结构的特殊性，其检索效率非常高，索引的检查可以一次定位，不像B-Tree索引需要从根节点到枝节点，最后才能访问到叶节点。这样多次的IO访问，所以哈希索引的效率要高于B-Tree索引。

​	但是，***\*哈希索引对于范围查找支持非常有限\****，所以应用场景不多。

哈希索引局限性：

1、 hash函数计算后的结果是随机的，如果是磁盘上放置数据，比如主键id，那么随着id的增长，id对应的行在磁盘上随机放置，而随机查询非常慢；

2、 哈希索引也没办法利用索引完成排序；

3、 无法对范围查询进行优化；

4、 在有大量重复键值情况下，哈希索引的效率也是极低的---->哈希碰撞问题；

5、 无法利用前缀索引，比如在B-Tree中，filed列的值“helloword”并添加索引，查询xx=helloword时自然可以利用索引，xx=hello也可以利用索引（左前缀索引），因为hash(“helloword”和hash(“hello”)两者的关系仍为随机。

6、 排序无法优化；

7、 必须回行，就是说，通过索引拿到的数据位置，必须回到表中取数据。

​	说明：哈希索引用在memory引擎中，所以平时一般使用的还是B-Tree索引。

 

***\*自适应哈希\****

自适应哈希索引仅是数据库自身创建并使用的，DBA本身并不能对其进行干预。自适应哈希索引经散列函数映射到一个散列表中，因此对于字典类型的查找非常快速，例如SELECT ＊ FROMTABLE WHERE index_col='xxx'，但是对于范围查找就无能为力了。通过命令SHOW ENGINE INNODB STATUS可以看到当前自适应哈希索引的使用状况。

需要注意的是，哈希索引只能用来搜索等值的查询，例如select ＊from table where index_col = 'xxx'，而对于其他查找类型，比如范围查找，是不能使用哈希索引的，因此，这里出现了non-hash searches/s的情况。由hash searches : non-hashsearches可以大概了解使用哈希索引后的效率。由于自适应哈希索引是由InnoDB存储引擎自己控制的，所以这些信息只供我们参考。不过可以通过参数innodb_adaptive_hash_index来禁用或启动此特性，默认为开启。

 

## R树索引

R树是一种用于处理多维数据的数据结构，用来访问二维或者更高维区域对象组成的空间数据。

R树是一棵平衡树。树上有两类结点：叶子结点和非叶子结点。每一个结点由若干个索引项构成。对于叶子结点，索引项形如(Index，Obj_ID)。其中，Index表示包围空间数据对象的最小外接矩形MBR，Obj_ID标识一个空间数据对象。对于一个非叶子结点，它的索引项形如(Index，Child_Pointer)。 Child_Pointer 指向该结点的子结点。Index仍指一个矩形区域，该矩形区域包围了子结点上所有索引项MBR的最小矩形区域。

## LSM

BigTable、LevelDB和HBase的应用场景都是什么？它们的读写比例有多少？为什么使用LSM树作为底层的数据结构？

### 背景

Log Structured Merge Tree，简称 LSM-Tree。2006年，Google发表了 BigTable的论文。这篇论文提到 BigTable 单机上所使用的数据结构就是 LSM-Tree。
	很多存储产品使用LSM-Tree作为数据结构，比如Apache HBase，Apache Cassandra，MongoDB 的 Wired Tiger存储引擎，LevelDB存储引擎，RocksDB存储引擎等。
	简单地说，LSM-Tree的设计目标是提供比传统的B-Tree/B+Tree更好的写性能。LSM-Tree通过将磁盘的随机写转化为顺序写来提高写性能 ，而付出的代价就是牺牲部分读性能、写放大（B-Tree/B+Tree同样有写放大的问题）。

 

### 概述

LSM Tree技术出现的一个最主要的原因就是磁盘的随机写速度要远远低于顺序写的速度，而数据库要面临很多写密集型的场景，所以很多数据库产品就把LSM Tree的思想引入到了数据库领域。

 

LSM Tree顾名思义，就是The Log-Structured Merge-Tree的缩写。从这个名称里面可以看到几个关键的信息：

1、log-structred，通过日志的方式来组织的

2、Merge，可以合并的

3、Tree，一种树形结构

实际上它并不是一棵树，也不是一种具体的数据结构，它实际上是一种数据保存和更新的思想。简单地说，就是将数据按照key来进行排序（在数据库中就是表的主键），之后形成一颗一颗的树形结构，或者不是树形结构，是一张小表也可以，这些数据通常被称为基线数据；之后把每次数据的改变（也就是log）都记录下来，也按照主键进行排序，之后定期的把log中对数据的改变合并（merge）到基线数据当中。

### 原理

下图描述了LSM Tree的基本结构：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F4A.tmp.jpg) 

图中的C0代表了缓存在内存中的数据，当内存中的数据达到了一定的阈值后，就会把数据内存中的数据排序后保存到磁盘当中，这就形成了磁盘中C1级别的增量数据（这些数据也是按照主键排序的），这个过程通常被称为转储。当C1级别的数据也达到一定阈值的时候，就会触发另外的一次合并（合并的过程可以认为是一种归并排序的过程），形成C2级别的数据，以此类推，如果这个逐级合并的结构定义了K层的话，那么最后的第K层数据就是最后的基线数据，这个过程通常称为合并。

用一句话简单描述的话，LSM Tree就是一个基于归并排序的数据存储思想。从上面的结构中不难看出，LSM Tree对写密集型的应用是非常友好的，因为绝大多数的写操作都是顺序的。但是对很多读操作是要损失一些性能的，因为数据在磁盘上可能存在多个版本，所以通常情况下，使用了LSM Tree的存储引擎都会选择把很多个版本的数据存在内存中，根据查询的需要，构建出满足要求的数据版本。在数据库领域，很多产品都使用了LSM Tree结构来作为数据库的存储引擎，例如Oceanbase，LevelDB，HBase等。

 

## ES索引

ES是基于 Lucene 的全文检索引擎，它会对数据进行分词后保存索引，擅长管理大量的索引数据，相对于 MySQL 来说不擅长经常更新数据及关联查询。

***\*全文检索通常使用倒排索引（inverted index）来实现\****。倒排索引同B树索引一样，也是一种索引结构。

### 正排索引

在ES中采用的是一种名叫倒排索引的数据结构；在正式讲倒排索引之前先来聊聊和他相反的正排索引。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F4B.tmp.jpg) 

以上图为例，我们可以通过 doc_id 查询到具体对象的方式称为使用正排索引，其实也能理解为一种散列表。

本质是通过key来查找value。

比如通过 doc_id=4 便能很快查询到 name=jetty wang,age=20 这条数据。

### 全文索引/倒排索引

那如果反过来我想查询 name 中包含了 li 的数据有哪些？这样如何高效查询呢？

仅仅通过上文提到的正排索引显然起不到什么作用，只能依次将所有数据遍历后判断名称中是否包含 li ；这样效率十分低下。

但如果我们重新构建一个索引结构：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F4C.tmp.jpg) 

当要查询 name 中包含 li 的数据时，只需要通过这个索引结构查询到 Posting List 中所包含的数据，再通过映射的方式查询到最终的数据。

这个索引结构其实就是倒排索引。

#### Term Dictionary

但如何高效的在这个索引结构中查询到 li 呢，结合我们之前的经验，只要我们将 Term 有序排列，便可以使用二叉树搜索树的数据结构在o(logn) 下查询到数据。

将一个文本拆分成一个一个独立Term 的过程其实就是我们常说的分词。

而将所有 Term 合并在一起就是一个 Term Dictionary，也可以叫做单词词典。

英文的分词相对简单，只需要通过空格、标点符号将文本分隔便能拆词，中文则相对复杂，但也有许多开源工具做支持。

当我们的文本量巨大时，分词后的 Term 也会很多，这样一个倒排索引的数据结构如果存放于内存那肯定是不够存的，但如果像 MySQL 那样存放于磁盘，效率也没那么高。

#### Term Index

所以我们可以选择一个折中的方法，既然无法将整个 Term Dictionary 放入内存中，那我们可以为Term Dictionary 创建一个索引然后放入内存中。

这样便可以高效的查询Term Dictionary ，最后再通过Term Dictionary 查询到 Posting List。

相对于 MySQL 中的 B+树来说也会减少了几次磁盘IO。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F5D.tmp.jpg) 

这个 Term Index 我们可以使用这样的 ***\*Trie树\****也就是我们常说的***\*字典树\****来存放。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F5E.tmp.jpg) 

如果我们是以 j 开头的 Term 进行搜索，首先第一步就是通过在内存中的 Term Index 查询出以 j 打头的 Term 在 Term Dictionary 字典文件中的哪个位置（这个位置可以是一个文件指针，可能是一个区间范围）。

紧接着在将这个位置区间中的所有 Term 取出，由于已经排好序，便可通过二分查找快速定位到具体位置；这样便可查询出 Posting List。

最终通过 Posting List 中的位置信息便可在原始文件中将目标数据检索出来。

#### 更多优化

当然 ElasticSearch 还做了许多针对性的优化，当我们对两个字段进行检索时，就可以利用 bitmap 进行优化。

比如现在需要查询 name=li and age=18 的数据，这时我们需要通过这两个字段将各自的结果 Posting List 取出。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F5F.tmp.jpg) 

最简单的方法是分别遍历两个集合，取出重复的数据，但这个明显效率低下。

这时我们便可使用 bitmap 的方式进行存储（还节省存储空间），同时利用先天的位与 ****计算便可得出结果。

[1, 3, 5] ⇒ 10101

[1, 2, 4, 5] ⇒ 11011

这样两个二进制数组求与便可得出结果：

10001 ⇒ [1, 5]

最终反解出 Posting List 为[1, 5],这样的效率自然是要高上许多。

同样的查询需求在 MySQL 中并没有特殊优化，只是先将数据量小的数据筛选出来之后再筛选第二个字段，效率自然也就没有 ES 高。

当然在最新版的 ES 中也会对 Posting List 进行压缩，具体压缩规则可以查看官方文档。

 

## GiST

通用搜索树（Generalized Search Tree），与其说是一种索引类型，不如说是建立索引的平台或者模板。利用Gist可以建立B-tree，R-tree或者其他的类型索引。

## 总结

问：为什么索引结构默认使用B-Tree，而不是hash，二叉树，红黑树？

hash：虽然可以快速定位，但是没有顺序，IO复杂度高。

二叉树：树的高度不均匀，不能自平衡，查找效率跟数据有关（树的高度），并且IO代价高。

红黑树：树的高度随着数据量增加而增加，IO代价高。

 

# 各类数据库索引

## MySQL

索引数据结构：B+ Tree，hash索引。

 

## Oracle

Oracle索引类型：

逻辑上：

Single column 单行索引

Concatenated 多行索引

Unique 唯一索引

NonUnique 非唯一索引

Function-based函数索引

Domain 域索引

物理上：

Partitioned 分区索引

NonPartitioned 非分区索引

B tree：

Normal 正常型B树

Rever Key 反转型B树

Bitmap 位图索引

 

## Postgresql

Postgresql提供了B-tree，R-tree，GiST和hash索引类型。

参考：https://www.pianshen.com/article/6076146660/

 

## Bigtable

索引数据结构：LSM Tree。

## Dynamo

索引数据结构：LSM Tree。

## Cassandra

索引数据结构：LSM Tree。

## LevelDB

索引数据结构：LSM Tree。

## RocksDB

索引数据结构：LSM Tree。

 

## HBase

索引数据结构：Row key，LSM Tree。

注：表格数据库/列存储都是采用row key。

## MongoDB

索引数据结构：B树，LSM Tree（MongoDB 的 Wired Tiger 存储引擎）。

注：文档类数据库都是采用B Tree，这与它的使用方式有关。

## Spanner

索引数据结构：LSM Tree。

## OceanBase

索引数据结构：LSM Tree。

 

## TiDB

索引数据结构：LSM Tree。

 

# MYISAM与InnoDB

B+树，它是一种非常适合用来做数据库索引的数据结构：

1、很适合磁盘存储，能够充分利用局部性原理，磁盘预读；

2、很低的树高度，能够存储大量数据；

3、索引本身占用的内存很小；

4、能够很好的支持单点查询，范围查询，有序性查询；

数据库的索引分为主键索引（Primary Inkex）与普通索引（Secondary Index）。InnoDB和MyISAM是怎么利用B+树来实现这两类索引，其又有什么差异呢？

## MyISAM索引

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F6F.tmp.jpg) 

MyISAM的索引与行记录是分开存储的，叫做非聚集索引（UnClustered Index）。

其主键索引与普通索引没有本质差异：

1、有连续聚集的区域单独存储行记录

2、主键索引的叶子节点，存储主键，与对应行记录的指针

3、普通索引的叶子结点，存储索引列，与对应行记录的指针

注：MyISAM的表可以没有主键。

主键索引与普通索引是两棵独立的索引B+树，通过索引列查找时，先定位到B+树的叶子节点，再通过指针定位到行记录。

举个例子，MyISAM：

t(id PK, name KEY, sex, flag);

表中有四条记录：

1, shenjian, m, A

3, zhangsan, m, A

5, lisi, m, A

9, wangwu, f, B

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F70.tmp.jpg) 

其B+树索引构造如上图：

行记录单独存储

id为PK，有一棵id的索引树，叶子指向行记录

name为KEY，有一棵name的索引树，叶子也指向行记录

 

## InnoDB索引

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F71.tmp.jpg) 

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F72.tmp.jpg) 

InnoDB的主键索引与行记录是存储在一起的，故叫做聚集索引（Clustered Index）：

1、没有单独区域存储行记录

2、主键索引的叶子节点，存储主键，与对应行记录（而不是指针）

注：因此，InnoDB的PK查询是非常快的。

因为这个特性，InnoDB的表必须要有聚集索引：

1、如果表定义了PK，则PK就是聚集索引；

2、如果表没有定义PK，则第一个非空unique列是聚集索引；

3、否则，InnoDB会创建一个隐藏的row-id作为聚集索引；

聚集索引，也只能够有一个，因为数据行在物理磁盘上只能有一份聚集存储。

InnoDB的普通索引可以有多个，它与聚集索引是不同的：普通索引的叶子节点，存储主键（也不是指针）

 

对于InnoDB表，这里的启示是：

1、不建议使用较长的列做主键，例如char(64)，因为所有的普通索引都会存储主键，会导致普通索引过于庞大；

2、建议使用趋势递增的key做主键，由于数据行与索引一体，这样不至于插入记录时，有大量索引分裂，行记录移动；

 

仍是上面的例子，只是存储引擎换成InnoDB：

t(id PK, name KEY, sex, flag);

表中还是四条记录：

1, shenjian, m, A

3, zhangsan, m, A

5, lisi, m, A

9, wangwu, f, B

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F73.tmp.jpg) 

其B+树索引构造如上图：

id为PK，行记录和id索引树存储在一起

name为KEY，有一棵name的索引树，叶子存储id

 

当：

select * from t where name=‘lisi’;

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F84.tmp.jpg) 

会先通过name辅助索引定位到B+树的叶子节点得到id=5，再通过聚集索引定位到行记录。

注：所以，其实扫了2遍索引树。

 

## 总结

MyISAM和InnoDB都使用B+树来实现索引：

1、MyISAM的索引与数据分开存储

2、MyISAM的索引叶子存储指针，主键索引与普通索引无太大区别

3、InnoDB的聚集索引和数据行统一存储

4、InnoDB的聚集索引存储数据行本身，普通索引存储主键

5、InnoDB一定有且只有一个聚集索引

6、InnoDB建议使用趋势递增整数作为PK，而不宜使用较长的列作为PK

 

# 索引NULL值

***\*索引不存储null值（但是索引可以为NULL值，只是叶子节点中不存储）\****

更准确的说，单列索引不存储null值，复合索引不存储全为null的值。索引不能存储Null，所以对这列采用is null条件时，因为索引上根本没Null值，不能利用到索引，只能全表扫描。

***\*为什么索引列不能存Null值？\****

将索引列值进行建树，其中必然涉及到诸多的比较操作。Null值的特殊性就在于参与的运算大多取值为null。

这样的话，null值实际上是不能参与进建索引的过程。也就是说，null值不会像其他取值一样出现在索引树的叶子节点上。

## 判断

参考：

https://www.cnblogs.com/fynfuxiaoxia/p/7670375.html

https://bbs.csdn.net/topics/390412212

### IFNULL

### IS NULL

### ISNULL

查询空值的运行速度基本上为IFNULL()>is NULL>ISNULL()

 

### COALESCE

COALESCE函数语法：

COALESCE(value1,value2,...);

COALESCE函数需要许多参数，并返回第一个非NULL参数。如果所有参数都为NULL，则COALESCE函数返回NULL。

## 性能

***\*问题：索引列允许为NULL，对性能影响有多少\****

结论：存储大量的NULL值，除了计算更复杂之外，数据扫描的代价也会更高一些

***\*初始化测试表、数据：\****

测试表结构如下：

[root@####]> CREATE TABLE `t_sk` (

 `id` int(10) unsigned NOT NULL AUTO_INCREMENT,

 `c1` int(10) unsigned NOT NULL,

 `c2` int(10) unsigned NOT NULL,

 `c3` int(10) unsigned NOT NULL,

 `c4` int(10) unsigned NOT NULL,

 `c5` datetime NOT NULL,

 `c6` char(20) NOT NULL,

 `c7` varchar(30) NOT NULL,

 `c8` varchar(30) NOT NULL,

 `c9` varchar(30) NOT NULL,

 PRIMARY KEY (`id`),

 KEY `k1` (`c1`)

) ENGINE=InnoDB;

除了主键索引外，还有个 c1 列上的辅助索引。

用 mysql_random_data_load 灌入50万测试数据。

[root@###]# mysql_random_data_load -hXX -uXX -pXX test t_sk 500000

把辅助索引列 c1 修改为允许NULL，并且随机更新5万条数据，将 c1 列设置为NULL

[root@####]> alter table t_sk modify c1 int unsigned;

[root@###]> update t_sk set c1 = NULL order by rand() limit 50000;

Query OK, 50000 rows affected (2.83 sec)

Rows matched: 50000  Changed: 50000  Warnings: 0

\#随机1/10为null

[root@###]> select count(*) from t_sk where c1 is null;

+----------+

| count(*) |

+----------+

|   50000 |

+----------+

好，现在观察辅助索引的索引数据页结构。

[root@###]# innblock test/t_sk.ibd scan 16

...

Datafile Total Size:100663296

===INDEX_ID:46  --聚集索引(主键索引)

level2 total block is (1)  --根节点,层高2(共3层),共1个page

block_no:     3,level:  2|*|

level1 total block is (5)  --中间节点,层高1,共5个page

block_no: 261,level: 1|*|block_no: 262,level:1|*|block_no: 263,level: 1|*|

block_no: 264,level:1|*|block_no:265,level:1|*|

level0 total block is (5020)  --叶子节点,层高0,共5020个page

block_no:5,level: 0|*|block_no: 6,level:0|*|block_no: 7,level: 0|*|

...

===INDEX_ID:47  --辅助索引

level1 total block is (1)  --根节点,层高1(共2层),共1个page

block_no:  4,level: 1|*|

level0 total block is (509)  --叶子节点,层高0,共509个page

block_no: 18,level: 0|*|block_no:19,level:  0|*|block_no:  31,level:  0|*|

...

观察辅助索引的根节点里的数据

[root@###]# innodb_space -s ibdata1 -T test/t_sk -p 4 page-dump

...

records:

{:format=>:compact,

 :offset=>126,   --第一条记录

 :header=>

 {:next=>428,

  :type=>:node_pointer,

  :heap_number=>2,

  :n_owned=>0,

  :min_rec=>true,   --min_rec表示最小记录

  :deleted=>false,

  :nulls=>["c1"],

  :lengths=>{},

  :externs=>[],

  :length=>6},

 :next=>428,

 :type=>:secondary,

 :key=>[{:name=>"c1", :type=>"INT UNSIGNED", :value=>:NULL}],   --对应c1列值为NULL

 :row=>[{:name=>"id", :type=>"INT UNSIGNED", :value=>9}],   --对应id=9

 :sys=>[],

 :child_page_number=>18,   --指向叶子节点 pageno = 18

 :length=>8}

...

{:format=>:compact,

 :offset=>6246,   --最后一条记录(next=>112,指向supremum)

 :header=>

 {:next=>112,

  :type=>:node_pointer,

  :heap_number=>346,

  :n_owned=>0,

  :min_rec=>false,

  :deleted=>false,

  :nulls=>[],

  :lengths=>{},

  :externs=>[],

  :length=>6},

 :next=>112,

 :type=>:secondary,

 :key=>[{:name=>"c1", :type=>"INT UNSIGNED", :value=>2142714688}],   --对应c1=2142714688

 :row=>[{:name=>"id", :type=>"INT UNSIGNED", :value=>73652}],   --对应id=73652

 :sys=>[],

 :child_page_number=>2935,   --指向叶子节点2935

 :length=>12}

经过统计，根节点中c1列值为NULL的记录共有33条，其余476条是c1列值为非NULL，共509条记录。

 

叶子节点中，每个page大约可以存储1547条记录，共有5万条记录值为NULL，因此需要至少33个page来保存（ceiling(50000/1547) = 33)。

 

看下这个SQL的查询计划

[root@###]> desc select count(*) from t_sk where c1 is null\G

*************************** 1. row ***************************

​      id: 1

 select_type: SIMPLE

​    table: t_sk

  partitions: NULL

​     type: ref

possible_keys: k1

​     key: k1

   key_len: 5

​     ref: const

​     rows: 99112

   filtered: 100.00

​    Extra: Using where; Using index

从上面的输出中，我们能看到，当索引列设置允许为NULL时，是会对其纳入索引统计信息，并且值为NULL的记录，都是存储在索引树的最左边。

 

接下来，跑几个SQL查询。

SQL1，统计所有NULL值数量

[root@####]> select count(*) from t_sk where c1 is null;

+----------+

| count(*) |

+----------+

|   50000 |

+----------+

查看slow log

InnoDB_pages_distinct: 34

...

select count(*) from t_sk where c1 is null;

共需要扫描34个page，根节点(1)+叶子节点(33)，正好34个page。

备注：需要用Percona版本才能在slow query log中有InnoDB_pages_distinct信息。

 

SQL2, 查询 c1 is null

[root@####]> select id,c1 from t_sk where c1 is null limit 1;

+------+------+

| id  | c1  |

+------+------+

| 9607 | NULL |

+------+------+

查看slow log

InnoDB_pages_distinct: 12

...

select id,c1 from t_sk where c1 is null limit 1;

这次的查询需要扫描12个page，除去1个根节点外，还需要扫描12个叶子节点，只是为了返回一条数据而已，这代价有点大。

 

如果把SQL微调改成下面这样

[root@####]> select id,c1 from t_sk where c1 is null limit 10000,1;

+-------+------+

| id   | c1  |

+-------+------+

| 99671 | NULL |

+-------+------+

可以看到还是需要扫描12个page。

InnoDB_pages_distinct: 12

...

select id,c1 from t_sk where c1 is null limit 10000,1;

SQL3, 查询 c1 任意非NULL值

如果把 c1列条件改成正常的int值，结果就不太一样了

[root@####]> select id, c1 from t_sk where c1  = 907299016;

+--------+-----------+

| id   | c1     |

+--------+-----------+

| 365115 | 907299016 |

+--------+-----------+

1 row in set (0.00 sec)

slow log是这样的

InnoDB_pages_distinct: 2

...

select id, c1 from t_sk where c1  = 907299016;

可以看到，只需要扫描2个page，这个看起来就正常了。

 

结论：存储大量的NULL值，除了计算更复杂之外，数据扫描的代价也会更高一些

另外，如果要查询的c1值正好介于两个page的临界位置，那么需要多读取一个page。

扫描第31号page，确认该数据页中的最小和最大物理记录

[root@####]# innodb_space -s ibdata1 -T test/t_sk -p 31 page-dump

...

records:

{:format=>:compact,

 :offset=>126,

 :header=>

 {:next=>9996,

  :type=>:conventional,

  :heap_number=>2,

  :n_owned=>0,

  :min_rec=>false,

  :deleted=>false,

  :nulls=>[],

  :lengths=>{},

  :externs=>[],

  :length=>6},

 :next=>9996,

 :type=>:secondary,

 :key=>[{:name=>"c1", :type=>"INT UNSIGNED", :value=>1531865685}],

 :row=>[{:name=>"id", :type=>"INT UNSIGNED", :value=>1507}],

 :sys=>[],

 :length=>8}

 ...

{:format=>:compact,

 :offset=>5810,

 :header=>

 {:next=>112,

  :type=>:conventional,

  :heap_number=>408,

  :n_owned=>0,

  :min_rec=>false,

  :deleted=>false,

  :nulls=>[],

  :lengths=>{},

  :externs=>[],

  :length=>6},

 :next=>112,

 :type=>:secondary,

 :key=>[{:name=>"c1", :type=>"INT UNSIGNED", :value=>1536700825}],

 :row=>[{:name=>"id", :type=>"INT UNSIGNED", :value=>361382}],

 :sys=>[],

 :length=>8} 

指定c1的值为 1531865685、1536700825 执行查询，查看slow log，确认都需要扫描3个page，而如果换成介于这两个值之间的数据，则只需要扫描2个page。

InnoDB_pages_distinct: 3

...

select id, c1 from t_sk where c1  = 1531865685;

InnoDB_pages_distinct: 3

...

select id, c1 from t_sk where c1  = 1536700825;

InnoDB_pages_distinct: 2

...

select id, c1 from t_sk where c1  = 1536630003;

InnoDB_pages_distinct: 2

...

select id, c1 from t_sk where c1  = 1536575377;

这是因为辅助索引是非唯一的，即便是在等值查询时，也需要再读取下一条记录，以确认已获取所有符合条件的数据。

还有，当利用辅助索引读取数据时，如果要读取整行数据，则需要回表。

也就是说，除了扫描辅助索引数据页之外，还需要扫描聚集索引数据页。

 

来个例子看看就知道了。

\#无需回表时

InnoDB_pages_distinct: 2

...

select id, c1 from tnull where c1  = 1536630003;

\#需要回表时

InnoDB_pages_distinct: 5

...

select * from t_sk where c1  = 1536630003;

需要回表时，除了扫描辅助索引页2个page外，还需要回表扫描聚集索引页，而聚集索引是个3层树，因此总共需要扫描5个page。

## 存储空间

***\*问题：索引列允许为NULL，会额外存储更多字节吗\****

结论：定义列值允许为NULL并不会增加物理存储代价，但对索引效率的影响要另外考虑

我们先把c1列改成NOT NULL DEFAULT 0，当然了，改之前要先把所有NULL值更新成0。

[root@####]> update t_sk set c1=0 where c1 is null;

[root@####]> alter table t_sk modify c1 int unsigned not null default 0;

在修改之前，每条索引记录长度都是10字节，更新之后却变成了13个字节。

直接对比索引页中的数据，发现不同之处

\#允许为NULL，且默认值为NULL时

{:format=>:compact,

 :offset=>136,

 :header=>

 {:next=>146,

  :type=>:conventional,

  :heap_number=>3,

  :n_owned=>0,

  :min_rec=>false,

  :deleted=>false,

  :nulls=>["c1"],

  :lengths=>{},

  :externs=>[],

  :length=>6},

 :next=>146,

 :type=>:secondary,

 :key=>[{:name=>"c1", :type=>"INT UNSIGNED", :value=>:NULL}],

 :row=>[{:name=>"id", :type=>"INT UNSIGNED", :value=>48}],

 :sys=>[],

 :length=>4}

\#不允许为NULL，默认值为0时

{:format=>:compact,

 :offset=>138,

 :header=>

 {:next=>151,

  :type=>:conventional,

  :heap_number=>3,

  :n_owned=>0,

  :min_rec=>false,

  :deleted=>false,

  :nulls=>[],

  :lengths=>{},

  :externs=>[],

  :length=>5},

 :next=>151,

 :type=>:secondary,

 :key=>[{:name=>"c1", :type=>"INT UNSIGNED", :value=>0}],

 :row=>[{:name=>"id", :type=>"INT UNSIGNED", :value=>48}],

 :sys=>[],

 :length=>8}

可以看到，原先允许为NULL时，record header需要多一个字节（共6字节），但实际物理存储中无需存储NULL值。

而当设置为NOT NULL DEFAULT 0时，record header只需要5字节，但实际物理存储却多了4字节，总共多了3字节，所以索引记录以前是10字节，更新后变成了13字节，实际上代价反倒变大了。

 

列值允许为NULL更多的是计算代价变大了，以及索引对索引效率的影响，反倒可以说是节省了物理存储开销。

# 索引碎片

在长期的数据更改过程中，索引文件和数据文件，都将产生空洞，形成碎片。

注：修复表的数据及索引碎片，就会把所有的数据文件重新整理一遍，使之对齐。这个过程，如果表的行数比较大，也是非常耗费资源的操作，所以不能频繁的修复。

## 表损坏与修复

## nop操作修复

我们可以通过一个nop操作（不产生对数据实质影响的操作）来修改表。比如，表的引擎为InnoDB，可以alter table xxx engine innodb。

optimize table表名，也可以修复。

 

## 索引碎片处理

### 行碎片

### 行间碎片

### 剩余空间碎片

# 索引失效

## 失效场景

​	索引失效的情况：

​	1、列类型是字符串，查询条件未加引号

card_code列是身份证号，数据类型是varchar,在没有将证件号码用引号括起时不会使用索引，此时索引失效。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F95.tmp.jpg) 

这种失效，其实是由于隐式类型转换导致的索引失效，这是因为MySQL做了隐式类型转换，调用函数将card_code做了转换：

select name,card_code from dm_person_info where CAST( card_code AS signed int )=610525199009040824;

2、未使用该列作为查询条件

索引建在card_code列上，使用tel列作为查询条件，此时该索引未被使用到，也可以说是失效的。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F96.tmp.jpg) 

3、使用like时通配符在前

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F97.tmp.jpg) 

4、在查询条件中使用OR

查询条件中使用or会使索引失效，要想是索引生效，需要将or中的每个列都加上索引。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4F98.tmp.jpg) 

5、索引字段做计算（格式转换，运算）

索引列不能参与计算，尽量保持列“干净”。

比如，FROM_UNIXTIME(create_time)='2016-06-06' 就不能使用索引，原因很简单，B+树中存储的都是数据表中的字段值，但是进行检索时，需要把所有元素都应用函数才能比较，显然这样的代价太大。所以语句要写成 ：create_time=UNIX_TIMESTAMP('2016-06-06')。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FA8.tmp.jpg) 

6、字符类型索引=数值类型字段值

7、不符合最左前缀/联合索引ABC问题

单个多列组合索引和多个单列索引的检索查询效果不同，因为在执行SQL时，MySQL只能使用一个索引，会从多个单列索引中选择一个限制最为严格的索引(在MySQL5.0以后的版本中，有“合并索引”的策略，《高性能MySQL第三版》作者认为：还是应该建立起比较好的索引，而不应该依赖于“合并索引”这么一个策略)。

注：是不是走索引，需要看查询字段是主键/索引/全表，where条件查询是不是符合最左前缀/范围查找，是否含order by索引字段。

8、隐式字符编码转换导致的索引失效

当两个表之间做关联查询时，如果两个表中关联的字段字符编码不一致的话，MySQL可能会调用CONVERT函数，将不同的字符编码进行隐式转换从而达到统一。作用到关联的字段时，就会导致索引失效。

比如下面语句，其中d.id字符编码为UTF8，而l.id字符编码为utf8mb4。因为utf8mb4是utf8的超集，所以MySQL在做转换时会用CONVERT将utf8转为utf8mb4。简单来看，就是CONVERT作用到了d.id上，因此索引失效。

select l.id from t1 l,t2 d where l.id=d.id;

## 误区

​	一种常见的误区：

​	1、在where条件常用的列上都加上索引：where id=2 and price>100;

​	误区：在id和price上都添加索引，因为是独立的索引，同时只能用1个。

​	2、在多列上建立索引后，查询哪个列，索引都将返回作用

​	误区：多列索引上，索引发挥作用需要满足最左前缀要求。

​	以a,b,c为联合索引：

| 语句                                | 索引是否发挥作用            |
| ----------------------------------- | --------------------------- |
| where a=3                           | 是，只使用a列               |
| where a=3 and b=5                   | 是，使用a,b列               |
| where a=3 and b=5 and c=4           | 是，使用abc                 |
| where b=3 或 where c=4              | 否                          |
| where b=3 and c=4                   | a列能发挥索引，c不能        |
| where a=3 and b>10 and c=7          | a能利用，b能利用，c不能利用 |
| where a=3 and b like ‘xxx%’ and c=7 | a能利用，b能利用，c不能利用 |

​	因为索引本身是排序的，所以索引在排序中会发挥作用，即有时候就无需文件排序了：

​	where a=1 and b =2 order by c;	//因为c是索引字段，所以explain中不会使用filesort

where a=1 and b =2 order by a,b;	//排序字段为索引，不使用filesort

where a=1 and b =2 order by b,a;	//排序字段为索引，条件查询a=1等价于order by b,1（后面的常量不影响排序，等价于order by b），不使用filesort（前面没有a=1则使用文件排序）

​	where a=1 and b=2 order by d;	//因为d不是索引，所以会使用filesort

注：***\*order by字段的顺序是不能随便颠倒的，否则会影响效率！\****

 

​	**举例：**

​	单索引index1：

select * from table order by index1;	//索引生效

​	联合索引(index1,index2)：

select * from table order by index2;	//索引失效

select * from table where index2= and index1=;	//索引失效

​	联合索引(index2,index1)：

select * from table where index1> and index2=;	//部分失效(仅前面index1>用到索引)

单索引ch（字符类型）：

Select * from table where ch=1;	

//需要将table中所有ch转换为int类型，然后再做比较，此时索引已经失效

## 案例

参考：

https://mp.weixin.qq.com/s/pY4C9gZTEfYZv8k3Sn7WOw

https://mp.weixin.qq.com/s/oOomxBmzuS7Lc6zx6RzMrQ

 

# 索引区分度/Cardinality

## 基数

由索引中唯一值计算的一个预估值。索引基数值的准确程度直接影响到 MySQL 优化器基于此索引的查询计划是否准确高效。

与索引基数值最为密切的典型场景就是：一条 SQL 在某一时刻执行比较慢，其中较为可能的原因就是当前表记录更新频繁，这条 SQL 执行计划走的索引基数值没及时更新，优化器选择走备用索引或者走全表扫描，从而非最优执行计划，最终执行结果没有达到预期，总体查询时间较慢，这时可能得手工更新索引的基数值。

 

***\*索引的可选择性：\****

索引的可选择性好与坏，和索引基数关系非常密切。基数值越高，索引的可选择性越好；相反，基数越低，索引的可选择性越差。优化器优先使用的索引一般选择性都不差，除非没得选，才会走选择性稍差点的索引或者走全表扫描。

 

***\*影响索引基数值的相关指标：\****

1、表的sample page个数， 也就是表样例数据页的个数。

2、表的更新频率，一般来说，当1/16的数据页被更新过，就会自动更新索引基数。

3、索引列的数据分布程度，比如状态类，订单号，日期等。不同的数据分布，有不同的索引基数。

4、手动进行索引基数更新，比如 analyze table、show table status 等。

***\*查看某个索引的基数值，有多种方式：\****

1、直接执行 show index from tablename。

2、查询数据字典表 information_schema.statstics。

 

## 选择性

并不是所有在查询条件中出现的列都需要添加索引。对于什么时候添加B+树索引，一般的经验是，在访问表中很少一部分行时使用B+树索引才有意义。对于性别字段、地区字段、类型字段，它们可取值的范围很小，称为低选择性。

怎样查看索引是否是高选择性的呢？可以通过SHOW INDEX语句中的Cardinality列来观察。Cardinality值非常关键，表示索引中唯一只记录数量的预估值。这里需要注意的是，Cardinality是一个预估值，而不是一个准确值，用户也不可能得到一个准确的值。在实际应用中，Cardinality/n_rows_in_table应尽可能接近1，如果非常小，那么需要考虑是否还要建这个索引。因此在访问高选择性属性的字段，并从表中取出很少一部分数据时，对这个字段添加B+树索引是非常有必要的。

 

我们看2个有序数组

[1,2,3,4,5,6,7,8,8,9,10]

[1,1,1,1,1,8,8,8,8,8]

上面2个数组是有序的，都是10条记录，如果我需要检索值为8的所有记录，那个更快一些？

咱们使用二分法查找包含8的所有记录过程如下：先使用二分法找到最后一个小于8的记录，然后沿着这条记录向后获取下一个记录，和8对比，知道遇到第一个大于8的数字结束，或者到达数组末尾结束。

采用上面这种方法找到8的记录，第一个数组中更快的一些。因为第二个数组中含有8的比例更多的，需要访问以及匹配的次数更多一些。

这里就涉及到数据的区分度问题：

***\*索引区分度 = count(distint 记录) / count(记录)。\****

当索引区分度高的时候，检索数据更快一些，索引区分度太低，说明重复的数据比较多，检索的时候需要访问更多的记录才能够找到所有目标数据。

当索引区分度非常小的时候，基本上接近于全索引数据的扫描了，此时查询速度是比较慢的。

第一个数组索引区分度为1，第二个区分度为0.2，所以第一个检索更快的一些。

所以我们创建索引的时候，尽量选择区分度高的列作为索引。

 

# 执行成本计算

SQL选用索引的执行成本如何计算？

​	在有多个索引的情况下，在查询数据前，MySQL会选择成本最小原则来选择使用对应的索引，这里的成本主要包含两个方面。

***\*IO成本:\**** 即从磁盘把数据加载到内存的成本，默认情况下，读取数据页的IO成本是1，MySQL是以页的形式读取数据的，即当用到某个数据时，并不会只读取这个数据，而会把这个数据相邻的数据也一起读到内存中，这就是有名的程序局部性原理，所以MySQL每次会读取一整页，一页的成本就是1。所以IO的成本主要和页的大小有关

***\*CPU成本：\****将数据读入内存后，还要检测数据是否满足条件和排序等CPU操作的成本，显然它与行数有关，默认情况下，检测记录的成本是0.2。

 

# 索引优化

1、最左前缀匹配原则。这是非常重要的原则，MySQL会一直向右匹配直到遇到范围查询 （>/</BETWEEN/LIKE）就停止匹配。

2、尽量选择区分度高的列作为索引，区分度的公式是COUNT(DISTINCT col)/COUNT(*)。表示字段不重复的比率，比率越大我们扫描的记录数就越少。

3、索引列不能参与计算，尽量保持列“干净”。

比如， FROM_UNIXTIME(create_time)='2016-06-06' 就不能使用索引，原因很简单，B+树中存储的都是数据表中的字段值，但是进行检索时，需要把所有元素都应用函数才能比较，显然这样的代价太大。所以语句要写成：create_time=UNIX_TIMESTAMP('2016-06-06')。

4、尽可能的扩展索引，不要新建立索引。比如表中已经有了a的索引，现在要加（a,b）的索引，那么只需要修改原来的索引即可。

5、单个多列组合索引和多个单列索引的检索查询效果不同，因为在执行SQL时，MySQL只能使用一个索引，会从多个单列索引中选择一个限制最为严格的索引(经指正，在MySQL5.0以后的版本中，有“合并索引”的策略，翻看了《高性能MySQL 第三版》，书作者认为：还是应该建立起比较好的索引，而不应该依赖于“合并索引”这么一个策略)。“合并索引”策略简单来讲，就是使用多个单列索引，然后将这些结果用“union或者and”来合并起来。

 

## 使用原则

• 对小的数据表来说，使用索引并不能提高检索效率，因此不需对其创建索引。

• 当用户要检索的字段的数据包含有很多数值或很多空值（NULL）时，为该字段创建索引，会大大提高检索效率。

• 当用户查询表中的数据时，如果查询结果包含的数据（行）较少，一般少于数据总数的25%时，使用索引会显著提高查询效率。反之，如果用户的查询操作返回结果总是包含大量数据，那么索引的用处不大。

• 索引列在WHERE子句中应频繁使用。例如，我们在学生姓名字段上建了索引，但实际查询中并不是经常用姓名作为查询条件，该索引就没有发生作用。

• 我们要先装数据，后建索引。对于大多数的表，总有一批初始数据需要装入。该原则是说，建立表后，我们要先将这些初始数据装入表，然后再建索引，这样可以加快初始数据的录入。如果建表后就建索引，那么在输入初始数据时，每插入一个记录都要维护一次索引；当然，对于索引来说，早建和晚建都是允许的。

• 索引提高了数据检索的速度，但也降低了数据更新的速度。如果要对表中的数据进行大量更新，我们最好先销毁索引，等数据更新完毕再创建索引，这样会提高效率。

• 索引要占用数据库空间。在设计数据库时，我们要把需要的索引空间考虑在内。

• 我们要尽量把表和它的索引存放在不同的磁盘上，这样会提高查询速度。

 

## 高性能索引策略

为了避免索引失效，可以设计高效能索引策略。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FA9.tmp.jpg) 

***\*索引设计的基本原则：\****

1、适合索引的列是出现在where子句中的列，或者连接子句中指定的列

2、基数较小的类，索引效果较差，没有必要在此列建立索引

3、使用短索引，如果对长字符串列进行索引，应该指定一个前缀长度，这样能够节省大量索引空间

4、不要过度索引。索引需要额外的磁盘空间，并降低写操作的性能。在修改表内容的时候，索引会进行更新甚至重构，索引列越多，这个时间就会越长。所以只保持需要的索引有利于查询即可

### 索引长度/前缀索引

有时候我们需要索引很长的字符串列，这时候我们就需要使用前缀索引，在MySQL中，对于TEXT、BLOB和很长的字符列，必须使用前缀索引，因为MySQL不允许索引这些列的所有长度。那么相应地，前缀索引必然会降低索引的选择性。索引的选择性是指，不重复的索引列与数据表的总记录数的比值。

 

那么怎么才能找到前缀索引和索引选择性间的一个平衡呢？套用《高性能MySQL》中的一个例子：

一张表中的一个字段存储的各个城市的名字。首先，我们找到最常见的城市列表：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FAA.tmp.jpg) 

然后尝试从3个前缀开始：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FBB.tmp.jpg) 

可以看出这个与原来的差距还是挺大的。经过尝试后，我们发现，当前缀索引长度为7时，比较合适：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FBC.tmp.jpg) 

我们还可以利用另外一种算法计算下：计算选择性。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FBD.tmp.jpg) 

这是完整列的选择性。然后我们看下当前缀索引分别为3，4，5，6，7时的选择性为多少：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FBE.tmp.jpg) 

这里可能有一个误区，会让我们感觉在索引前缀长度为4或5的时候，就已经足够了。那么我们再用之前的方法验证一下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FBF.tmp.jpg) 

可以看到最常出现的前缀次数要比最常出现的城市次数大很多。即使它们的选择性比较低。找到前缀索引长度后，我们就可以创建前缀索引了：

mysql> ALTER TABLE city ADD KEY (city(7));

前缀索引是一种能使索引更小、更快的有效办法。它的缺点是：MySQL无法使用前缀索引做ORDER BY和GROUP BY，也无法使用前缀索引做覆盖扫描。

 

### 独立的列

通常会看到一些不当的查询使得MySQL无法使用已有的索引。例如：

select id from users where id+1=5;

这种查询是不会使用到索引的，而且这种查询完全可以写成：

select id from users where id=4;

所以我们应该养成简化WHERE条件的习惯，始终将索引列单独放在比较符号的一侧。

 

### *多列索引*

在MySQL5.0之前，下面的查询将无法用到索引，需要全表扫描：

select id from `shops_orders` where user_id=11 and shop_id=1;

在MySQL5.0之后，引入了“索引合并”的概念。这种算法包括：OR条件的联合（union），AND条件的相交（intersect），组合前两种情况的联合和相交。

首先看下OR条件的联合（union）：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FCF.tmp.jpg) 

会看到在EXTRA列中，有一个Using union()。而AND条件的相交（intersect）会有一个Using intersect()。

这种索引合并策略是一种优化结果，但也间接说明了你的表上的索引建的很糟糕：

当服务器对多个索引做相交操作时（通常是多个AND条件），通常意味着需要一个包含相关列的多列索引，而不是多个独立的单独索引。

当服务器对多个索引做联合操作时（通常是多个OR条件），通常需要消耗大量的CPU和内存资源在算法的缓存、排序和合并操作上。特别是其中有些索引选择性不高，需要合并扫描返回的大量数据。

更重要的是，这种索引合并策略不会被优化器计算到“查询成本”（cost）中去，优化器只关心随机页面的读取。

### 索引列顺序

既然要建立多列索引，那么选择合适的顺序就相当重要了。选择合适的索引顺序有一个经验法则：将选择性最高的列放到索引最前列。

最开始，你可以按照这个法则建立多列索引，因为这可以在使用第一个索引列的时候就筛选出最少的数据量。随着经验的积累，你会有自己的索引列排序的经验。

 

### 聚簇索引

聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。聚簇索引总是把数据行存储在叶子页中，因此一个表中只能有一个聚簇索引。

并不是所有的存储引擎都支持聚簇索引，这里我们主要讨论InnoDB。在InnoDB中，聚簇索引其实就是主键索引。如果表中没有定义主键，InnoDB会选择一个唯一的非空索引作为主键；如果没有这样的索引，InnoDB会隐式的定义一个主键来作为聚簇索引。聚簇索引的优点如下：

1、可以把相关数据保存在一起；

2、数据访问更快；

3、使用覆盖索引扫描的查询可以直接使用页节点中的主键值。

如果表在设计和查询的时候能充分利用以上特点，将会极大提高性能。当然，聚簇索引也有它的缺点：

1、聚簇索引最大限度提高了I/O密集型应用的性能，但如果所有的数据都存放在内存中，聚簇索引就没有优势了。

2、插入速度严重依赖插入顺序。这也是为什么InnoDB一般都会设置一个自增的int列作为主键。

3、更新聚簇索引的代价很高，因为会强制InnoDB将每个被更新的行移到新的位置。

4、如果不按顺序插入新数据时，可能会导致“页分裂”。

5、二级索引可能会比想象的更大。因为在二级索引的叶子节点中包含了引用行的主键列。

6、二级索引访问可能会需要进行回表查询。

 

有人可能会有疑问：什么是回表查询呢？二级索引为什么要回表查询？

答案在二级索引中保存的“行指针”的实质。因为二级索引在叶子节点中保存的并不是指向行的物理位置的指针，而是行的主键值。

那么，如果此次查询不是覆盖查询，就会利用二级索引叶子节点中保存的行主键值再去表里进行二次查询。这时才会得到我们真正想要的数据，这样就是导致使用两次B-TREE查询，而不是一次。

 

看一下聚簇索引的数据分布：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FD0.tmp.jpg) 

### 覆盖索引

如果一个索引包含或覆盖所有需要查询的字段值，我们就称之为“覆盖索引”。所以可能一个索引对于某些查询是覆盖索引，而对于其他的查询则不是。其实就是一个二级索引，只不过满足了一个特定条件。

覆盖索引是一个非常有用的工具，可以极大提升性能。试想一下，如果一个查询只需要扫描索引而无需二次回表查询，会带来什么好处：

1、索引行通常远小于数据行的大小，所以如果只需要索引，那么MySQL就会极大地减少数据访问量。

2、因为索引是按照顺序存储的，所以对于I/O密集型的范围查询会比随机从磁盘读取每一行数据的I/O要少的多。

由于InnoDB的聚簇索引，所以覆盖索引对InnoDB特别有用。

当发起一个覆盖查询的时候，在Explain中的Extra列中可以看到“Using index”的信息。让我们回到select*这个问题上：没有任何一个索引能够覆盖所有列，所以select*可能会导致原本可以用到覆盖索引的查询而无法使用覆盖索引。

 

### 索引与排序

ORDER BY和查找型查询的限制是一样的：需要满足索引的最左前缀原则，否则，MySQL无法使用索引排序。但有一个特殊情况，就是前导列为常量。

例如，有一个索引为（A，B，C），那么这样的SQL语句也会用索引排序，如下：

select id from table where A=2 order by B,C;

而这种则不行：

select id from table where A>2 order by B,C;

 

### 冗余索引

### FORCE INDEX

有时候索引失效或者优化器认为需要全表扫描，可能会导致语句比较慢，针对这种“误判”的场景，需要使用FORCE INDEX强制使用索引，提升效率。

下面几种场景需要使用：

1、INSERT INTO SELECT FROM WHERE

如果WHERE条件查询中字段没有索引，需要增加索引，然后FROM后面增加FORCE INDEX(索引)。

2、UPDATE 

针对分布式场景，需要下发SELECT FROM WHERE FOR UPDATE，此时如果条件查询字段区分度比较低没有走索引，可以在优化器中增加FORCE INDEX（不需要用户操作）。

3、DELETE

注：GoldenDB分布式数据库中对于悲观锁update/delete会先下发select for update，然后锁住数据后才会执行写操作，如果索引失效会造成全表锁，因此使用force index优化select for update。

## 索引碎片

​	在长期的数据更改过程中，索引文件和数据文件都将产生空洞，形成碎片。

​	我们可以通过一个nop操作（不产生对数据实质影响的操作）来修改表，比如表的引擎为InnoDB，可以alter table xxx engine innodb。

## Multi-Range Read

MySQL数据库5.6版本开始支持Multi-Range Read（MRR）优化。MRR优化的目的就是减少磁盘的随机访问，并且将随机访问转化为较为顺序的数据访问，可为IO-bound类型的SQL查询语句带来性能的极大提升。MRR优化适用于range、ref和eq_ref类型的查询。

MRR优化有以下几个好处：

使得数据访问变得较为顺序。在查询辅助索引时，先对得到的查询结果按照主键进行排序，并按照主键排列的顺序进行书签查找。

减少缓冲池中页被替换的次数。

批量处理对键值的查询操作。

 

对于InnoDB和MyISAM存储引擎的范围查询和联接查询，MRR的工作方式如下：

将查询得到的辅助索引键值存放于一个缓存中，这时缓存中的数据是根据辅助索引键值排序的。

将缓存中的键值根据RowID进行排序。

根据RowID的排序顺序来访问实际的数据文件。

此外，若InnoDB存储引擎或MyISAM存储引擎的缓冲池不是足够大，即不能存放下一张表中的所有数据，此时频繁的离散读取操作还会导致将缓存中的页替换出缓冲池，然后又不断地读入缓冲池。若按照主键顺序进行访问，则可以将重复行为的次数降为最低。

 

## 索引下推

### 概述

MySQL在5.6版本中引入了这个优化——Index Condition Pushdown。MySQL官网手册是这样描述的：

The goal of ICP is to reduce the number of full-record reads and thereby reduce IO operations. For InnoDB clustered indexes, the complete record is already read into the InnoDB buffer. Using ICP in this case does not reduce IO.

意思是：ICP的目的是通过减少完整记录读取的数量来减少IO操作。对于InnoDB的聚簇索引，完整记录已经被读取到InnoDB缓冲里，在这种情况下使用ICP不能减少IO。

#### 简介

Index Condition Pushdown（索引条件下推），MySQL 5.6引入了索引下推优化，是一种在存储引擎层使用索引过滤数据的一种优化方式，***\*ICP可以减少存储引擎访问基表的次数以及MySQL服务器访问存储引擎的次数\****。

索引下推（INDEX CONDITION PUSHDOWN，简称ICP）是MySQL 5.6发布后***\*针对扫描二级索引的一项优化改进\****。总的来说是通过把索引过滤条件下推到存储引擎，来减少MySQL存储引擎访问基表的次数以及MySQL服务层访问存储引擎的次数。ICP适用于MYISAM和INNODB。

 

#### 优点

1、MySQL服务层：也就是SERVER层，用来解析SQL的语法、语义、生成查询计划、接管从MySQL存储引擎层上推的数据进行二次过滤等等。

2、MySQL存储引擎层：按照MySQL服务层下发的请求，通过索引或者全表扫描等方式把数据上传到MySQL服务层。

3、MySQL索引扫描：根据指定索引过滤条件（比如where id = 1) ，遍历索引找到索引键对应的主键值后回表过滤剩余过滤条件。

4、MySQL索引过滤：通过索引扫描并且基于索引进行二次条件过滤后再回表。

ICP就是把以上索引扫描和索引过滤合并在一起处理，过滤后的记录数据下推到存储引擎后的一种索引优化策略。这样做的优点如下：

1、减少了回表的操作次数。

2、减少了上传到MySQL SERVER层的数据。

 

#### 限制

任何需要下推到底层存储层的操作一般都有诸多限制，MySQL ICP也不例外，ICP限制如下：

1、ICP仅用于需要访问基表所有记录时使用，适用的访问方法为：range、ref、eq_ref、ref_or_null。ICP尤其是对联合索引的部分列模糊查找非常有效。

2、ICP同样适用于分区表。

3、ICP的目标是减少全行记录读取，从而减少I/O操作，仅用于二级索引。主键索引本身即是表数据，不存在下推操作。

4、ICP不支持基于虚拟列上建立的索引，比如函数索引。

5、ICP不支持引用子查询的条件。

 

#### 开启

ICP默认开启，可通过优化器开关参数关闭ICP：

optimizer_switch='index_condition_pushdown=off' 

或者是在SQL层面通过HINT来关闭。

### 原理

#### 在不使用ICP索引扫描的过程

MySQL存储引擎层只把满足索引键值对应的整行表记录一条一条取出，并且上传给MySQL服务层。

MySQL服务层对接收到的数据，使用SQL语句后面的where条件过滤，直到处理完最后一行记录，再一起返回给客户端。

假设SQL语句为：

(localhost:mysqld.sock)|(ytt)>select * from t1 where r1 = 1 and r2 like '%dog%' and r4 = 5\G
	*************************** 1. row ***************************
	id: 28965
	f1: 81
	f2: 89
	f3: 100
	f4: 35
	r1: 1
	r2: 12844bda dog 11ea a051 08002753f58d
	r3: 17
	r4: 5
	1 row in set (0.00 sec)

关闭 ICP 的处理流程大概如图 1：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FD1.tmp.jpg) 

#### 使用ICP扫描的过程

MySQL存储引擎层，先根据过滤条件中包含的索引键确定索引记录区间，再在这个区间的记录上使用包含索引键的其他过滤条件进行过滤，之后规避掉不满足的索引记录，只根据满足条件的索引记录回表取回数据上传到MySQL服务层。

MySQL服务层对接收到的数据，使用where子句中不包含索引列的过滤条件做最后的过滤，然后返回数据给客户端。

如下图所示：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FE2.tmp.jpg) 

上面两张图很明显的对比出开启ICP比不开启ICP的效率。返回数据这一块虚线表示规避掉的记录，开启ICP很明显减少了上传到MySQL存储引擎层、MySQL服务层的记录条数，节省了IO。

查看语句是否用了ICP，只需要对语句进行EXPLAIN，在EXTRA信息里可以看到ICP相关信息。

以下分别为关闭 ICP 与开启 ICP 的 EXPLAIN 结果：

(localhost:mysqld.sock)|(ytt)>explain select /*+ no_icp (t1) */ * from t1 where r1 = 1 and r2 like '%dog%' and r4 = 5\G
*************************** 1. row ***************************
id: 1
select_type: SIMPLE
table: t1
partitions: NULL
type: ref
possible_keys: idx_r4,idx_u1
key: idx_u1
key_len: 5
ref: const
rows: 325
filtered: 0.12
Extra: Using where
1 row in set, 1 warning (0.00 sec)

(localhost:mysqld.sock)|(ytt)>explain select * from t1 where r1 = 1 and r2 like '%dog%' and r4 = 5\G *************************** 1. row ***************************
id: 1
select_type: SIMPLE
table: t1
partitions: NULL
type: ref
possible_keys: idx_r4,idx_u1
key: idx_u1
key_len: 5
ref: const
rows: 325
filtered: 0.12
Extra: Using index condition; Using where
1 row in set, 1 warning (0.00 sec)

其中extra里显示 “Using index condition” 就代表用了ICP。不过这个信息有点过于简单了，除了EXTRA列结果显示不同外，其他的列结果都一样，没法从执行计划结果判断ICP的优略。

可以通过以下几种方法来查看ICP带来的直观性能提升。

1、show status like '%handler%'

show status语句可以查看对存储引擎的相关指标监控结果。从以下结果可以看出：指标 Handler_read_next（表示MySQL存储引擎按照索引键顺序读取下一行记录的请求数，也就是说这个值表示按照索引键值来访问基表的请求数）在没有开启 ICP 时，值为 325，也就是说对基表读取请求 325 次；而开启 ICP 后，这个值仅有 14 次。所以开启 ICP 效率提升很明显。

(localhost:mysqld.sock)|(ytt)>flush status;
	Query OK, 0 rows affected (0.01 sec)

​	(localhost:mysqld.sock)|(ytt)> select /*+ no_icp (t1) */ * from t1 where r1 = 1 and r2 like '%dog%' and r4 = 5\G
​	*************************** 1. row ***************************
​	id: 28965
​	f1: 81
​	f2: 89
​	f3: 100
​	f4: 35
​	r1: 1
​	r2: 12844bda dog 11ea a051 08002753f58d
​	r3: 17
​	r4: 5
​	1 row in set (0.00 sec)

​	(localhost:mysqld.sock)|(ytt)>show status like '%handler%';
​	+----------------------------+-------+
​	| Variable_name | Value |
​	+----------------------------+-------+
​	| Handler_commit | 1 |
​	| Handler_delete | 0 |
​	| Handler_discover | 0 |
​	| Handler_external_lock | 2 |
​	| Handler_mrr_init | 0 |
​	| Handler_prepare | 0 |
​	| Handler_read_first | 0 |
​	| Handler_read_key | 1 |
​	| Handler_read_last | 0 |
​	| Handler_read_next | 325 |
​	| Handler_read_prev | 0 |
​	| Handler_read_rnd | 0 |
​	| Handler_read_rnd_next | 0 |
​	| Handler_rollback | 0 |
​	| Handler_savepoint | 0 |
​	| Handler_savepoint_rollback | 0 |
​	| Handler_update | 0 |
​	| Handler_write | 0 |
​	+----------------------------+-------+
​	18 rows in set (0.00 sec)

​	(localhost:mysqld.sock)|(ytt)>flush status;
​	Query OK, 0 rows affected (0.01 sec)

​	(localhost:mysqld.sock)|(ytt)>select * from t1 where r1 = 1 and r2 like '%dog%' and r4 = 5\G
​	*************************** 1. row ***************************
​	id: 28965
​	f1: 81
​	f2: 89
​	f3: 100
​	f4: 35
​	r1: 1
​	r2: 12844bda dog 11ea a051 08002753f58d
​	r3: 17
​	r4: 5
​	1 row in set (0.00 sec)

​	(localhost:mysqld.sock)|(ytt)>show status like '%handler%';
​	+----------------------------+-------+
​	| Variable_name | Value |
​	+----------------------------+-------+
​	| Handler_commit | 1 |
​	| Handler_delete | 0 |
​	| Handler_discover | 0 |
​	| Handler_external_lock | 2 |
​	| Handler_mrr_init | 0 |
​	| Handler_prepare | 0 |
​	| Handler_read_first | 0 |
​	| Handler_read_key | 1 |
​	| Handler_read_last | 0 |
​	| Handler_read_next | 14 |
​	| Handler_read_prev | 0 |
​	| Handler_read_rnd | 0 |
​	| Handler_read_rnd_next | 0 |
​	| Handler_rollback | 0 |
​	| Handler_savepoint | 0 |
​	| Handler_savepoint_rollback | 0 |
​	| Handler_update | 0 |
​	| Handler_write | 0 |
​	+----------------------------+-------+
​	18 rows in set (0.00 sec)
​	2、开启 profiles

查看 profile 结果的总体时间，关闭 ICP 为：0.00101900，开启 ICP 为：0.00100325。时间上开启 ICP 占优势。

(localhost:mysqld.sock)|(ytt)>set profiling=1;
	Query OK, 0 rows affected, 1 warning (0.00 sec)

​	(localhost:mysqld.sock)|(ytt)>show profiles;
​	Empty set, 1 warning (0.00 sec)

​	(localhost:mysqld.sock)|(ytt)> select /*+ no_icp (t1) */ * from t1 where r1 = 1 and r2 like '%dog%' and r4 = 5\G
​	*************************** 1. row ***************************
​	id: 28965
​	f1: 81
​	f2: 89
​	f3: 100
​	f4: 35
​	r1: 1
​	r2: 12844bda dog 11ea a051 08002753f58d
​	r3: 17
​	r4: 5
​	1 row in set (0.00 sec)

​	(localhost:mysqld.sock)|(ytt)> select * from t1 where r1 = 1 and r2 like '%dog%' and r4 = 5\G 	*************************** 1. row ***************************
​	id: 28965
​	f1: 81
​	f2: 89
​	f3: 100
​	f4: 35
​	r1: 1
​	r2: 12844bda dog 11ea a051 08002753f58d
​	r3: 17
​	r4: 5
​	1 row in set (0.00 sec)

​	(localhost:mysqld.sock)|(ytt)>show profiles\G
​	*************************** 1. row ***************************
​	Query_ID: 1
​	Duration: 0.00101900
​	Query: select /*+ no_icp (t1) */ * from t1 where r1 = 1 and r2 like '%dog%' and r4 = 5
​	*************************** 2. row ***************************
​	Query_ID: 2
​	Duration: 0.00100325
​	Query: select * from t1 where r1 = 1 and r2 like '%dog%' and r4 = 5
​	2 rows in set, 1 warning (0.00 sec)

 

### 举例

官方文档中给的例子和解释如下：

people表中（zipcode，lastname，firstname）构成一个索引

SELECT * FROM people WHERE zipcode='95054' AND lastname LIKE '%etrunia%' AND address LIKE '%Main Street%';

如果没有使用索引下推技术，则MySQL会通过zipcode='95054'从存储引擎中查询对应的数据，返回到MySQL服务端，然后MySQL服务端基于lastname LIKE '%etrunia%'和address LIKE '%Main Street%'来判断数据是否符合条件。

如果使用了索引下推技术，则MYSQL首先会返回符合zipcode='95054'的索引，然后根据lastname LIKE '%etrunia%'和address LIKE '%Main Street%'来判断索引是否符合条件。如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接reject掉。有了索引下推优化，可以在有like条件查询的情况下，减少回表次数。

 

再举一例：

我们需要查询name以javacode35开头的，性别为1的记录数，sql如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps4FE3.tmp.jpg) 

过程：

1、走name索引检索出以javacode35的第一条记录，得到记录的id

2、利用id去主键索引中查询出这条记录R1

3、判断R1中的sex是否为1，然后重复上面的操作，直到找到所有记录为止。

上面的过程中需要走name索引以及需要回表操作。

 

如果采用ICP的方式，我们可以这么做，创建一个(name,sex)的组合索引，查询过程如下：

1、走(name,sex)索引检索出以javacode35的第一条记录，可以得到(name,sex,id)，记做R1

2、判断R1.sex是否为1，然后重复上面的操作，知道找到所有记录为止

这个过程中不需要回表操作了，通过索引的数据就可以完成整个条件的过滤，速度比上面的更快一些。

 

有些查询可以采用联合索引，进而使用到索引下推（IPC），也可以减少回表操作，提升效率。

 

 

 