# 概述

# 原理

# 分布式数据库实践

## TDSQL

在生产系统中，通常都需要用高可用方案来保证系统不间断运行；数据库作为系统数据存储和服务的核心能力，其可用要求高于计算服务资源。目前，TDSQL高可用方案通常是让多个数据库服务协同工作，当一台数据库故障，余下的立即顶替上去工作，这样就可以做到不中断服务或只中断很短时间，该方案简称主从高可用，也可以叫做主备高可用。在普通的主从高可用基础上， TDSQL支持：
	⚫ 支持故障自动转移，集群自动成员控制，故障节点自动从集群中移除；如果是实例级的主从切换，换后VIP（虚拟 IP）不变；基于强同步复制策略下，主从切换将保证主从数据完全一致，可满足金融级数据一致性要求。
	⚫ 支持故障自动恢复， 承载分片的物理节点故障，调度系统自动尝试恢复节点，如果原节点无法恢复，将在30分钟内自动申请新资源，并通过备份重建（ Rebuild）节点，并将节点自动加入集群，已确保实例长期来保持完整的高可用架构。
	⚫ 每个节点都包含完整的数据副本，可以根据DBA需求切换；
	⚫ 支持免切设置，即可以设置在某一特殊时期，不处理故障转移。
	⚫ 仅需x86设备，且无需共享存储设备即可支持；
	⚫ 支持跨可用区部署，实例的主机和从机可分处于不同机房（无论是否同城），数据之间通过专线网络进行实时的数据复制。本地为主机，远程为从机，首先访问本地的节点，若本地实例发生故障或访问不可达，则访问远程从机。 若配合腾讯VPC网络环境下，可支持同城双活架构，即业务系统可以直接在两个中心读写数据库。跨可用区部署特性为TDSQL提供了多可用区容灾的能力， 避免了单IDC部署的运营风险。 

TDSQL的每一个分片都支持基于强同步的高可用方案，主数据库故障时将自动选举出最优备机立即顶替工作，切换过程对用户透明，且不改变访问IP。并且对数据库和底层物理设备提供7X24小时持续监控。发生故障时，TDSQL将自动重启数据库及相关进程；如果节点崩溃无法恢复，将通过备份文件自动重建节点（如下图）：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsEE8F.tmp.jpg) 

## OceanBase

## TiDB

## GoldenDB

### **主备一致性校验**

#### pt-table-checksum

##### 原理

pt-table-checksum将每个表按照行分成块，使用REPLACE...SELECT查询检查每块数据的一致性，通过改变块大小保证一致性校验的运行时间，每块校验的目标时间默认为0.5s。

##### 命令

项目代码生成命令：

pt-table-checksum --no-check-binlog-format --databases=

A=utf8,h=10.10.10.10.P=6666,u=username,p=’password’

--nocheck-replication-filters,

--ignore-databases=mysql,percona,dbagent

--tables=

--ignore-tables=percona.checksums

--chunk-szie-limit=2

--recursion-method=hosts 	1>/home.dbagent_guardianft/table-sync/****_checksum.log 2>&1

##### 参数

| 参数                          | 解释                                                         |
| ----------------------------- | ------------------------------------------------------------ |
| --nocheck-replication-filters | 不检查复制过滤器，建议启用。可以用--databases来指定需要检查的数据库。默认在检查到在主从复制过程中又被用ignore过滤的表，检查会中断并退出，如果想避开这个检查可以设置--no-check-replication-filters |
| --no-check-binlog-format      | 不检查复制的binlog模式，要是binlog模式是ROW，则会报错。默认会检查binlog-format，默认不是statement，就会报错，想避免检查可以设置--no-check-binlog-format |
| --replicate-check-only        | 只显示不同步的信息                                           |
| --replicate=                  | 用来指定存放计算结果的表名，默认是percona.checksums          |
| --databases=                  | 指定需要被检查的数据库，多个则用逗号隔开                     |
| A=                            | 字符集                                                       |
| u=                            | 用户名                                                       |
| h=                            | IP，主机ip必须指定，备机ip未指定默认情况下搜索DSN能搜到的所有备机，备机ip指定时只检查主机和备机的一致性，第一个ip为主机，第二个ip为备机 |
| p=                            | 密码                                                         |
| P=                            | 端口                                                         |
| --tables=                     | 指定需要被忽略的表，多个用逗号隔开                           |
| --ignore-databases=           | 检查时忽略的库                                               |
| --ignore-tables               | 检查时忽略的表，项目代码中自动配置percona.checksums          |
| --chunk-size-limit=           | 不需要对比该限制大的多（如超过该限制两倍）的块进行校验和。无索引该项默认值为2，该限制大于2时，可以对较大的块进行校验，项目代码中初始化为0，禁止超大块校验 |
| --recursion-methods           | Processlist、hosts、dsb=DSN或no。pt-tbale-checksums工具自动探测所有备机，但为以防探测失败，配置该项指定寻找备机的方法，默认为processlist，项目代码中指定为hosts。服务端口非标准端口（3306）时，hosts更优。 |

##### 退出状态（EXIT STATUS）

有三种可能的退出状态：

1、0

主备一致，没有错误告警，没有不一致校验结果，没有跳过块或表

2、255

pt-table-checksum工具致命错误

3、其他值

 

##### 返回结果

| 列名    | 解释                                                         |
| ------- | ------------------------------------------------------------ |
| TS      | 完成检查的时间                                               |
| ERRORS  | 检查时候发生错误和告警的数目                                 |
| IDFFS   | 0表示一直，1表示不一致。当指定--no-replicate-check时，会一直为0当指定--replicate-check-only会显示不同的信息 |
| ROWS    | 表的行数                                                     |
| CHUNKS  | 被划分到表中的块的数目                                       |
| SKIPPED | 由于错误或告警过大，则跳过块的数目                           |
| TIME    | 执行的时间                                                   |
| TABLE   | 被检查的表名                                                 |

 

 

#### pt-table-sync

##### 原理

对表数据进行单向或双向同步，它不同步表结构、索引或任何其他结构对象。

 

##### 命令

pt-table-sync --charset=utf8 --print --sync-to-master

A=utf8,h=10.10.10.10,P=6667,u-username,p=’password’

--ignore-databases=mysql,percona,dnagent --tables=alltype.t_all_type

\>/home/dbagent_gudianft/table-sync/****_ip_port_sql 2>&1!

##### 参数

| 参数                | 解释                                                         |
| ------------------- | ------------------------------------------------------------ |
| A=                  | 备机用户名                                                   |
| u=                  | 备机用户名                                                   |
| h=                  | 备机IP                                                       |
| p=                  | 备机密码                                                     |
| P=                  | 备机端口                                                     |
| --tables            | 指定需要被检查的表，多个逗号隔开                             |
| --ignore-databases= | 忽略的数据库，项目代码中自动配置mysql,percona,dbagent        |
| --ignore-tables     | 指定执行同步的表，多个逗号隔开                               |
| --print             | 打印修复主备一致性的SQL语句，但是不执行                      |
| --execute           | 执行命令                                                     |
| --[no]check-master  | 和--sync-to-master配合使用，验证检测的主机是否为真主机       |
| --[no]check-slave   | 检测目标服务器是否为备机，pt-table-sync默认对备机的操作告警，--no-check-slave不做备机检查有一定风险 |

 

##### 退出状态

 

 

### 故障判断

***\*怎么判断发生了故障？\****

1、DBAgent主动上报DB的状态为失败，这个时候就认定故障，不需要额外进行判断

2、CM的DBAgent断链超过一定次数（默认是10s，3次），这种心跳检测只能说明CM和DBAgent断链了，还需要其他的一些判断：

1）查看该主机下面的备机是SQL/IO线程是否异常，如果异常，这个时候不需要切换

2）计算当前集群中与CM断链的总数，如果超过某个值（隐藏配置项），则认定是网络故障。

排除上述两种情况，就认定主机fail了，此时需要执行故障切换。

 

### 切换条件检查

进入切换的一些前期检查，判断当前情况下是否可以进行切换操作？

1、当前CM的状态，是否已经启服，如果未启服，则不会执行切换

2、根据切换策略（手动同城还是自动切换），初步判断是否存在可用的DB来供选择切换，如果没有可用的DB（RDB中存储相关备机信息），则同样不会执行切换

 

### 状态机

故障切换包含很多流程，每个流程会对应一个状态，目前包含的状态有：

1、PM停服

2、设定DB只读

3、查询DB的GTID

4、查询水位信息

5、切换策略判断（高可用、高一致性、补数据）

6、连接到同城DB进行补数据

7、设定PM只读启服

8、主备切换

9、新主设定读写

10、PM启服

状态转换图如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsEE90.tmp.jpg) 

各个状态机的含义：

1、PM停服

只要涉及主的切换都会首先需要到PM申请停服，当前停服也不是PM的操作，是通过PM透传给各个proxy，让proxy执行停服，proxy停服后，再接收到外部的业务就直接拒绝了，停服是group级别的，某个group的停服是不影响其他group的业务操作的，在申请停服的时候会将在哪个group哪个主机停服这些详细信息发送给proxy，停服需要所有的proxy都停止成功，如果有一个停服失败，都表示停服任务失败。

2、DB只读

设定DB的read_only配置项为ON，这个是设定该group下的所有机器，在成功情况下，所有DB（除了故障主机）本身的值就应该是只读的，这个地方重新设置一下是为了更加保险一些，设定备机只读的目的主要是防止：

1）某个proxy在与PM断链后，仍然往旧主上发送数据（脑裂）

2）用户或者其他程序直连到DB上

3、查询GTID

这个流程很简单，就是向该city下面的所有备机发送查询GTID的请求，后期通过GTID来选择新主。

注：这个与TDSQL的同步机制不同，TDSQL要求所有备机全部同步成功才认为成功，切换的时候任何一个备机都是可以的（可以设置备机的优先级，OceanBase则是通过paxos智能选主），因为肯定是数据一致的。我们只要求有一个备机返回成功即可，在切换备机的时候并不一定任何一个备机都是与主机数据一致的，所以需要查询GTID最大的那个备机。这种方式可以明显提高写操作的效率，但是会稍微降低一些切换的效率。

4、查询高低水位

在一致性检查时，需要从MDS查询高低水位信息，来判断是否有一致性副本存在，返回的有三个值，高水位（也称为正常水位），低于高水位，低于低水位，在低于低水位的情况就认定不存在一致性副本，切换失败，在高水位和低于高水位说明可能存在有一致性副本，不一定肯定存在，所以还需要结合多节点故障来判断，简单来说，在高水位的情况下，如果存在同城有DB故障，则不能切换，低于高水位就是如果存在本地或同城有DB故障，就不能切换。

5、切换策略

根据配置的策略切换，以及是否可切同城选择相应的切换策略，目前有三个策略：

1）高一致性

2）高可用性

3）补数据

6、高一致性

从名称可以看出，优先保证数据的一致性才能进行切换，在主机故障了，宁可不发生切换，也不能在可能丢失数据的情况下执行切换，这种高一致性的保证主要是通过查询高低水位和多节点故障来判断是否有一致性副本存在，如果存在一致性副本，再根据切换策略选择GTID最大的DB切换为主，在备机切主成功后，此时会向PM发送只读启服的操作，同时让原来连接在旧主上面的备机切换到新主上面。

7、高可用性

和高一致性区别就是，在高可用场景下，通过允许丢失数据来保证可以立即恢复到可用状态，处理逻辑也比较简单，就是选择一个GTID最大的DB为主就可以了。

8、补数据

这个和高一致性，高可用性的选择策略不同的就是，在查询所有备机的GTID时发现GTID值最大的在同城，这个就需要看该集群是否允许自动切换到同城，如果允许切换到同城，再继续判断是高一致性还是高可用性，如果不允许切换到同城，那就要走补数据策略，具体流程就是除了GTID值最大的DB，其他所有的备机，都先连接到该DB上同步数据，当其他备机都同步完成后，在从本地选择一台DB作为新主来进行切换。

9、DB读写

当选择一台备机作为新主，切换成功后，设定该新主的read_only为OFF，保证新主是可读写的权限。

10、PM启服

切换完成后，通知PM启服，同时告诉PM新主的IP和Port，让其在新主上启服。

 

### **主备切换**

主备切换存在两种：一种是故障切换，一种是OMM页面主动切换。

#### 异常切换流程

1、CM判断主DB异常

1）主DBAgent和CM断链（默认丢失3个心跳）

2）该DBGroup上所有备机与主机I/O线程断链

2、执行切换：

1）对该节点停服，个给该DBGroup所有DB设置为只读状态，等待所有备机回放完成（超时60s）

2）获取高低水位信息：

2.1）低于低水位时，DB不能故障切换

2.2）高低水位之间，存在FAM_S或FAM_D的DB则不能切换

2.3）高水位时，存在一个或多个FAM_D则不能切换

3）获取所有备机GTID，超过60s认为备机异常设置该备机异常

4）多节点故障场景判断

5）如果可以切换则继续，不满足一致性切换则切换失败

6）取GTID最大的DB为新主，解除只读修正备机的主备关系

 

DB切换为备机的主要操作命令：

1、清理现有的主备关系：

stop slave and reset slave all;

2、如果备机数据比主机多，需要执行以下操作：

回滚操作：

ddbbinlog --rollback-binlog-path=’/home/zxdb1/data/binlog’ 

--rollback-sql-path=’/home/zxdb1/SwitchRollbackSql/rollback_****’

--host=’’ --port=**** --user=’’ --password=’’

--rollback-gtid-set=’’

回滚结束后，执行purge：

reset master;

set @@global.gtid_purged=’’;

3、设置半同步标志

sed -i “s/^#*\<rpl_semi_sync_master_enable\>[]*=.*/rpl_semi_sync_master_enabled=OFF/g” /home/zxdb1/etc/my.cnf

sed -i “s/^#*\<rpl_semi_sync_slave_enable\>[]*=.*/rpl_semi_sync_slave_enabled=ON/g” /home/zxdb1/etc/my.cnf

4、建立主备关系

change master to MATSER_HOST=’’,

MASTER_PORT=3306,

MASTER_AUTO_POSITION=1,

MASTER_HEARTBEAT_PERIOD=2,

MASTER_CONNECT_RETRY=10;

5、启动主从复制

start slave;

6、切换成功，切换记录保存在$HOME/etc/dbagent_info/role_switch_pos.log

#### OMM页面主动切换流程

1、OMM界面下发主备切换命令

2、DBGroup禁用

3、等待新主回放完成比较新主和旧主的GTID

4、新主和旧主GTID相同则可以切换，不同则不允许切换

5、完成主备关系纠正

 

 

 