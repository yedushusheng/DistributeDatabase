# 背景

​	对于数据量不是很大的情况下，采用本地缓存即可解决快速访问数据库的问题：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps6491.tmp.jpg) 

​	对于数据量很大的情况下，需要将应用程序和缓存分别置于不同机器，即采用远程分布式缓存（Redis单机并发10W+）：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps64A2.tmp.jpg) 

​	对于大型高并发系统（高并发，海量数据），针对客户端高并发Redis缓存无法满足需要，需要做缓存集群，针对海量数据，缓存数据会超过单台机器的内存限制，所以需要将数据分割，采用数据分布式存储：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps64A3.tmp.jpg) 

​	应用程序要想读取不同节点上的缓存数据，可以采用如下方法：

1、 哈希求余：hash(key) % 缓存集群节点数

2、 一致性hash

3、 一致性hash+虚拟节点

# 原理

​	传统哈希算法有这样的一个缺陷，如果增加服务器数量，则原来哈希计算出来的存储节点会失效，即缓存失效，造成雪崩。

​	一致性哈希算法将经过哈希计算后的结果映射到一个环上，然后顺时针查找，下一个节点就是需要存放数据的节点。缓存机器数量发生变化的时候，一致性哈希算法可以使得大部分缓存数据可以被访问，即***\*不是所有缓存数据失效，只有少部分缓存失效\****。

## **步骤**

简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0 - 232-1（即哈希值是一个32位无符号整形），整个哈希空间环如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps64A4.tmp.jpg) 

整个空间按顺时针方向组织。0和232-1在零点中方向重合。下一步将各个服务器使用H进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中三台服务器使用ip地址哈希后在环空间的位置如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps64A5.tmp.jpg) 

接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数H计算出哈希值h，根据h确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。例如我们有A、B、C、D四个数据对象，经过哈希计算后，在环空间上的位置如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps64B5.tmp.jpg) 

根据一致性哈希算法，数据A会被定为到Server 1上，D被定为到Server 3上，而B、C分别被定为到Server 2上。

 

​	总结，一致性hash算法的步骤：

1、 hash值是个整数非负，非负整数的值范围做成一个圆环；

2、 对集群的节点的某个属性（比如节点名）求hash值，放到环上；

3、 对数据key求hash值，也放到环上，按照顺时针方向找到离它最近的节点，放在它上面。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps64B6.tmp.jpg) 

## **容错性/扩展性**

现假设Server 3宕机了：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps64B7.tmp.jpg) 

可以看到此时A、C、B不会受到影响，只有D节点被重定位到Server 2。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即顺着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。

 

下面考虑另外一种情况，如果我们在系统中增加一台服务器Memcached Server 4：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps64B8.tmp.jpg) 

此时A、D、C不受影响，只有B需要重定位到新的Server 4。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即顺着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。

综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。

 

## **虚拟节点**

​	但是***\*一致性哈希算法存在hash偏斜的问题\****，即缓存不均匀，导致系统崩溃。针对这种问题，可以增加服务器，使得尽可能均匀分布，为此引入虚拟节点（缓存读写à虚拟节点à真实节点à读写）。

 

一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。 例如我们的系统中有两台服务器，其环分布如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps64C9.tmp.jpg) 

此时必然造成大量数据集中到Server 1上，而只有极少量会定位到Server 2上。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。 

 

具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，我们决定为每台服务器计算三个虚拟节点，于是可以分别计算“Memcached Server 1#1”、“Memcached Server 1#2”、“Memcached Server 1#3”、“Memcached Server 2#1”、“Memcached Server 2#2”、“Memcached Server 2#3”的哈希值，于是形成六个虚拟节点：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wps64CA.tmp.jpg) 

同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Memcached Server 1#1”、“Memcached Server 1#2”、“Memcached Server 1#3”三个虚拟节点的数据均定位到Server 1上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。

# 应用

​	应用一致性哈希算法：缓存（Redis/memcache），Hadoop，搜索引擎（ES），分布式数据库。即数据分布式存储的场景，需要考虑使用一致性哈希算法。

## **缓存**

## **Hadoop**

## **ES**

## **分布式数据存储**

​	分布式数据库领域的应用：

1、 水平拓展：

https://blog.csdn.net/linuxheik/article/details/51025879

https://blog.csdn.net/ydyang1126/article/details/70313981

2、 其他

https://yq.aliyun.com/articles/57954

https://www.cnblogs.com/lonecloud/p/8093328.html

 