# 事务

## 概述

事务就是一组不可分割的操作。

事务特性：***\*事务是恢复和并发控制的基本单位\****。

事务一般是指数据库事务，简称事务，是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。事务会把数据库从一种一致状态转换为另一种一致状态。在数据库提交工作时，可以保证要么所有修改都保存了，要么所有修改都不保存。

事务是数据库区别于文件系统的重要特征之一。在文件系统中，如果正在写文件，但是操作系统突然崩溃了，这个文件就很有能被破坏。当然，有一些机制可以把文件恢复到某个时间点。不过，如果需要保证两个文件同步，这些文件系统可能就显得无能为力了。例如，在需要更新两个文件时，更新完一个文件之后，在更新完第二个文件之前系统重启了，就会有两个不同步的文件。

用转账的例子来说，A 账户要给 B 账户转 100块，这中间至少包含了两个操作：

1、A 账户减100块

2、B 账户加100块

在支持事务的数据库管理系统来说，就是得确保上面两个操作（整个“事务”）都能完成，不能存在，A的100块扣了，然后B的账户又没加上去的情况。

 

**说明：**

1、**每个SQL语句都是一个事务**；

2、**事务只对DML语句有效，对于DQL无效**。

## ACID

​	一个支持事务（Transaction）的数据库，必须要具有这四种特性，否则在事务过程当中无法保证数据的正确性，交易过程极可能达不到交易方的要求。数据库的事务又叫本地事务。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDCD7.tmp.jpg) 

​	**事务的实现原理：**

***\*事务的原子性是通过undo\**** ***\*log\*******\*实现的；\****

​	***\*事务的持久性是通过redo\**** ***\*log\*******\*实现的；\****

​	***\*事务的隔离性是通过读写锁+MVCC实现的；\****

​	***\*事务的一致性是通过原子性，持久性，隔离性实现的。\****

### 原子性（Atomicity）

​	整个事务中所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。

​	原子性实现：undo log

分布式事务中通过两阶段方式（要么成功要么失败）实现原子性。

注：之所以原子性是undo log实现，就是因为undo log记录的是历史的信息，可以通过它实现恢复，MVCC就是利用这种快照链表实现的。

 

### 一致性（Consistency）

​	一个事务可以封装状态改变（除非它是一个只读的）。事务必须始终保持系统处于一致

的状态，不管在任何给定的时间并发事务有多少。

​	一致性状态是指：

1、 系统的状态满足数据的完整性约束（主码，参照完整性，check约束等）；

2、 系统的状态反应数据库本应描述的显式世界的真实状态，比如转账前后两个账户的金额总和应该保持不变。

注：分布式事务中分为***\*最终一致性\****和***\*强一致性\****（需要使用一致性算法实现）。

 

可以说，一致性是事务追求的最终目标：前面提到的原子性、持久性和隔离性，都是为了保证数据库状态的一致性。此外，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。

实现一致性的措施包括：

1、保证原子性、持久性和隔离性，如果这些特性无法保证，事务的一致性也无法保证；

2、数据库本身提供保障，例如不允许向整形列插入字符串值、字符串长度不能超过列的限制等；

3、应用层面进行保障，例如如果转账操作只扣除转账者的余额，而没有增加接收者的余额，无论数据库实现的多么完美，也无法保证状态的一致。

 

实现

在事务的四个特点中，**一致性是事务的根本追求**，而在某些情况下会对一致性造成破坏：

1、 事务的并发执行

2、 事务故障或系统故障

数据库系统通过***\*并发控制技术和日志恢复技术\****来避免这种情况的发生：

1、 **并发控制技术**（***\*锁+MVCC\****）保证了事务的***\*隔离性\****，使数据库的一致性状态不会因为并发执行的操作被破坏；

2、 **日志恢复技术**保证了事务的***\*原子性\****，使一致性状态不会因事务或系统故障被破坏。同时使已提交的数据库的修改不会因系统崩溃而丢失，保证了事务的持久性。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDCE8.tmp.jpg) 

**实现机制：原子性，隔离性，持久性**

​	也就是说：如果事务并发多个，系统也必须如同串行事务一样操作。其主要特征是保护性和不变形。以转账案例为例，假设有5个账户，每个账户的余额是100元，那么5个账户总额是500元，如果在这5个账户之间发生多个转账，无论并发多少个，比如在A与B账户之间转账5元，在C与D账户之间转账10元，在B与E之间转账15元，5个账户总额也应该是500元，这就是保护性和不变形。

 

​	我们使用的数据库由两个文件组成，一个数据库文件和一个日志文件，通常情况下，日志文件都要比数据库文件大很多。数据库进行任何写入操作的时候都是先写日志的，我们在执行事务的时候数据库首先会记录下这个事务的redo操作日志，然后才开始真正操作数据库，在操作之前首先会把日志文件写入磁盘，那么当突然断电的时候，即使操作没有完成，在重新启动数据库时，数据库会根据当前数据的情况进行undo回滚或者是redo前滚，这样就保证了数据的强一致性。

#### 单机数据一致性

MySQL作为一个可插拔的数据库系统，支持插件式的存储引擎，在设计上分为Server层和Storage Engine层。

在Server层，MySQL以events的形式记录数据库各种操作的Binlog二进制日志，其基本核心作用有：复制和备份。

除此之外，我们结合多样化的业务场景需求，基于Binlog的特性构建了强大的MySQL生态，如：DTS、单元化、异构系统之间实时同步等等，Binlog早已成为MySQL生态中不可缺少的模块。

而在Storage Engine层，InnoDB作为比较通用的存储引擎，其在高可用和高性能两方面作了较好的平衡，早已经成为使用MySQL的首选。

和大多数关系型数据库一样，InnoDB采用WAL技术，即InnoDB Redo Log记录了对数据文件的***\*物理更改\****，并保证总是日志先行，在持久化数据文件前，保证之前的redo日志已经写到磁盘。

***\*Binlog和InnoDB Redo Log是否落盘将直接影响实例在异常宕机后数据能恢复到什么程度\****。InnoDB提供了相应的参数来控制事务提交时，写日志的方式和策略，例如：

innodb_flush_method:控制innodb数据文件、日志文件的打开和刷写的方式，建议取值：fsync、O_DIRECT。

innodb_flush_log_at_trx_commit:控制每次事务提交时，重做日志的写盘和落盘策略，可取值：0，1，2。

当innodb_flush_log_at_trx_commit=1时，每次事务提交，日志写到InnoDB Log Buffer后，会等待Log Buffer中的日志写到Innodb日志文件并刷新到磁盘上才返回成功。

sync_binlog：控制每次事务提交时，Binlog日志多久刷新到磁盘上，可取值：0或者n(N为正整数)。

不同取值会影响MySQL的性能和异常crash后数据能恢复的程度。当sync_binlog=1时，MySQL每次事务提交都会将binlog_cache中的数据强制写入磁盘。

innodb_doublewrite：控制是否打开double writer功能，取值ON或者OFF。

当Innodb的page size默认16K，磁盘单次写的page大小通常为4K或者远小于Innodb的page大小时，发生了系统断电/os crash ，刚好只有一部分写是成功的，则会遇到partial page write问题，从而可能导致crash后由于部分写失败的page影响数据的恢复。InnoDB为此提供了Double Writer技术来避免partial page write的发生。

innodb_support_xa:控制是否开启InnoDB的两阶段事务提交.默认情况下，innodb_support_xa=true，支持xa两段式事务提交。

以上参数不同的取值分别影响着MySQL异常crash后数据能恢复的程度和写入性能，实际使用过程中，需要结合业务的特性和实际需求，来设置合理的配置。比如:

MySQL单实例，Binlog关闭场景：

innodb_flush_log_at_trx_commit=1，innodb_doublewrite=ON时，能够保证不论是MySQL Crash 还是OS Crash 或者是主机断电重启都不会丢失数据。

MySQL单实例，Binlog开启场景：

默认innodb_support_xa=ON，开启binlog后事务提交流程会变成两阶段提交，这里的两阶段提交并不涉及分布式事务，mysql把它称之为内部xa事务。

 当innodb_flush_log_at_trx_commit=1，sync_binlog=1，innodb_doublewrite=ON，,innodb_support_xa=ON时，同样能够保证不论是MySQL Crash 还是OS Crash 或者是主机断电重启都不会丢失数据。

但是，当由于主机硬件故障等原因导致主机完全无法启动时，则MySQL单实例面临着单点故障导致数据丢失的风险，故MySQL单实例通常不适用于生产环境。

 

#### 集群数据一致性

MySQL集群通常指MySQL的主从复制架构。

通常使用MySQL主从复制来解决MySQL的单点故障问题，其通过逻辑复制的方式把主库的变更同步到从库，主备之间无法保证严格一致的模式，于是，MySQL的主从复制带来了主从“数据一致性”的问题。MySQL的复制分为：异步复制、半同步复制、全同步复制。

##### 异步复制

主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从库上，如果此时，强行将从提升为主，可能导致“数据不一致”。早期MySQL仅仅支持异步复制。

##### 半同步复制

MySQL在5.5中引入了半同步复制，主库在应答客户端提交的事务前需要保证至少一个从库接收并写到relay log中，半同步复制通过rpl_semi_sync_master_wait_point参数来控制master在哪个环节接收 slave ack，master 接收到 ack 后返回状态给客户端，此参数一共有两个选项 AFTER_SYNC & AFTER_COMMIT。

配置为WAIT_AFTER_COMMIT

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDCE9.tmp.jpg) 

rpl_semi_sync_master_wait_point为WAIT_AFTER_COMMIT时，commitTrx的调用在engine层commit之后，如上图所示。

即在等待Slave ACK时候，虽然没有返回当前客户端，但事务已经提交，其他客户端会读取到已提交事务。如果Slave端还没有读到该事务的events，同时主库发生了crash，然后切换到备库。

那么之前读到的事务就不见了，出现了数据不一致的问题：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDCF9.tmp.jpg) 

如果主库永远启动不了，那么实际上在主库已经成功提交的事务，在从库上是找不到的，也就是数据丢失了。

 

配置为WAIT_AFTER_SYNC

MySQL官方针对上述问题，在5.7.2引入了Loss-less Semi-Synchronous，在调用binlog sync之后，engine层commit之前等待Slave ACK。这样只有在确认Slave收到事务events后，事务才会提交。

如下图所示：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDCFA.tmp.jpg) 

在after_sync模式下解决了after_commit模式带来的数据不一致的问题，因为主库没有提交事务。

但也会有个问题，当主库在binlog flush并且binlog同步到了备库之后，binlog sync之前发生了abort，那么很明显这个事务在主库上是未提交成功的（由于abort之前binlog未sync完成，主库恢复后事务会被回滚掉），但由于从库已经收到了这些Binlog，并且执行成功，相当于在从库上多出了数据，从而可能造成“数据不一致”。

此外，MySQL半同步复制架构中，主库在等待备库ack时候，如果超时会退化为异步后，也可能导致“数据不一致”。

### 隔离性（Isolation）

​	隔离状态执行事务，使他们好像是系统在给定时间内执行的唯一操作。如果有两个事务，运行在相同的时间内，执行相同的功能，事务的隔离性将确保每一个事务在系统中认为只有该事务在使用系统。这种属性有时称为串行化，为了防止事务操作间的混淆，必须串行化或者序列化请求，使得在同一时间仅有一个请求用于同一数据。	

​	**实现机制：读写锁+MVCC****（****不加锁****）**

**注：事务隔离级别其实就是锁和MVCC的具体体现。**

 

**怎样实现隔离性呢？**

原则上无非是两种类型的锁：

一种是悲观锁，即当前事务将所有涉及操作的对象加锁，操作完成后释放给其它对象使用。

一种是乐观锁，即不同的事务可以同时看到同一对象（一般是数据行）的不同历史版本。如果有两个事务同时修改了同一数据行，那么在较晚的事务提交时进行冲突检测。可见在数据库事务中，一致性是基础和目标，其他属性都是为一致性服务的。

注：在GoldenDB分布式数据库中实现了乐观锁和悲观锁的控制，乐观锁包括proxy和DB两个层次，对于Porxy计算节点而言，就是通过对update/delete拆分的select语句进行改造，使用lock in share mode和select from gtid not in () and gtid<max_gtid实现，并且失败重试，对于DB而言，即MVCC机制，悲观锁即SELECT FOR UPDATE。

 

InnoDB有两种不同的SELECT，即普通SELECT和锁定读SELECT。锁定读SELECT 又有两种，即SELECT ... FOR SHARE 和 SELECT ... FOR UPDATE；锁定读SELECT 之外的则是 普通SELECT。

不同的SELECT是否都需要加锁呢？

**1、普通SELECT 时使用一致性非锁定读（即MVCC），不加锁；**

**2、锁定读SELECT使用锁定读，加锁；**

3、此外，DML(INSERT/UPDATE/DELETE)时，需要先查询表中的记录，此时也使用锁定读，加锁；

FOR SHARE 语法是 MySQL 8.0 时加入的，FOR SHARE 和 LOCK IN SHARE MODE 是等价的，但，FOR SHARE 用于替代 LOCK IN SHARE MODE，不过，为了向后兼容，LOCK IN SHARE MODE依然可用。

 

#### 一致性非锁定读(consistent nonlocking read)

InnoDB采用多版本并发控制(MVCC, multiversion concurrency control)来增加读操作的并发性。MVCC是指，InnoDB使用基于时间点的快照来获取查询结果，读取时在访问的表上不设置任何锁，因此，在事务T1读取的同一时刻，事务T2可以自由的修改事务T1所读取的数据。这种读操作被称为一致性非锁定读。这里的读操作就是普通SELECT。

隔离级别为RU和Serializable时不需要MVCC，因此，只有RC和RR时，才存在MVCC，才存在一致性非锁定读。

一致性非锁定读在两种隔离级别RC和RR时，是否有什么不同呢？是的，两种隔离级别下，拍得快照的时间点不同

1、RC时，同一个事务内的每一个一致性读总是设置和读取它自己的最新快照。也就是说，每次读取时，都再重新拍得一个最新的快照（所以，RC时总是可以读取到最新提交的数据）。

2、RR时，同一个事务内的所有的一致性读 总是读取同一个快照，此快照是执行该事务的第一个一致性读时所拍得的。

 

#### 锁定读(locking read)

如果你先查询数据，然后，在同一个事务内 插入/更新 相关数据，普通的SELECT语句是不能给你足够的保护的。其他事务可以 更新/删除 你刚刚查出的数据行。InnoDB提供两种锁定读，即：SELECT ... FOR SHARE和 SELECT ... FOR UPDATE。它俩都能提供额外的安全性。

这两种锁定读在搜索时所遇到的（注意：不是最终结果集中的）每一条索引记录(index record)上设置排它锁或共享锁。此外，如果当前隔离级别是RR，它还会在每个索引记录前面的间隙上设置排它的或共享的gap lock（排它的和共享的gap lock没有任何区别，二者等价）。

### 持久性（Durability）

​	在事务完成以后，该事务对数据库所作的变更会持久地保存在数据库之中，并不会被回滚。

​	**实现机制：redo** **log****重做日志**

 

​	由于一项操作通常会包含许多子操作，而这些子操作可能会因为硬件的损坏或其他因素产生问题，要正确实现ACID并不容易。ACID建议数据库将所有需要更新以及修改的资料一次操作完毕，但实际上并不可行。

​	目前主要有两种方式实现ACID：第一种是Write aheadlogging，也就是日志式的方式（现代数据库均基于这种方式），第二种是shadow paging。

​	相对于WAL（write ahead logging）技术，shadow paging技术实现起来比较简单，消除了写日志记录的开销，恢复的速度也快（不需要redo和undo）。Shadow paging的缺点就是事务提交时要输出多个块，这使得提交的开销很大，而且以块为单位，很难应用到允许多个事务并发执行的情况，这是它的致命缺点。

​	WAL的中心思想是对数据文件的修改（它们是表和索引的载体）必须是只能发生在这些修改记录了日志之后，也就是说，在日志记录冲刷到永久存储器之后。如果我们遵循这个过程，那么我们就不需要在每次事务提交的时候，都把数据页冲刷到磁盘，因为我们知道在出现崩溃的情况下，我们可以用日志来恢复数据库：任何尚未附加到数据页的记录都将先从日志记录中重做（这叫向前滚动恢复，也叫作redo），然后那些未提交的事务做的修改将被从数据页中删除（这叫向后滚动恢复undo）。

## 分类

### 扁平事务

扁平事务（Flat Transaction）是事务类型中最简单的一种，但是在实际生产环境中，这可能是使用最频繁的事务。在扁平事务中，所有操作都处于同一层次，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束，其间的操作是原子的，要么都执行，要么都回滚。因此，扁平事务是应用程序成为原子操作的基本组成模块。

扁平事务的主要限制是不能提交或者回滚事务的某一部分，或分几个步骤提交。因此就出现了带有保存点的扁平事务。

### 带有保存点的扁平事务

带有保存点的扁平事务（Flat Transaction with Savepoint），除了支持扁平事务支持的操作外，允许在事务执行过程中回滚到同一事务中较早的一个状态。这是因为某些事物可能在执行过程中出现的错误并不会导致所有的操作都无效，放弃整个事务不合乎要求，开销也太大。保存点（savepoint）用来通知系统应该记住事务当前的状态，以便当之后发生错误时，事务能回到状态点当前的状态。

### 链事务

链事务（Chained Transaction）可视为保存点模式的一种变种。带有保存点的扁平事务，当发生系统崩溃时，所有的保存点都将消失，因为其保存点是易失的（volatile），而非持久的（persistent）。这意味着当进行恢复时，事务需要从开始处重新执行，而不能从最近的一个保存点继续执行。

链事务的思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。注意，提交事务操作和开始下一个事务操作将合并为一个原子操作。这意味着下一个事务看到上一个事务的结果，就好像在一个事务中进行的一样。

链事务与带有保存点的扁平事务不同的是，带有保存点的扁平事务能够回滚到任意正确的保存点。而链事务中的回滚仅限于当前事务，即只能恢复到最近一个的保存点。对于锁的处理，二者也不相同。链事务在执行COMMIT后即释放房钱事务所持有的锁，而带有保存点的扁平事务不影响迄今为止所持有的锁。

### 嵌套事务

嵌套事务（Nested Transaction）是一个层次结构框架。由一个顶层事务（top-level transaction）控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务（subtransaction），其控制每一个局部的变换。

### 分布式事务

分布式事务（Distributed Transaction）通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。

 

除了上述分类之外，还可以分为刚性事务和柔性事务。

刚性事务（如单一数据库事务）完全遵循 ACID 规范，即数据库事务的四大基本特性。刚性事务也能够以分布式CAP理论中的CP事务来作为定义。

在电商领域等互联网场景下，传统的事务在数据库性能和处理能力上都遇到了瓶颈。因此，柔性事务被提了出来，柔性事务基于分布式 CAP 理论以及延伸出来的 BASE 理论，相较于数据库事务这一类完全遵循 ACID 的刚性事务来说，柔性事务保证的是 “基本可用，最终一致”。

 

## 使用

### 开启事务

开启事务：start transaction

### 回滚事务

回滚事务：rollback

（开启事务后roolback和commit选择其一）

### 提交事务

提交事务：commit

（所有语句全部执行完，没有发生异常，提交事务，更新到数据库中）

#### 自动提交

​	通过指令SHOW VARIABLES LIKE ‘autocommit’；查看是否开启事务自动提交，默认是开启的。

​	显式地使用START TRANSACTION或者BEGIN语句开启一个事务，这样在本次事务提交或者回滚前会暂时关闭自动提交的功能。

​	把系统变量autocommit设置为OFF，即SET autocommit=OFF，这样写入的多条语句就算是属于一个事务了，直到我们显式地写出COMMIT语句才把该事务提交，或者显式的写出ROLLBACK语句把这个事务回滚。

 

MySQL auto-commit带来的问题：

https://m.linuxidc.com/Linux/2018-12/155810.htm

#### 隐式提交

​	当我们使用START TRANSACTION或者BEGIN语句开启一个事务，或者把系统变量autocommit的值设置为OFF时，事务就不会进行自动提交，但是如果我们输入了某些语句之后就会悄悄地提交，就像是输入了COMMIT语句一样，这种因为某些特殊的语句而导致事务提交的情况称为隐式提交，这些会导致事务隐式提交的语句包括：

1、 定义或修改数据库对象的DDL。所谓的数据库对象，指的就是数据库、表、视图、存储过程等这些东西，当我们使用CREATE、ALTER、DROP等语句去修改这些所谓的数据库对象时，就会隐式的提交前面语句所属于的事务；

2、 隐式使用或修改数据库中的表：当我们使用ALTER USER、CREATE USER、DROP USER、GRANT、RENAME USER、SET PASSWORD等语句时也会隐式的提交前边语句所属于的事务；

3、 事务控制或关于锁定的语句：

当我们在一个事务还没有提交或者回滚时就又使用START TRANSACTION或者BEGIN语句开启了另一个事务时，就会隐式的提交上一个事务。

或者当前的autocommit系统变量的值为OFF，我们手动把它调为ON时，也会隐式的提交前面语句所属的事务。

或者使用LOCK TABLES、UNLOCK TABLES等关于锁定的语句也会隐式的提交前面语句所属的事务。

4、 加载数据的语句：比如我们使用LOAD DATA语句来批量往数据库中导入数据时，也会隐式的提交前面语句所属的事务。

5、 其他一些语句：使用ANALYSE TABLE、CACHE INDEX、CHECK TABLE、FLUSH、LOAD INDEXINTO CACHE、OPTIMIZE TABLE、REPAIR TABLE、RESET等语句也会隐式的提交前面语句所属的事务。

常用的select、insert、update和delete命令，都不会强制提交事务。

### 保存点

​	SAVEPOINT 保存点名称;

​	ROLLBACK [WORK] TO [SAVEPOINT] 保存点名称;

​	RELEASE SAVEPOINT 保存点名称;

## 隔离级别

MySQL是一个服务器/客户端架构的软件，对于同一个服务器来说，可以有若干个客户端与之连接，每个客户端与服务器连接上之后，就可以称之为一个会话（Session）。我们可以同时在不同的会话里输入各种语句，这些语句可以作为事务的一部分进行处理。不同的会话可以同时发送请求，也就是说服务器可能同时在处理多个事务，这样子就会导致不同的事务可能同时访问到相同的记录。我们前边说过事务有一个特性称之为隔离性，理论上在某个事务对某个数据进行访问时，其他事务应该进行排队，当该事务提交之后，其他事务才可以继续访问这个数据。但是这样子的话对性能影响太大，所以数据库设计者提出了各种隔离级别，来最大限度的提升系统并发处理事务的能力，但是这也是以牺牲一定的隔离性来达到的。

参考：

https://blog.csdn.net/weixin_39651041/article/details/79980202

 

### 更新丢失

两个事务同时更新一行数据，一个事务对数据的更新把另一个事务对数据的更新覆盖了。这是因为系统没有执行任何锁操作，因此并发并没有隔离开来。

解决方法：排它锁实现（隔离级别：读未提交UR）

### 脏读

脏读：当前事务(A)中可以读到其他事务(B)未提交的数据（脏数据），这种现象是脏读。举例如下（以账户余额表为例）：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDCFB.tmp.jpg) 

这种是相当危险的，因为很可能所有的操作都被回滚（即事务1读取到事务2未提交的数据并且使用了这个脏数据，但是事务2实际上回滚了这个数据，事务1的数据就是非法的）。

### 不可重复读

不可重复读：在事务A中先后两次读取同一个数据，两次读取的结果不一样，这种现象称为不可重复读。脏读与不可重复读的区别在于：前者读到的是其他事务未提交的数据，后者读到的是其他事务已提交的数据。举例如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD0C.tmp.jpg) 

不可重复读（Non-repeatable Reads）：一个事务对同一行数据重复读取两次，但是却得到不同的结果。包括以下两种情况：

1、虚读：事务T1读取某一数据后，事务T2对其做了***\*修改\****，当事务T1再次读取该数据时得到与前一次不同的值；

2、幻读：事务在操作过程中进行两次查询，第二次查询的结果包含了第一次查询中未出现的数据或者缺少了第一次查询中出现的数据。这是因为在两次查询过程中有另一个事务***\*插入数据\****造成的。

 

### 幻读

#### 概述

幻读是指某个事务读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前事务再次读取该范围内的记录时就会产生幻行。

 

举一个例子，user表中id是主键索引，T1是主事务：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD0D.tmp.jpg) 

T2是干扰事务：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD0E.tmp.jpg) 

Step1：T1开始，并检查user表中是否有id=1的记录。

Step2：T2开始，插入id为1的记录且成功执行。

Step3：T1查到没有id=1的记录就开始插入id=1的记录，但是失败了（主键冲突）。

Step4：T1不能接受现实又查了一遍是否存在id=1的记录，发现的确没有，彻底崩溃...

从第四步我们可以看出，在主事务执行commit之前，不管再查多少次，都无法获取到id=1的这条记录，因为此时它已经产生幻读了。

 

幻读：在事务A中按照某个条件先后两次查询数据库，两次查询结果的条数不同，这种现象称为幻读。不可重复读与幻读的区别可以通俗的理解为：前者是数据变了，后者是数据的行数变了。举例如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD0F.tmp.jpg) 

 

#### 解决方案

要解决幻读的问题有两种方案，一种是采用SERIALIZABLE数据隔离级别，但是这种方案会强制把所有事务排序，来达到事务之间不互相冲突产生幻读的问题，当事务并发高的时候，很容易产生大量***\*超时\****和***\*锁竞争\****的情况，所以一般不太建议采用这种方案。另一种方案是采用在RR数据隔离级别下，手动给select操作加上x锁（排它锁）或者s锁（共享锁）。

 

### 分类

#### UR：Read uncommitted

读未提交：***\*只处理更新丢失\****。如果一个事务已经开始写数据，则不允许其他事务同时进行写操作，但是允许其他事务读取该行数据（允许其他事务读那么就会产生脏读）。可以通过***\*排它写锁\****实现。

查询时，读取的数据中允许含有脏数据，不检查来自各存储节点的数据是否活跃，即***\*不检查来自各个存储节点的数据是否来自同一版本或同一时刻的副本数据\****（脏读的原因在于不检查数据是否来自同一个版本）。

在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。

注：读未提交存在**脏读**问题。

 

#### CR：Read commited强一致性读/读已提交

读已提交：处理更新丢失和脏读。读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。可以通过***\*“瞬间共享读锁”和“排它写锁”\****实现。

查询时，读取的数据中不允许包含脏数据，检查来自各存储节点的数据不能为活跃状态，即***\*检查来自各存储节点的数据必须为同一版本或同一时刻的副本数据\****。

这是大多数数据库系统的默认隔离级别（但是不是MySQL默认隔离级别）。它满足了隔离的简单定义：一个事务只能看到已经提交事务所做的改变。这种隔离级别不支持所谓的不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理期间可能会有新的commit，所以同一select可能返回不同结果（即隔离性不好）。

注：已提交读存在**不可重复读**和**幻读**问题。

**通过行锁，MVCC的版本链和ReadView解决。**

 

#### RR：Repetable read（MySQL默认隔离级别）

可重复读：处理更新丢失、脏读和不可重复读。读取数据的事务将会禁止写事务，但是允许读事务，写事务则禁止任何其他事务。可以通过***\*“共享读锁”和“排它写锁”\****实现。

 

这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读（Phantom Read）。简单地说，幻读指当用户读取**某一范围**的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影”行。

**Inno****DB****和Falcon存储引擎通过多版本并发（MVCC，Multiversion** **Consurrency** **Control）机制解决了该问题**。

注：***\*不可重复读是update操作造成另外一个事务提交前后查询结果不一致，幻读是insert操作造成另外一个事务前后查询结果不一致\****（一般是范围查找而不是等值查找，比如查找>1的数据，接着插入一条数据，这样就会多出一条记录），二者都是事务隔离性不够好造成的。（幻读的危害不仅仅是在于另一个事务查询的时候出现错误结果，而且在另一个事务执行INSERT的时候可能会与另一个事务数据冲突）

通过**MVCC的版本链、ReadView**以及读写锁（**间隙锁**）实现。

 

上述是标准SQL规定的隔离级别及存在的问题，但是，**在MySQL中可重复读已经解决了幻读！**

#### Serializable

这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

| 隔离级别                     | 脏读 | 不可重复读 | 幻读 |
| ---------------------------- | ---- | ---------- | ---- |
| 读未提交（Read uncommitted） | √    | √          | √    |
| 读已提交（Read committed）   | ×    | √          | √    |
| 可重复读（Readeatable read） | ×    | ×          | √    |
| 可串行化（Serializable）     | ×    | ×          | ×    |

​	**SW：单节点写**

​	不考虑分布式事务下对部分已提交事务数据的修改，即不检查修改的数据是否活跃。下面的两种情况使用SW：

1、 修改的数据不会在两个及以上的事务中同时修改；

2、 涉及本数据的所有事务都只会修改单条记录。

**CW** **：强一致性写**

需要考虑分布式事务下的对部分已提交事务的数据的修改，需要检查修改的数据是都处于活跃状态

### 2PL

2PL，两阶段加锁协议:主要用于单机事务中的一致性与隔离性。

2PC，两阶段提交协议:主要用于分布式事务。

#### 概述

在一个事务里面，分为加锁(lock)阶段和解锁(unlock)阶段，也即所有的lock操作都在unlock操作之前，如下图所示:

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD20.tmp.jpg) 

引入2PL是为了保证事务的隔离性，即多个事务在并发的情况下等同于串行的执行。 在数学上证明了如下的封锁定理:

如果事务是良构的且是两阶段的，那么任何一个合法的调度都是隔离的。

#### S2PL

在实际情况下，SQL是千变万化、条数不定的,数据库很难在事务中判定什么是加锁阶段，什么是解锁阶段。于是引入了S2PL(Strict-2PL),即:

在事务中只有提交(commit)或者回滚(rollback)时才是解锁阶段，其余时间为加锁阶段。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD21.tmp.jpg) 

 

### 查看事务隔离级别

select @@global.tx_isolation.@@tx_isolations;

### 设置事务隔离级别

全局的：set global/session transaction isolation level read commited;

当前会话：select @@tx_isolation;

 

### 事务并发操作

1、 UR脏读

问题：一个事务可以读取另一个未提交事务的数据 

解决方法：Read Commited 读提交

2、 不可重复读

问题：一个事务开启的时候另一个事务可以修改操作，导致读取结果不一致

解决方法：Repeated read

3、 可重复读

4、 幻读

问题：一个事务开启的时候另一个事务insert插入数据，导致事务提交前后读取的结果不一致

解决方法：Serialized

5、 串行化（Serializable）SR

这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。

### 总结

SQL标准中定义了四种隔离级别，并规定了每种隔离级别下上述几个问题是否存在。一般来说，隔离级别越低，系统开销越低，可支持的并发越高，但隔离性也越差。隔离级别与读问题的关系如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD22.tmp.jpg) 

在实际应用中，读未提交在并发时会导致很多问题，而性能相对于其他隔离级别提高却很有限，因此使用较少。可串行化强制事务串行，并发效率很低，只有当对数据一致性要求极高且可以接受没有并发时使用，因此使用也较少。因此在大多数数据库系统中，默认的隔离级别是读已提交(如Oracle)或可重复读（后文简称RR）。

 

​	这四种隔离级别是SQL的标准定义，不同的数据库会有不同的实现，特别需要注意的是“MySQL在REPEATABLE READ隔离级别下，是可以禁止幻读问题的发生的”。

## 实现

​	原子性、一致性、持久性通过数据库的redo log和undo log来完成。redo log称为重做日志，用来保证事务的原子性和持久性，undo log用来保证事务的一致性。

redo恢复提交事务修改的页操作，而undo回滚行记录到某个特性版本。因此，二者记录的内容不同，redo通常是物理日志，记录的是页的物理修改操作。undo是逻辑日志，根据每行记录进行记录。

### 回滚日志/undo

undo log，undo日志用于存放数据被修改前的值，如果修改出现异常，可以使用undo日志来实现回滚操作，保证事务的一致性。另外InnoDB MVCC事务特性也是基于undo日志实现的。undo日志分为insert undo log（insert语句产生的日志，事务提交后直接删除）和update undo log（delete和update语句产生的日志，由于该undo log可能提供MVVC机制使用，所以不能再事务提交时删除）。

参考：https://www.cnblogs.com/f-ck-need-u/p/9010872.html

#### 概述

​	**undo** **log****回滚日志****是为了实现事务的****原子性**，在MySQL数据库InnoDB存储引擎中，**采用****u****ndo log来实现多版本并发控制（简称 MVCC）**。

​	在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为undo log，redo log相反是对新数据的备份），然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用undo log中的备份将数据恢复到事务开始之前的状态。除了可以保证事务的原子性，undo log也可以用来辅助完成事务的持久化。

​	因此，undo log有两个作用：**提供回滚****和****多个行版本控制(MVCC)**。

 

​	注意：undo log和redo log记录物理日志不一样，它是逻辑日志（不是直接可读）。可以理解为（只是便于理解，实际上不是这种可读性的sql）：

​	当delete一条记录时，undo log中会记录一条对应的insert记录

​	当insert一条记录时，undo log中会记录一条对应的delete记录

​	当update一条记录时，undo log中会记录一条对应相反的update记录

undo log也会产生redo log，因为undo log也要实现持久性保护。

#### 存储

InnoDB存储引擎对undo的管理采用**段**的方式。rollback segment称为回滚段，每个回滚段中有1024个undo log segment。

undo log默认存放在***\*共享表空间\****中。

[root@learn data]# ll /mydata/data/ib*

-rw-rw---- 1 mysql mysql 79691776 Mar 31 01:42 ***\**/mydata/data/ibdata1\**\***

-rw-rw---- 1 mysql mysql 50331648 Mar 31 01:42 /mydata/data/ib_logfile0

-rw-rw---- 1 mysql mysql 50331648 Mar 31 01:42 /mydata/data/ib_logfile1

如果开启了 ***\*innodb_file_per_table\****，将放在每个表的.ibd文件中。

在MySQL5.6中，undo的存放位置还可以通过变量***\*innodb_undo_directory\****来自定义存放目录，默认值为"."表示datadir。

默认rollback segment全部写在一个文件中，但可以通过设置变量***\*innodb_undo_tablespaces\****平均分配到多少个文件中。该变量默认值为0，即全部写入一个表空间文件。该变量为静态变量，只能在数据库示例停止状态下修改，如写入配置文件或启动时带上对应参数。但是innodb存储引擎在启动过程中提示，不建议修改为非0的值，如下：

***\*2017\****-***\*03\****-***\*31\**** ***\*13\****:***\*16\****:***\*00\**** 7f665bfab720 InnoDB: Expected to open ***\*3\**** undo tablespaces but was able

***\*2017\****-***\*03\****-***\*31\**** ***\*13\****:***\*16\****:***\*00\**** 7f665bfab720 InnoDB: to find only ***\*0\**** undo tablespaces.

***\*2017\****-***\*03\****-***\*31\**** ***\*13\****:***\*16\****:***\*00\**** 7f665bfab720 InnoDB: Set the innodb_undo_tablespaces parameter to the

***\*2017\****-***\*03\****-***\*31\**** ***\*13\****:***\*16\****:***\*00\**** 7f665bfab720 InnoDB: correct value and retry. ***\**Suggested value is 0\**\***

 

#### 变量

mysql> show variables like "%undo%";

+-------------------------+-------+

| Variable_name      | Value |

+-------------------------+-------+

| innodb_undo_directory  | .   |

| innodb_undo_logs     | ***\*128\****  |

| innodb_undo_tablespaces | ***\*0\****   |

+-------------------------+-------+

 

#### delete**/update**内部实现

当事务提交的时候，innodb不会立即删除undo log，因为后续还可能会用到undo log，如隔离级别为repeatable read时，事务读取的都是开启事务时的最新提交行版本，***\*只要该事务不结束，该行版本就不能删除，即undo log不能删除\****。

但是***\*在事务提交的时候，会将该事务对应的undo log放入到删除列表中，未来通过purge来删除\****。并且提交事务时，还会判断undo log分配的页是否可以重用，如果可以重用，则会分配给后面来的事务，避免为每个独立的事务分配独立的undo log页而浪费存储空间和性能。

 

undo log属于逻辑日志，它记录的是sql执行相关的信息。当发生回滚时，InnoDB会根据undo log的内容做与之前相反的工作：对于每个insert，回滚时会执行delete；对于每个delete，回滚时会执行insert；对于每个update，回滚时会执行一个相反的update，把数据改回去。

通过undo log记录delete和update操作的结果发现：

1、insert操作无需分析，就是插入行而已；

2、delete操作实际上不会直接删除，而是将delete对象打上delete flag，标记为删除，最终的删除操作是purge线程完成的；

3、update分为两种情况：update的列是否是主键列。

如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。

如果是主键列，update分两部执行：先删除该行，再插入一行目标行。

当事务执行update时，其生成的undo log中会包含被修改行的主键(以便知道修改了哪些行)、修改了哪些列、这些列在修改前后的值等信息，回滚时便可以使用这些信息将数据还原到update之前的状态。

### 重做日志/redo

redo log，当数据库对数据做修改的时候，需要把数据页从磁盘读到buffer pool中，然后在buffer pool中进行修改，那么这个时候buffer pool中的数据页就与磁盘上的数据页内容不一致，称buffer pool的数据页为dirty page脏数据，如果这个时候发生非正常的DB服务重启，那么这些数据还没在内存，并没有同步到磁盘文件中（注意，同步到磁盘文件是个随机IO），也就是会发生数据丢失，如果这个时候，能够在有一个文件，当buffer pool中的data page变更结束后，把相应修改记录记录到这个文件（注意，记录日志是顺序IO），那么当DB服务发生crash的情况，恢复DB的时候，也可以根据这个文件的记录内容，重新应用到磁盘文件，数据保持一致。

#### 概述

​	和undo log相反，**redo** **log****重做日志****记录的是****新数据的备份**。**在事务提交前，只要将redo** **log****持久化即可，不需要将数据持久化**。当系统崩溃时，虽然数据没有持久化，但是redo log已经持久化。系统可以根据redo log的内容，将所有数据恢复到最新的状态。

redo log包括两部分：一是**内存中的日志缓冲(redo log buffer)**，该部分日志是易失性的；二是**磁盘上的重做日志文件(redo log file)**，该部分日志是持久的。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD32.tmp.jpg) 

MySQL支持用户自定义在commit时如何将log buffer中的日志刷log file中。这种控制通过变量***\*innodb_flush_log_at_trx_commit\****的值来决定。该变量有3种值：0、1、2，默认为1。但注意，这个变量只是控制commit动作是否刷新log buffer到磁盘。

当设置为1的时候，事务每次提交都会将log buffer中的日志写入os buffer并调用fsync()刷到log file on disk中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。

当设置为0的时候，事务提交时不会将log buffer中日志写入到os buffer，而是每秒写入os buffer并调用fsync()写入到log file on disk中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。

当设置为2的时候，每次提交都仅写入到os buffer，然后是每秒调用fsync()将os buffer中的日志写入到log file on disk。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD33.tmp.jpg) 

##### Buffer pool

InnoDB作为MySQL的存储引擎，数据是存放在磁盘中的，但如果每次读写数据都需要磁盘IO，效率会很低。为此，InnoDB提供了缓存(Buffer Pool)，Buffer Pool中包含了磁盘中部分数据页的映射，作为访问数据库的缓冲：当从数据库读取数据时，会首先从Buffer Pool中读取，如果Buffer Pool中没有，则从磁盘读取后放入Buffer Pool；当向数据库写入数据时，会首先写入Buffer Pool，Buffer Pool中修改的数据会定期刷新到磁盘中（这一过程称为刷脏）。

Buffer Pool的使用大大提高了读写数据的效率，但是也带了新的问题：如果MySQL宕机，而此时Buffer Pool中修改的数据还没有刷新到磁盘，就会导致数据的丢失，事务的持久性无法保证。

于是，redo log被引入来解决这个问题：当数据修改时，除了修改Buffer Pool中的数据，还会在redo log记录这次操作；当事务提交时，会调用fsync接口对redo log进行刷盘。如果MySQL宕机，重启时可以读取redo log中的数据，对数据库进行恢复。redo log采用的是WAL（Write-ahead logging，预写式日志），所有修改先写入日志，再更新到Buffer Pool，保证了数据不会因MySQL宕机而丢失，从而满足了持久性要求。

 

既然redo log也需要在事务提交时将日志写入磁盘，为什么它比直接将Buffer Pool中修改的数据写入磁盘(即刷脏)要快呢？主要有以下两方面的原因：

（1）刷脏是随机IO，因为每次修改的数据位置随机，但写redo log是追加操作，属于顺序IO。

（2）刷脏是以数据页（Page）为单位的，MySQL默认页大小是16KB，一个Page上一个小修改都要整页写入；而redo log中只包含真正需要写入的部分，无效IO大大减少。

##### redo与binlog

在MySQL中还存在binlog(二进制日志)也可以记录写操作并用于数据的恢复，但二者是有着根本的不同的：

（1）作用不同：redo log是用于crash recovery的，保证MySQL宕机也不会影响持久性；binlog是用于point-in-time recovery的，保证服务器可以基于时间点恢复数据，此外binlog还用于主从复制。

（2）层次不同：redo log是InnoDB存储引擎实现的，而binlog是MySQL的服务器层(可以参考文章前面对MySQL逻辑架构的介绍)实现的，同时支持InnoDB和其他存储引擎。

（3）内容不同：redo log是物理日志，内容基于磁盘的Page；binlog是逻辑日志，内容是一条条sql。

（4）写入时机不同：binlog在事务提交时写入；redo log的写入时机相对多元：

前面曾提到：当事务提交时会调用fsync对redo log进行刷盘；这是默认情况下的策略，修改innodb_flush_log_at_trx_commit参数可以改变该策略，但事务的持久性将无法保证。

除了事务提交时，还有其他刷盘时机：如master thread每秒刷盘一次redo log等，这样的好处是不一定要等到commit时刷盘，commit速度大大加快。

 

#### 日志块

innodb存储引擎中，redo log以块为单位进行存储的，每个块占512字节，这称为redo log block。所以不管是log buffer中还是os buffer中以及redo log file on disk中，都是这样以512字节的块存储的。

每个redo log block由3部分组成：日志块头、日志块尾和日志主体。其中日志块头占用12字节，日志块尾占用8字节，所以每个redo log block的日志主体部分只有512-12-8=492字节。

#### 格式

#### 日志刷盘规则

log buffer中未刷到磁盘的日志称为脏日志(dirty log)。

默认情况下事务每次提交的时候都会刷事务日志到磁盘中，这是因为变量 innodb_flush_log_at_trx_commit 的值为1。但是innodb不仅仅只会在有commit动作后才会刷日志到磁盘，这只是innodb存储引擎刷日志的规则之一。

 

刷日志到磁盘有以下几种规则：

1、发出commit动作时。已经说明过，commit发出后是否刷日志由变量 innodb_flush_log_at_trx_commit 控制。

2、每秒刷一次。这个刷日志的频率由变量 innodb_flush_log_at_timeout 值决定，默认是1秒。要注意，这个刷日志频率和commit动作无关。

3、当log buffer中已经使用的内存超过一半时。

4、当有checkpoint时，checkpoint在一定程度上代表了刷到磁盘时日志所处的LSN位置。

#### 数据页刷盘规则

#### Checkpoint

#### LSN

#### Innodb恢复行为

### 故障恢复

​	事务的执行流程如下：

​	系统会为每个事务开辟一个私有工作区；

​	事务读操作将从磁盘中拷贝数据项到工作区中，在执行写操作前所有的更新都作用域工作区中的拷贝；

​	事务的写操作将数据输出到内存的缓冲区中，等到合适的时间再由缓冲区管理器将数据写入到磁盘。

​	由于数据库存在立即修改和延迟修改，所以在事务执行过程中可能存在以下情况：

​	在事务提交前出现故障，但是事务对数据库的部分修改已经写入磁盘数据库中，这导致了事务的原子性被破坏。

​	在系统崩溃前事务已经提交，但数据还在内存缓冲区中，没有写入磁盘。系统恢复时将丢失此次已提交的修改。这是对事务持久性的破坏。

​	故障恢复：

​	撤销事务undo：将事务更新的所有数据项恢复为日志中的旧值；

​	重做事务redo：将事务更新的额所有数据项恢复为日志中的新值。

​	事务正常回滚/因事务故障中止将进行redo。

​	系统从崩溃中恢复时将先进行redo再进行undo。

## MVCC

### 概述

数据库事务有不同的隔离级别，不同的隔离级别对锁的使用是不同的，锁的应用最终导致不同事务的隔离级别。

MVCC(Multi-Version Concurrency Control)多版本并发控制，可以简单地认为：***\*MVCC就是行级锁的一个变种(升级版)\****。

***\*事务的隔离级别就是通过锁的机制来实现，只不过隐藏了加锁细节\****。

在表锁中我们读写是阻塞的，基于提升并发性能的考虑，MVCC一般读写是不阻塞的(所以说MVCC很多情况下避免了加锁的操作)

MVCC实现的读写不阻塞正如其名：多版本并发控制--->通过一定机制生成一个数据请求时间点的一致性数据快照（Snapshot)，并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度来看，好像是数据库可以提供同一数据的多个版本。

 

***\*快照有两个级别：\****

1、语句级

针对于Read committed隔离级别

2、事务级别

针对于Repeatable read隔离级别

注：读未提交和串行化的隔离级别是不存在MVCC的，因为读未提交直接可以读到脏数据，不需要快照，串行化是顺序执行的，不存在所谓的快照。

 

***\*事务的隔离级别有4种：\****

Read uncommitted

会出现脏读，不可重复读，幻读

Read committed

会出现不可重复读，幻读

Repeatable read

会出现幻读(但在Mysql实现的Repeatable read配合gap锁不会出现幻读！)

Serializable

串行，避免以上的情况！

Readuncommitted会出现的现象--->脏读：一个事务读取到另外一个事务未提交的数据

例子：A向B转账，A执行了转账语句，但A还没有提交事务，B读取数据，发现自己账户钱变多了！B跟A说，我已经收到钱了。A回滚事务rollback，等B再查看账户的钱时，发现钱并没有多。

 

#### 行锁与MVCC

***\*Read uncommitted过程：\****

事务A读取记录(没有加任何的锁)

事务B修改记录(此时加了写锁，并且还没有commit-->也就没有释放掉写锁)

事务A再次读取记录(此时因为事务A在读取时没有加任何锁，所以可以读取到事务B还没提交的(没释放掉写锁)的记录

出现脏读的原因是因为在读的时候没有加读锁，导致可以读取出还没释放锁的记录。

注：读未提交可以读到脏数据，不需要快照控制多版本读。

 

Read committed避免脏读的做法其实很简单：

在***\*读取\****的时候生成一个版本号，直到事务其他commit被修改了之后，才会有新的版本号

 

***\*Read committed过程：\****

事务A读取了记录(生成版本号)

事务B修改了记录(此时加了写锁)

事务A再读取的时候，是依据最新的版本号来读取的(当事务B执行commit了之后，会生成一个新的版本号)，如果事务B还没有commit，那事务A读取的还是之前版本号的数据。

但Read committed出现的现象--->不可重复读：一个事务读取到另外一个事务已经提交的数据，也就是说一个事务可以看到其他事务所做的修改（正是因为读已提交是语句级别的快照，而不是事务级别的快照，导致无法解决不可重复读）

注：A查询数据库得到数据，B去修改数据库的数据，导致A多次查询数据库的结果都不一样

危害：A每次查询的结果都是受B的影响的，那么A查询出来的信息就没有意思了

 

上面也说了，***\*Read committed是\*******\**语句级别\**\******\*的快照\****！每次读取的都是当前最新的版本！

***\*Repeatable read避免不可重复读是\*******\**事务级别\**\******\*的快照\****！***\*每次读取的都是当前事务的版本，即使被修改了，也只会读取当前事务版本的数据\****。

注：***\*RC与RR最根本的区别就是，在MVCC控制的时候，前者是当前读的时候生成版本号，后者是在事务开始时生成版本号，所以一个是SQL级别的快照，一个是事务级别的快照，因此前者无法避免不可重复读\****。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD34.tmp.jpg) 

至于虚读(幻读)：是指在一个事务内读取到了别的事务插入的数据，导致前后读取不一致。

注：和不可重复读类似，但虚读(幻读)会读到其他事务的插入的数据，导致前后读取不一致

MySQL的 Repeatableread隔离级别加上GAP间隙锁已经处理了幻读了。

 

RR解决脏读、不可重复读、幻读等问题，使用的是MVCC：MVCC全称Multi-Version Concurrency Control，即多版本的并发控制协议。下面的例子很好的体现了MVCC的特点：在同一时刻，不同的事务读取到的数据可能是不同的(即多版本)——在T5时刻，事务A和事务C可以读取到不同版本的数据。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD45.tmp.jpg) 

MVCC最大的优点是读不加锁，因此读写不冲突，并发性能好。InnoDB实现MVCC，多个版本的数据可以共存，主要是依靠数据的隐藏列(也可以称之为标记位)和undo log。其中数据的隐藏列包括了该行数据的版本号、删除时间、指向undo log的指针等等；当读取数据时，MySQL可以通过隐藏列判断是否需要回滚并找到回滚需要的undo log，从而实现MVCC；隐藏列的详细格式不再展开。

#### 脏读

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD46.tmp.jpg) 

当事务A在T3时间节点读取zhangsan的余额时，会发现数据已被其他事务修改，且状态为未提交。此时事务A读取最新数据后，根据数据的undo log执行回滚操作，得到事务B修改前的数据，从而避免了脏读。

 

#### 不可重复读

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD47.tmp.jpg) 

当事务A在T2节点第一次读取数据时，会记录该数据的版本号（数据的版本号是以row为单位记录的），假设版本号为1；当事务B提交时，该行记录的版本号增加，假设版本号为2；当事务A在T5再一次读取数据时，发现数据的版本号（2）大于第一次读取时记录的版本号（1），因此会根据undo log执行回滚操作，得到版本号为1时的数据，从而实现了可重复读。

 

#### 幻读

InnoDB实现的RR通过next-key lock机制避免了幻读现象。

next-key lock是行锁的一种，实现相当于record lock(记录锁) + gap lock(间隙锁)；其特点是不仅会锁住记录本身(record lock的功能)，还会锁定一个范围(gap lock的功能)。当然，这里我们讨论的是不加锁读：此时的next-key lock并不是真的加锁，只是为读取的数据增加了标记（标记内容包括数据的版本号等）；准确起见姑且称之为类next-key lock机制。还是以前面的例子来说明：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD48.tmp.jpg) 

当事务A在T2节点第一次读取0<id<5数据时，标记的不只是id=1的数据，而是将范围(0,5)进行了标记，这样当T5时刻再次读取0<id<5数据时，便可以发现id=4的数据比之前标记的版本号更高，此时再结合undo log执行回滚操作，避免了幻读。

 

***\*总结\****

概括来说，InnoDB实现的RR，通过锁机制、数据的隐藏列、undo log和类next-key lock，实现了一定程度的隔离性，可以满足大多数场景的需要。不过需要说明的是，RR虽然避免了幻读问题，但是毕竟不是Serializable，不能保证完全的隔离，下面是一个例子，大家可以自己验证一下。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD58.tmp.jpg) 

 

### 原理

​	MVCC主要是为了**提高****并发**的读写性能，**不用加锁就能让多个事务并发读写**。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD59.tmp.jpg) 

​	对于事务id为12的操作，先查询select * from account；（创建了查询快照，记录执行sql这一刻最大的已提交事务id（快照点已提交最大事务id）），对于事务id为13的操作，先删除id=1的记录，然后更新id=2的记录，再提交。

​	对于删除操作，mysql底层会记录好被删除的数据行的删除事务id，对于更新操作mysql底层会新增一行相同数据并记录好对应的创建事务id。

​	在id为12的事务里执行查询操作mysql底层会带上过滤条件，创建事务id<=max（当前事务id(12)，快照点已提交最大事务id），删除事务id>max（当前事务id(12)，快照点已提交最大事务id）。

 

​	**具体分析：**

​	一开始对于id=1，name=lilei的记录（事务id=60，还未生成roll_pointer），生成如下：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD5A.tmp.jpg) 

​	注：MySQL底层会给每条记录增加两个字段，一个事务id字段（trx_id），一个回滚指针roll_pointer。

​	依次执行操作：

| Transaction100                                | Transaction200                               | Transaction300                                 | Select 1                                                     | Select 2                                                     |
| --------------------------------------------- | -------------------------------------------- | ---------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| begin;                                        | begin;                                       | begin;                                         | begin;                                                       | begin;                                                       |
| update test set c1=’123’ where id=1;          |                                              |                                                |                                                              |                                                              |
|                                               | update test set c1=’666’ where id=5;         | update account set name=’lilei300’ where id=1; |                                                              |                                                              |
|                                               |                                              | commit;                                        |                                                              |                                                              |
|                                               |                                              |                                                | select name from account where id=1;(readview:[100,200],300 lilei300） |                                                              |
| update account set name=’lilei1’ where id=1;à |                                              |                                                |                                                              |                                                              |
| update account set name=’lilei2’ where id=1;  |                                              |                                                |                                                              |                                                              |
|                                               |                                              |                                                | select name from account where id=1;(readview:[100,200],300 lilei300） |                                                              |
| commit;                                       | update account set name=’lilei3’ where id=1; |                                                |                                                              |                                                              |
|                                               | update account set name=’lilei4’ where id=1; |                                                |                                                              |                                                              |
|                                               |                                              |                                                | select name from account where id=1;(readview:[100,200],300 lilei300） | select name from account where id=1;(readview:[200],300 lilei2） |
|                                               | commit;                                      |                                                |                                                              |                                                              |

对于Transaction100：update test set c1=’123’ where id=1;（开启事务，执行该语句生成事务id 100）。

​	注：begin/start transaction命令并不是一个事务的起点，在执行到它们之后的第一个操作InnoDB表的语句，事务才真正启动，才会向mysql申请事务id，**mysql内部是严格按照事务的启动顺序来分配事务id的**。

​	对于Transaction200：update test set c1=’666’ where id=5;（生成事务id 200）。

​	对于Transaction300：update account set name=’lilei300’ where id=1;（生成事务id 300），执行该语句commit操作，在底层会在表中插入一条记录：id=1,name=’lilei300’，同时之前的那条记录（更新前的旧记录）放到undo日志中，新的记录回滚指针roll_pointer指向undo日志的地址（即通过这个指针找到历史数据）。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD6B.tmp.jpg) 

​	接着，开启一个session，执行查询操作（查询不会生成事务id，更新操作才会生成新的事务id）：select name from account where id=1;（readview:[100,200],300，结果集为lilei300），MySQL在第一次执行查询的时候会生成一个一致性视图ReadView（即快照读，包括未提交事务id数组和已创建的最大事务id），即活跃事务数组[100,200]（这两个事务未提交事务组成的数组），最大事务id=300。

​	每一条select语句会根据ReadView到版本链中，从最新的那条记录开始按照一定的规则（具体规则后述）找到应该显示的数据。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD6C.tmp.jpg) 

​	Transaction100：update account set name=’lilei1’ where id=1;

àupdate account set name=’lilei2’ where id=1;

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD6D.tmp.jpg) 

​	此时，Transaction300的记录已经变为历史记录，最新的记录是id=1,name=’lilei2’。

​	在select sessiion中执行查询：select name from account where id=1;（readview[100,200], 300，结果集为lilei300而不是最新的lilei2），如果是可重复读，则该查询依据的是第一次查询时生成的ReadView，即select name from account where id=1;（readview:[100,200],300），如果是读已提交，每次查询都会按照最新的情况重新生成一次ReadView，这里研究可重复读。MySQL底层会将事务id划分为3部分进行比较：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD6E.tmp.jpg) 

​	注：已提交事务<min_id（未提交的最小事务id），在min_id和max_id之间的可能是已提交或未提交的事务id，对于>max_id的表示未开始的事务。

***\*具体对比规则：\****

对于最新的记录tax_id=100，表示未提交或已提交事务id，这个id在未提交事务id数组[100,200]，表示在第一次select的时候这个事务还没有提交，不可见。依次网上查找，最后找到trx_id=300，这个事务id不在未提交事务id数组中，表示在查询时这个事务已经提交，可见，返回这条记录。

Transaction200：update account set name=’lilei3’ where id=1;

àupdate account set name=’lilei4’ where id=1;

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD7F.tmp.jpg) 

​	同理，执行查询select name from account where id=1;（readview[100,200], 300，结果集为lilei300）。

​	再启动一个select session，此时Transaction100和Transaction300都已经提交，只有Transaction200未提交，所以生成的readview[200],300，此时查找到id=100,name=’lilei2’。

 

### 读形式

快照读：读取的只是当前事务的可见版本，不用加锁。只要记住简单的select操作就是**快照读**(select * from table where id = xxx)。

当前读：读取的是当前版本，比如特殊的读操作，更新/插入/删除操作。比如：select * from table where xxx lock in share mode， select * from table where xxx for update， update table set.... insert into table (xxx,xxx) values (xxx,xxx) delete from table where id = xxx。

### 版本链

对于使用InnoDB存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列（row_id并不是必要的，我们创建的表中有主键或者非NULL唯一键时都不会包含row_id）：事务ID（transaction_id）和回滚指针（roll_pointer）。

trx_id：每次对某条记录进行改动时（比如插入操作），都会把对应的事务id赋值给trx_id隐藏列。

roll_pointer：每次对某条记录进行改动时，这个隐藏列会存一个指针，可以通过这个指针找到该记录修改前的信息。

 

每次对记录进行改动，都会记录一条undo日志，每条undo日志也都有一个roll_pointer属性（INSERT操作对应的undo日志没有该属性，因为该记录并没有更早的版本），可以将这些undo日志都连起来，串成一个链表：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD80.tmp.jpg) 

​	比如这里的数据变化为1->2->3->4，对应的事务ID：80->81->82->200，并且回滚指针roll_pointer指向前面修改的内容。这称之为版本链。

版本链的头节点就是当前记录最新的值。另外，每个版本中还包含生成该版本时对应的事务id。

​	注：上述所有的***\*版本链就是undo回滚日志的链表\****（不是每个数据都备份一个），即以前版本的数据都是存储到undo log。

每个事务都是共享版本链的，而不是每个事务复制一份，通过对比规则查找该事务对应的行记录，这样可以大大减小空间占用。

### 可见性算法

#### 回滚日志/undo log

​	事务的回滚日志，是可见性算法的非常重要的部分，可以分为两类：

insert undo log：事务在插入新记录产生的undo log，当事务提交之后可以直接丢弃。

update undo log：事务在进行update或者delete的时候产生的undo log，在快照读的时候还是需要的，所以不能直接删除，只有当系统没有比这个log更早的read-view了的时候才能删除。

注：所以长事务会产生很多老的视图导致undo log无法删除大量占用存储空间。

#### ReadView

##### 定义

​	当执行查询sql时会生成一致性视图read-view，它由执行查询时所有**未提交事务id数组**（数组里最小的id为min_id）和**已创建（已提交/未提交）的最大事务id**（max_id）组成，查询的数据结果需要跟read view作比对从而得到快照结果。

 

​	对于使用READ UNCOMMITTED隔离级别的事务来说，直接读取记录的最新版本就好了，对于使用SERIALIZABLE隔离级别的事务来说，使用加锁的方式来访问记录。对于使用READ COMMITTED和REPEATABLE READ隔离级别的事务来说，就需要用到版本链，核心问题就是：需要判断一下版本链中的哪个版本是当前事务可见的。

​	注：对于select查询语句其实就是根据ReadView存储的信息，到版本链中查找对应的版本的数据。

 

##### 参数

​	ReadView中主要包含4个比较重要的内容：

1、 m_ids：表示在生成ReadView时当前系统中活跃的读写事务的事务id列表。

2、 min_trx_id：表示在生成ReadView时当前系统中活跃的读写事务中最小的事务id，也就是m_ids中的最小值。

3、 max_trx_id：表示生成ReadView时系统中应该分配给下一个事务的id值。

4、 creator_trx_id：表示生成该ReadView事务的事务id。

READ COMMITTED的实现方式：每次读取数据前都生成一个ReadView

REPEATABLE READ的实现方式：在第一次读取数据时生成一个ReadView

##### 规则

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD81.tmp.jpg) 

​	版本链对比规则：

1、 如果落在绿色部分（trx_id<min_id），表示这个版本是已提交的事务生成的，这个数据是可见的；

2、 如果落在红色部分（trx_id>max_id），表示这个版本是由将来启动的事务生成的，是肯定不可见的；

3、 如果落在黄色部分（min_id<trx_id<=max_id），那就包括两种情况：

3.1 若row的trx_id在数组中，表示这个版本是由还没提交的事务生成的，不可见，当前自己的事务时可见的；

3.2 若row的trx_id不在数组中，表示这个版本是已提交了的事务生成的，可见。

​	对于删除的情况可以认为是update的特殊情况，会将版本链上最新的数据复制一份，然后将trx_id修改成删除操作的trx_id，同时在该条记录的头信息（record header）里的（delete flag）标记位置true来表示当前记录已经被删除。在查询时按照前面的规则查到对应的记录如果delete flag标记位为true，意味着记录已被删除，则不返回数据。

 

ReadView中主要包含当前系统中还有哪些活跃的读写事务，把它们的事务id放到一个列表中，我们把这个列表命名为为m_ids。这样在访问某条记录时，只需要按照下边的步骤判断记录的某个版本是否可见：

1、如果被访问版本的trx_id属性值小于m_ids列表中最小的事务id，表明生成该版本的事务在生成ReadView前已经提交，所以该版本可以被当前事务访问。

2、如果被访问版本的trx_id属性值大于m_ids列表中最大的事务id，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问。

3、如果被访问版本的trx_id属性值在m_ids列表中最大的事务id和最小事务id之间，那就需要判断一下trx_id属性值是不是在m_ids列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。

如果某个版本的数据对当前事务不可见的话，那就顺着版本链找到下一个版本的数据，继续按照上边的步骤判断可见性，依此类推，直到版本链中的最后一个版本，如果最后一个版本也不可见的话，那么就意味着该条记录对该事务不可见，查询结果就不包含该记录。

在MySQL中，READ COMMITTED和REPEATABLE READ隔离级别的的一个非常大的区别就是它们生成ReadView的时机不同。

##### 产生时机

###### READ COMMITTED

READ COMMITTED：每次读取数据前都生成一个ReadView

比方说现在系统里有两个id分别为100、200的事务在执行：

\# Transaction 100

BEGIN;

UPDATE t SET c = '关羽' WHERE id = 1;

UPDATE t SET c = '张飞' WHERE id = 1;

 

\# Transaction 200

BEGIN;

\# 更新了一些别的表的记录

...

注： 事务执行过程中，只有在第一次真正修改记录时（比如使用INSERT、DELETE、UPDATE语句），才会被分配一个单独的事务id，这个事务id是递增的。

此刻，表t中id为1的记录得到的版本链表如下所示：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD91.tmp.jpg) 

假设现在有一个使用READ COMMITTED隔离级别的事务开始执行：

\# 使用READ COMMITTED隔离级别的事务

BEGIN;

\# SELECT1：Transaction 100、200未提交

SELECT * FROM t WHERE id = 1; # 得到的列c的值为'刘备'

这个SELECT1的执行过程如下：

1、在执行SELECT语句时会先生成一个ReadView，ReadView的m_ids列表的内容就是[100, 200]。

2、然后从版本链中挑选可见的记录，从图中可以看出，最新版本的列c的内容是'张飞'，该版本的trx_id值为100，在m_ids列表内，所以不符合可见性要求，根据roll_pointer跳到下一个版本。

3、下一个版本的列c的内容是'关羽'，该版本的trx_id值也为100，也在m_ids列表内，所以也不符合要求，继续跳到下一个版本。

4、下一个版本的列c的内容是'刘备'，该版本的trx_id值为80，小于m_ids列表中最小的事务id100，所以这个版本是符合要求的，最后返回给用户的版本就是这条列c为'刘备'的记录。

之后，我们把事务id为100的事务提交一下，就像这样：

\# Transaction 100

BEGIN;

UPDATE t SET c = '关羽' WHERE id = 1;

UPDATE t SET c = '张飞' WHERE id = 1;

COMMIT;

然后再到事务id为200的事务中更新一下表t中id为1的记录：

\# Transaction 200

BEGIN;

\# 更新了一些别的表的记录

...

UPDATE t SET c = '赵云' WHERE id = 1;

UPDATE t SET c = '诸葛亮' WHERE id = 1;

此刻，表t中id为1的记录的版本链就长这样：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD92.tmp.jpg) 

然后再到刚才使用READ COMMITTED隔离级别的事务中继续查找这个id为1的记录，如下：

\# 使用READ COMMITTED隔离级别的事务

BEGIN;

\# SELECT1：Transaction 100、200均未提交

SELECT * FROM t WHERE id = 1; # 得到的列c的值为'刘备'

\# SELECT2：Transaction 100提交，Transaction 200未提交

SELECT * FROM t WHERE id = 1; # 得到的列c的值为'张飞'

这个SELECT2的执行过程如下：

1、在执行SELECT语句时会先生成一个ReadView，ReadView的m_ids列表的内容就是[200]（事务id为100的那个事务已经提交了，所以生成快照时就没有它了）。

2、然后从版本链中挑选可见的记录，从图中可以看出，最新版本的列c的内容是'诸葛亮'，该版本的trx_id值为200，在m_ids列表内，所以不符合可见性要求，根据roll_pointer跳到下一个版本。

3、下一个版本的列c的内容是'赵云'，该版本的trx_id值为200，也在m_ids列表内，所以也不符合要求，继续跳到下一个版本。

4、下一个版本的列c的内容是'张飞'，该版本的trx_id值为100，比m_ids列表中最小的事务id200还要小，所以这个版本是符合要求的，最后返回给用户的版本就是这条列c为'张飞'的记录。

 

以此类推，如果之后事务id为200的记录也提交了，再此在使用READ COMMITTED隔离级别的事务中查询表t中id值为1的记录时，得到的结果就是'诸葛亮'了，具体流程我们就不分析了。总结一下就是：***\*使用READ COMMITTED隔离级别的事务在每次查询开始时都会生成一个独立的ReadView\****。

 

###### REPEATABLE READ

REPEATABLE READ：在第一次读取数据时生成一个ReadView

对于使用REPEATABLE READ隔离级别的事务来说，只会在第一次执行查询语句时生成一个ReadView，之后的查询就不会重复生成了。我们还是用例子看一下是什么效果。

比方说现在系统里有两个id分别为100、200的事务在执行：

\# Transaction 100

BEGIN;

UPDATE t SET c = '关羽' WHERE id = 1;

UPDATE t SET c = '张飞' WHERE id = 1;

\# Transaction 200

BEGIN;

\# 更新了一些别的表的记录

...

此刻，表t中id为1的记录得到的版本链表如下所示：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD93.tmp.jpg) 

假设现在有一个使用REPEATABLE READ隔离级别的事务开始执行：

\# 使用REPEATABLE READ隔离级别的事务

BEGIN;

\# SELECT1：Transaction 100、200未提交

SELECT * FROM t WHERE id = 1; # 得到的列c的值为'刘备'

这个SELECT1的执行过程如下：

1、在执行SELECT语句时会先生成一个ReadView，ReadView的m_ids列表的内容就是[100, 200]。

2、然后从版本链中挑选可见的记录，从图中可以看出，最新版本的列c的内容是'张飞'，该版本的trx_id值为100，在m_ids列表内，所以不符合可见性要求，根据roll_pointer跳到下一个版本。

3、下一个版本的列c的内容是'关羽'，该版本的trx_id值也为100，也在m_ids列表内，所以也不符合要求，继续跳到下一个版本。

4、下一个版本的列c的内容是'刘备'，该版本的trx_id值为80，小于m_ids列表中最小的事务id100，所以这个版本是符合要求的，最后返回给用户的版本就是这条列c为'刘备'的记录。

之后，我们把事务id为100的事务提交一下，就像这样：

\# Transaction 100

BEGIN;

UPDATE t SET c = '关羽' WHERE id = 1;

UPDATE t SET c = '张飞' WHERE id = 1;

COMMIT;

然后再到事务id为200的事务中更新一下表t中id为1的记录：

\# Transaction 200

BEGIN;

\# 更新了一些别的表的记录

...

UPDATE t SET c = '赵云' WHERE id = 1;

UPDATE t SET c = '诸葛亮' WHERE id = 1;

此刻，表t中id为1的记录的版本链就长这样：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDD94.tmp.jpg) 

然后再到刚才使用REPEATABLE READ隔离级别的事务中继续查找这个id为1的记录，如下：

\# 使用REPEATABLE READ隔离级别的事务

BEGIN;

\# SELECT1：Transaction 100、200均未提交

SELECT * FROM t WHERE id = 1; # 得到的列c的值为'刘备'

\# SELECT2：Transaction 100提交，Transaction 200未提交

SELECT * FROM t WHERE id = 1; # 得到的列c的值仍为'刘备'

这个SELECT2的执行过程如下：

1、因为之前已经生成过ReadView了，所以此时直接复用之前的ReadView，之前的ReadView中的m_ids列表就是[100, 200]。

2、然后从版本链中挑选可见的记录，从图中可以看出，最新版本的列c的内容是'诸葛亮'，该版本的trx_id值为200，在m_ids列表内，所以不符合可见性要求，根据roll_pointer跳到下一个版本。

3、下一个版本的列c的内容是'赵云'，该版本的trx_id值为200，也在m_ids列表内，所以也不符合要求，继续跳到下一个版本。

4、下一个版本的列c的内容是'张飞'，该版本的trx_id值为100，而m_ids列表中是包含值为100的事务id的，所以该版本也不符合要求，同理下一个列c的内容是'关羽'的版本也不符合要求。继续跳到下一个版本。

5、下一个版本的列c的内容是'刘备'，该版本的trx_id值为80，80小于m_ids列表中最小的事务id100，所以这个版本是符合要求的，最后返回给用户的版本就是这条列c为'刘备'的记录。

也就是说两次SELECT查询得到的结果是重复的，记录的列c值都是'刘备'，这就是可重复读的含义。如果我们之后再把事务id为200的记录提交了，之后再到刚才使用REPEATABLE READ隔离级别的事务中继续查找这个id为1的记录，得到的结果还是'刘备'。

 

#### 总结

***\*MVCC（Multi-Version\**** ***\*Concurrency Control\*******\*，多版本并发控制）指的就是在使用READ\**** ***\*COMMITTD，REPEATABLE\**** ***\*READ这两种隔离级别的事务在执行普通的SELECT操作时访问记录的版本链的过程\****。可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。

READ COMMITTD、REPEATABLE READ这两个隔离级别的一个很大的不同就是：生成ReadView的时机不同，READ COMMIT在每一次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView就好了。

MVCC主要是为了实现高并发的***\*读操作\****。

### 分布式MVCC

## 并发控制

​	参考资料：[https://www.cnblogs.com/takumicx/p/9998844.html#%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E6%80%A7%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%B8%B8%E8%A7%81%E7%9A%84%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%E6%8A%80%E6%9C%AF](https://www.cnblogs.com/takumicx/p/9998844.html#事务隔离性的实现常见的并发控制技术)

在分布式事务中，集群中的每个服务器节点要管理很多资源对象，每个节点必须保证在并发事务访问这些资源对象时，它们能够始终保持一致性。因此，每个服务器节点需要对自己的管理的资源对象应用一定的并发控制机制。分布式事务中需要所有服务器节点共同保证事务以串行等价的的方式执行。

也就是说，如果事务 T 对某一个服务器节点上的资源对象 S 的并发访问在事务 U 之前，那么我们需要保证在所有服务器节点上对 S 和其他资源对象的冲突访问，T 始终在 U 之前。

 

### 基于加锁的并发控制

核心思想：对于并发可能冲突的操作，比如读-写，写-读，写-写，通过锁使它们互斥执行。

锁通常分为共享锁和排他锁两种类型：

1、共享锁(S)：事务T对数据A加共享锁，其他事务只能对A加共享锁但不能加排他锁。

2、排他锁(X)：事务T对数据A加排他锁，其他事务对A既不能加共享锁也不能加排他锁。

基于锁的并发控制流程：

事务根据自己对数据项进行的操作类型申请相应的锁(读申请共享锁，写申请排他锁)。

申请锁的请求被发送给锁管理器。锁管理器根据当前数据项是否已经有锁以及申请的和持有的锁是否冲突决定是否为该请求授予锁。

若锁被授予，则申请锁的事务可以继续执行；若被拒绝，则申请锁的事务将进行等待，直到锁被其他事务释放。

#### 原理

在分布式事务中，某个对象的锁总是本地持有的（在同一个服务器节点上）。是否加锁是由本地锁管理器（Local Lock Manager，LLM）决定的。LLM决定是满足客户端持锁的请求，还是阻塞客户端发起的分布式事务。但是，事务在所有服务器节点上被提交或者放弃之前，LLM不能释放任何锁。在使用加锁机制的并发控制中，原子提交协议在进行的过程中资源对象始终被锁住，并且是排他锁，其他事务无法染指这些资源对象。但如果事务在两阶段提交协议的阶段一就被放弃，则互斥锁可以提前释放。

由于不同服务器节点上的LLM独立设置资源对象锁，因此，对于不同的事务，它们加锁的顺序也可能出现不一致。考虑一个场景：事务T和U在服务器X和Y之间的交错执行：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDA5.tmp.jpg) 

1、事务T锁住了服务器节点X上的资源对象A，做写入操作；

2、事务U锁住了服务器节点Y上的资源对象B，做写入操作；

3、事务T试图读取服务器节点Y上的资源对象B，此时B被事务U锁住，因此T等待锁释放；

4、事务U试图读取服务器节点X上的资源对象A，此时A被事务T锁住，因此U等待锁释放。

在服务器节点X上，事务T在事务U之前；而在服务器节点Y上，事务U在事务T之前。这种不一致的事务次序导致了事务之间的循环依赖，从而引起分布式死锁。分布式死锁需要通过特定的方法/算法来检测并解除，一旦检测到死锁，则必须放弃其中的某个事务来解除死锁，然后通知事务协调者，它将会放弃该事务所涉及的所有参与者上的事务。

 

#### 问题

**可能出现的问题：**

死锁：多个事务持有锁并互相循环等待其他事务的锁导致所有事务都无法继续执行。

饥饿：数据项A一直被加共享锁，导致事务一直无法获取A的排他锁。

对于可能发生冲突的并发操作，锁使它们由并行变为串行执行，是一种悲观的并发控制。

 

#### 乐观并发控制

加锁机制这一类悲观并发控制有许多明显的缺陷：

锁的维护带来了很多新的开销。这些开销在不支持对共享数据并发访问的系统中是不存在的。即使是只读事务（如查询），就算这一类事务不会改变数据的完整性，却仍然需要利用锁来保证数据在读取过程中不会被其他事务修改，然而锁却只在最极端的情况下才会发挥作用。

锁机制非常容易引发死锁。预防死锁会严重降低并发度，因此必须利用超时或者死锁检测来解除死锁，但这些死锁解除方案对于交互式的程序来说并不是很理想。

锁周期过长。为了避免事务的连锁（雪崩）放弃，锁必须保留到事务结束之时才能释放，这再一次严重降低了系统的并发度。

由于锁这一类的悲观并发控制有上述的种种弊端，因此研究者们提出了另一种乐观并发控制的机制，以求规避锁机制的天然缺陷，研究者们发现这样的一个现象：在大多数应用中两个客户端事务访问同一个资源对象的可能性其实很低，事务总是能够成功执行，就好像事务之间不存在冲突一样。

所以事务的乐观并发控制的基本思路就是：各个并发事务只有在执行完成之后并且发出 closeTransaction 请求时，再去检测是否有冲突，如果确实存在冲突，那么就放弃一些事务，然后让客户端重新启动这些事务进行重试。

在乐观并发控制中，每个事务在提交之前都必须进行验证。事务在验证开始时首先要附加一个事务号，事务的串行化就是根据这些事务号的顺序实现的。分布式事务的验证由一组独立的服务器节点共同完成，每个服务器节点验证访问自己资源对象的事务。这些验证在两阶段提交协议的第一个阶段进行。

 

### 基于时间戳的并发控制

核心思想：对于并发可能冲突的操作，基于时间戳排序规则选定某事务继续执行，其他事务回滚。

系统会在每个事务开始时赋予其一个时间戳，这个时间戳可以是系统时钟也可以是一个不断累加的计数器值，当事务回滚时会为其赋予一个新的时间戳，先开始的事务时间戳小于后开始事务的时间戳。

每一个数据项Q有两个时间戳相关的字段:

W-timestamp(Q):成功执行write(Q)的所有事务的最大时间戳

R-timestamp(Q):成功执行read(Q)的所有事务的最大时间戳

时间戳排序规则如下:

假设事务T发出read(Q),T的时间戳为TS

a.若TS(T)<W-timestamp(Q),则T需要读入的Q已被覆盖。此read操作将被拒绝,T回滚。

b.若TS(T)>=W-timestamp(Q),则执行read操作,同时把R-timestamp(Q)设置为TS(T)与R-timestamp(Q)中的最大值

假设事务T发出write(Q)

a.若TS(T)<R-timestamp(Q),write操作被拒绝,T回滚。

b.若TS(T)<W-timestamp(Q),则write操作被拒绝,T回滚。

c.其他情况:系统执行write操作,将W-timestamp(Q)设置为TS(T)。

基于时间戳排序和基于锁实现的本质一样：对于可能冲突的并发操作，以串行的方式取代并发执行，因而它也是一种悲观并发控制。它们的区别主要有两点：

基于锁是让冲突的事务进行等待，而基于时间戳排序是让冲突的事务回滚。

基于锁冲突事务的执行次序是根据它们申请锁的顺序，先申请的先执行；而基于时间戳排序是根据特定的时间戳排序规则。

### 基于有效性检查的并发控制

核心思想：事务对数据的更新首先在自己的工作空间进行，等到要写回数据库时才进行有效性检查，对不符合要求的事务进行回滚。

基于有效性检查的事务执行过程会被分为三个阶段：

读阶段：数据项被读入并保存在事务的局部变量中。所有write操作都是对局部变量进行,并不对数据库进行真正的更新。

有效性检查阶段：对事务进行有效性检查，判断是否可以执行write操作而不违反可串行性。如果失败,则回滚该事务。

写阶段：事务已通过有效性检查，则将临时变量中的结果更新到数据库中。

有效性检查通常也是通过对事务的时间戳进行比较完成的，不过和基于时间戳排序的规则不一样。

该方法允许可能冲突的操作并发执行，因为每个事务操作的都是自己工作空间的局部变量,直到有效性检查阶段发现了冲突才回滚。因而这是一种乐观的并发策略。

 

### 基于快照隔离的并发控制

快照隔离是多版本并发控制(mvcc)的一种实现方式。

其核心思想是：数据库为每个数据项维护多个版本(快照)，每个事务只对属于自己的私有快照进行更新，在事务真正提交前进行有效性检查，使得事务正常提交更新或者失败回滚。

由于快照隔离导致事务看不到其他事务对数据项的更新，为了避免出现丢失更新问题，可以采用以下两种方案避免：

先提交者获胜：对于执行该检查的事务T，判断是否有其他事务已经将更新写入数据库，是则T回滚否则T正常提交。

先更新者获胜：通过锁机制保证第一个获得锁的事务提交其更新，之后试图更新的事务中止。

事务间可能冲突的操作通过数据项的不同版本的快照相互隔离，到真正要写入数据库时才进行冲突检测。因而这也是一种乐观并发控制。

 

# 分布式事务

​	单机数据库遵循的ACID属性，在分布式事务领域已经不能满足需求，于是引入CAP和BASE理论。

## 概述

分布式事务是指会涉及到操作多个数据库的事务。其实就是将对同一库事务的概念扩大到对多个库的事务。目的是为了保证分布式系统中的数据一致性。***\*分布式事务处理的关键是必须有一种方法可以知道事务在任何地方所做的所有动作，提交或回滚事务的决定必须产生统一的结果（全部提交或全部回滚）\****。

 

在「单体应用」中，我们只需要贴上@Transactional注解就可以开启事务来保证整个操作的「原子性」。

如果转账是在一个数据库中的事务操作，我们可以使用一些框架比如 Spring的事务管理器来给我们统一搞定。

但是如果我们系统中出现垮库操作，比如一个操作中，我需要操作多个库，或者说这个操作会垮应用之前的调用，那么Spring 的事务管理机制就对这种场景没有办法了。

就像上面面试题中出现的问题一样，在系统 A 的步骤 2 在远程调用 B 的时候，由于网络超时，导致B 没有正常响应，但是A 这边调用失败，进行了回滚，而 B 又提交了事物。此时就可能会导致数据不一致的情况，产生分布式事物的问题。

与本地事务不同的是，分布式系统之所以叫分布式，是因为提供服务的各个节点分布在不同的机器上，相互之间通过网络交互，不能因为有一点网络问题就导致整个系统无法提供服务，网络因素成了分布式事务的考量标准之一。因此，分布式事务需要更进一步的理论支持。

### 对比

| 单机数据库                                                   | 分布式数据库                                                 |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 原子性：多条记录的多次操作要么一起成功，要么一起失败         | 原子性：多个数据分片上的多次操作要么一次成功，要么一起失败   |
| 隔离性：不同连接（处理线程或进程）不会相互访问到未提交事务的数据 | 隔离性：多个计算节点上的不同连接不会相互访问到多个数据分片内未提交事务的数据 |
| 持久性：事务提交前必须先将日志落盘，机器重启后不会丢失数据   | 持久性：事务提交前必须将日志在分片主、从节点都得到复制，主节点故障时从节点仍能找回数据 |

 

分布式事物的存在，就是解决数据不一致的情况。

***\*MySQL从5\*******\*.03\*******\*开始支持分布式事务，当前分布式事务只支持InnoDB存储引擎\****。

 

### 难点

要实现分布式事务的实时一致性（保证ACID），难点在哪里？

1、部分数据节点提交失败，如何保证全局事务的原子性（A）？

2、并发访问时，每个事务都不知道其他事务的状态，如何保证事务之间的合理性？

3、更进一步，部分数据节点提交成功，部分数据节点提交失败时，如何保证回滚期间的隔离性（C&A）？

### CAP定理

​	当我们的单个数据库性能产生瓶颈的时候，我们可以对数据库进行分区，这里所说的分区是指的物理分区，分区之后可能不同的库就处于不同的服务器之上，这个时候单个数据库的ACID已经不能适应这种分布式的情况了，或者说如果再追求ACID会导致我们的系统变得很差，这时我们需要引入一个新的理论原则来适应这种集群的情况，这就是CAP原则或CAP定理。即***\*本地事务遵循ACID，分布式事务遵循CAP和BASE理论\****。

注：分布式事务不是摒弃ACID，而是在单机上仍然遵循ACID，但是在分布式情况下事务不再追求严格的ACID，因为这样会导致性能很差，基本不可用，索引引入分布式事务需要遵循的CAP和BASE理论。

#### 概述

CAP理论由加州大学伯克利分校的计算机教授Eric Brewer在2000年提出，其***\*核心思想是任何基于网络的数据共享系统最多只能满足数据一致性(Consistency)、可用性(Availability)和网络分区容忍(Partition Tolerance)三个特性中的两个\****，三个特性的定义如下：

a. 一致性 (Consistency)：也就是线性一致性，一个写操作返回成功，那么之后的读请求都必须读到这个新数据；如果返回失败，那么所有读操作都不能读到这个数据。所有节点访问同一份最新的数据。

b. 可用性 (Availability)：对数据更新具备高可用性，请求能够及时处理，不会一直等待，即使出现节点失效。

c. 分区容错性 (Partition tolerance)：能容忍网络分区，在网络断开的情况下，被分隔的节点仍能正常对外提供服务。

CAP理论的表述很好地服务了它的目的，开阔了分布式系统设计者的思路，在多样化的取舍方案下设计出多样化的系统。在过去的十几年里确实涌现了不计其数的新系统，也随之在一致性和可用性的相对关系上产生了相当多的争论。***\*一般来说使用网络通信的分布式系统，无法舍弃P性质，那么就只能在一致性和可用性上做选择。既然在分布式系统中一致性和可用性只能选一个\****。

 

CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency一致性，Availability可用性，分区容错性Partition tolerance，三者不可兼得。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDA6.tmp.jpg) 

举例，商品信息管理的执行流程：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDB7.tmp.jpg) 

整体执行流程如下：

1、 商品服务请求主数据库写入商品信息（添加商品、修改商品、删除商品）

2、 主数据库向商品服务响应写入成功；

3、 商品服务请求从数据库读取商品信息。

#### 原理

##### C一致性

一致性：是指写操作后的读操作可以读取到最新的数据状态，当数据分布在多个节点上，从任意节点读取到的数据都是最新的状态。即***\*分布式系统中的所有数据，同一时刻有同样的值\****。

如果要保证可用性，那么有数据的节点返回数据，没数据的节点返回null ,就会出现用户那里看到的是一会儿有数据，一会儿没有数据，此时就存在一致性的问题。

在实例中，商品信息的读写要满足一致性就是要实现如下目标：

1、 商品服务写入主数据库成功，则向从数据库查询新数据也成功；

2、 商品服务写入主数据库失败，则向从数据库查询新数据也失败。

如何实现一致性？

1、 写入主数据库后要将数据同步到从数据库；

2、 写入主数据库后，在向从数据库同步期间要将从数据库锁定，待同步完成后再释放锁，以免在新数据写入成功后，向从数据库查询到旧的数据。

分布式系统一致性的特点：

1、 由于存在数据同步的过程，写操作的响应会有一定的延迟；

2、 为了保证数据一致性会对资源暂时锁定，待数据同步完成释放锁定资源；

3、 如果请求数据同步失败的节点则会返回错误信息，一定不会返回旧数据。

 

如果深究一致性的语义还是略有差别，这里简单归为3类介绍其区别：

Coherence更关注多核共享存储架构的cache数据一致性；

Consistence更关注分布式系统的一致性，该一致性往往以客户端为视角，比如数据库的事务一致性（ACID），分布式系统副本数据同步的CAP理论中的C都指的是这个一致性。尽管两者还有一定差异：ACID关注的是系统内部的数据一致性，CAP关注的是多副本数据对外界的一致性；

Consensus关注的是达成一致性的手段或者协议，是一种过程，比如通过Paxos达成共识，一致性是共识的目的。

几个C虽有差别，但也不是毫无关系，只是看待问题的角度和层次的差别，理论很多是相通的。

 

##### A可用性

​	可用性：是指任何事物操作都可以得到响应结果，且不会出现响应超时或者响应错误。

如果保证一致性，那么在用户访问的时候，不管web1还是web2，我们可能会返回一些提示信息，说系统不可用，稍后再试等等，保证每次都是一致的。明明我们有数据在，但是我们系统却响应的是提示信息，此时就是可用性的问题。

 

​	在实例中，商品信息读写满足可用性就是要实现如下目标：

1、 从数据库接收到数据查询的请求则立即能够响应数据查询结果；

2、 从数据库不允许出现响应超时或响应错误。

​	如何实现可用性？

1、 写入主数据库后要将数据同步到从数据库；

2、 由于要保证从数据库的可用性，不可将从数据库中的资源进行锁定；

3、 即使数据还没有同步过来，从数据库也要返回要查询的数据，哪怕是旧数据，如果连旧数据也没有则可以按照约定返回一个默认信息，但不能返回错误或者响应超时。

分布式系统可用性的特点：

1、 所有请求都有响应，且不会出现响应超时或者响应错误。

 

##### P分区容错性

我们先看这样一个场景，现在我们系统部署了两份（两个节点，web1和web2），同样的业务代码，但是维护的是自己这个节点生成的数据。但是用户访问进来，可能会访问到不同的节点。

但是不管是访问web1还是web2，在用户参数数据过后，这个数据都必须得同步到另外的节点，让用户不管访问哪个节点，都是响应他需要的数据。如下图：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDB8.tmp.jpg) 

分区容错性：就算上面这两个节点之间发生了网络故障，无法发生同步的问题，但是用户访问进来，***\*不管到哪个节点，这个节点都得单独提供服务，这一点对于互联网公司来说，是必须要满足的\****。

当web1和web2之间的网络发生故障，导致数据无法进行同步。用户在web1上写了数据，马上又访问进来读取数据，请求到了web2，但是此时web2是没有数据的。那么我们是给用户返回null？还是说给一些提示，说系统不可用，稍后重试呢？

 

​	通常分布式系统的各个节点部署在不同的子网，这就是网络分区，不可避免的会出现**网络问题**而导致节点之间通信失败，此时仍可对外提供服务，这叫分区容错性。

***\*网络无法100%可靠，分区其实是一个必然现象，P必须保证！\****

​	

​	在实例中，商品信息读写满足分区容忍性就是要实现如下目标：

1、 主数据库向从数据库同步数据失败不影响读写操作；

2、 其中一个节点挂掉不影响另一个节点提供服务。

如何实现分区容忍性？

1、 尽量***\*使用异步取代同步操作\****，例如使用异步方式将数据从主数据库同步到从数据库，这样节点之间能有效地实现松耦合；

2、 添加从数据库节点，其中 一个从节点挂掉其他从节点提供服务。

分区容忍性的特点：

1、 分区容忍性是分布式系统具备的基本能力；

​	

***\*另一种解释：\****

​	一致性：在分布式系统中所有数据备份，在同一时刻是否同样的值（等同于所有节点访问同一份最新的数据副本）。

​	可用性：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求（对数据更新具备高可用性）。

​	分区容错性：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致时，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。

 

#### CAP组合方式

​	WEB服务器无法同时满足以下3个属性：

​	一致性（Consistency）：客户端知道一系列的操作都会同时发生（生效）。

​	可用性（Availability）：每个操作都必须以可预期的响应结束。

​	分区容错性（Partition tolerance）：即使出现单个组件无法可用，操作依然可以完成。

​	具体地将在分布式系统中，在任何数据库设计中，一个Web应用至多只能同时支持上面的两个属性。显然，任何横向拓展策略都要依赖于数据分区。因此，设计人员必须在一致性与可用性之间做出选择。

 

​	在所有分布式事务场景中不会同时具备CAP三个特性，因为在具备了P的前提下C和A是不可能共存的。

​	在实例中，分区容忍的含义是：

1、 主数据库通过网络向从数据同步数据，可以认为主从数据库部署在不同的分区，通过网络进行交互；

2、 当主数据库和从数据库之间的网络出现问题不影响主数据库和从数据库对外提供服务；

3、 其一个节点挂掉不影响另一个节点对外提供服务。

如果要实现C则必须保证数据一致性，在数据同步的时候为防止向从数据库查询不一致的数据则需要将从数据库数据锁定，待同步完成后解锁，如果同步失败从数据库要返回错误信息或超时信息。

如果要实现A则必须保证数据可用性，不管任何时候都可以向从数据库查询数据，则不会响应超时或者返回错误信息。

通过分析发现在满足P的前提下C和A存在矛盾性。

所以在生产中对分布式事务处理时需要根据需求来确定满足CAP的哪两个方面：

1、 AP：

放弃一致性，追求分区容错性和可用性，这是很多分布式系统设计时的选择。

例如：

在商品管理实例中，完全可以实现AP，前提是只要用户可以接收所查询的数据再一定时间内不是最新的即可。

通常实现AP都会保证最终一致性，后面的BASE理论就是根据AP来拓展的，一些业务场景，比如：订单退款，今日退款成功，明天账户到账，只要用户可以接受在一定时间内到账即可。

2、 CP：

放弃可用性，追求一致性和分区容错性，zookeeper其实就是追求的强一致，又比如跨行转账，一次转账请求要等待双方银行系统都完成整个事务才算完成。

3、 CA：

放弃分区容错性，即不进行分区，不考虑网络不通或者节点挂掉的问题，则可以实现一致性和可用性，那么系统将不是一个标准的分布式系统，我们最常用的关系型数据库就满足CA。

 

#### CAP与一致性算法

那Paxos、Raft等分布式一致性算法是如何做到在保证一定的可用性的同时，对外提供强一致性呢？在CAP理论提出十二年之后，其作者又出来辟谣。“三选二”的公式一直存在着误导性，它会过分简单化各性质之间的相互关系：

首先，由于分区很少发生，那么在系统不存在分区的情况下没什么理由牺牲C或A。

其次，C与A之间的取舍可以在同一系统内以非常细小的粒度反复发生，而每一次的决策可能因为具体的操作，乃至因为牵涉到特定的数据或用户而有所不同。

最后，这三种性质都可以在程度上衡量，并不是非黑即白的有或无。可用性显然是在0%到100%之间连续变化的，一致性分很多级别，连分区也可以细分为不同含义，如系统内的不同部分对于是否存在分区可以有不一样的认知。所以一致性和可用性并不是水火不容，非此即彼的。Paxos、Raft等分布式一致性算法就是在一致性和可用性之间做到了很好的平衡的见证。

 

#### 方案

参考：

https://www.bilibili.com/video/BV1bt411y72u?p=5&spm_id_from=pageDriver

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDB9.tmp.jpg) 

#### 总结

​	CAP是一个已经被证实的理论：一个分布式系统最多只能同时满足一致性、可用性和分区容忍性这三项中的两项。它可以作为我们进行架构设计、技术选型的考量标准。对于多数大型互联网应用的场景，节点众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9（99.99...%），并要达到良好的响应性能来提高用户体验，因此一般都会做出如下选择：***\*保证P和A，舍弃C强一致，保证最终一致性\****。

***\*由于分区容错性（P）是必须保证的，那么我们分布式系统就更多是在一致性（CP） 和可用性（AP）上做平衡，只能同时满足两个条件。\****

 

其实，ZK就是严格实现了CP，而Eureka则是保证了AP。

其实分布式事物强调的就是一致性。

 

### FLP

FLP定理是由Fischer，Lynch和Patterson三位科学家于1985年发表，是分布式理论中最重要的理论之一，它指出在最小化异步网络通信场景下，即使只有一个节点失败，也没有一种确定性的共识算法能够使得在其他节点之间保持数据一致。

a. 统模型假设

异步通信与同步通信的最大区别是没有时钟、不能时间同步、不能使用超时、不能探测失败、消息可任意延迟、消息可乱序

通信健壮只要进程非失败，消息虽会被无限延迟，但最终会被送达；并且消息仅会被送达一次（无重复）

fail-stop模型进程失败如同宕机，不再处理任何消息。相对Byzantine模型，不会产生错误消息

失败进程数量最多一个进程失败

b. 衡量标准

衡量一个分布式算法是否正确有三个标准：

Termination（终止性）非失败进程最终可以做出选择

Agreement（一致性）所有的进程必须做出相同的决议

Validity（合法性）进程的决议值，必须是其他进程提交的请求值 终止性，描述了算法必须在有限时间内结束，不能无限循环下去；一致性描述了我们期望的相同决议；合法性是为了排除进程初始值对自身的干扰。

***\*CAP与FLP关系\****

FLP讨论的分布式共识（distributed consensus）的问题。分布式共识可实现的功能包括：

leader election

replicated state machine

distributed commit

而CAP关注的是复制存储（replicated storage）的问题，replicated storage可以看作是replicated state machine的一个特例。可以看出，复制存储是分布式共识的子问题。也即，FLP关注的问题更加通用，CAP问题是FLP问题的子集。

此外，CAP中的复制存储问题只讨论了这样一类问题：同一份数据在不同节点上进行存储（主从复制即是这样一类问题）；而FLP中的分布式共识问题除了CAP中的问题外，还讨论了这样一类问题：多个任务（数据）被调度到不同节点上并行执行（存储），不同节点上的任务和状态可能是不同的（2PC协议即包含了这样一类问题）。由此也可见，FLP中讨论的问题更加复杂。一些方案可能无法解决FLP中的问题，但可能能够解决CAP中的问题。

 

### BASE理论

#### 强一致性/最终一致性

​	CAP理论告诉我们一个分布式系统最多只能满足一致性、可用性和分区容忍性这三项中的两项，其中AP在实际应用中较多，AP舍弃一致性，保证可用性和分区容忍性。但是，在实际生产中很多场景都要实现一致性，比如前面实例中主数据库向从数据库同步数据，即使不要一致性，但是最终也要将数据同步成功来保证数据一致，这种一致性和CAP中的一致性不同，***\*CAP中的一致性要求在任何时间查询每个节点的数据都必须一致，它强调的是强一致性，但是最终一致性是允许可以在一段时间内每个节点的数据不一致，但是经过一段时间每个节点的数据必须一致，它强调的是最终数据的一致性\****。

***\*在互联网领域的绝大多数场景，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可\****。

 

***\*强一致性：\****完成数据更新后，后续所有读操作都能且只能度读到更新以后的值，是事务一致性的最高级别。

***\*弱一致性：\****完成数据更新之后，不保证后续读操作都能读到更新以后的值，也不保证多久以后能够读到更新以后的值，甚至不能保证最终是否能够读到该值。

***\*最终一致性：\****完成数据更新以后，后续读操作不能立即读到更新后的值，系统能保证在没有后续更新的情况下，最终能够读到该值，是弱一致性的一种特例。

 

#### BASE原理

​	BASE理论是Basically Available(基本可用)，Soft State（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。***\*B\*******\*ASE\*******\*理论是对CAP的一个拓展，通过牺牲强一致性来获得可用性，当出现故障允许部分不可用弹药保证核心功能可用，允许数据再一段时间内是不一致的，但是最终达到一致状态\****。满足BASE理论的事务，我们称之为“***\*柔性事务\****”。

##### 基本可用

基本可用（Basically Available）：指分布式系统在出现不可预知故障的时候，允许损失部分可用性，保证核心功能可用。即使在流量激增的情况下，也会考虑通过限流降级的办法保证用户的请求是可用的。如，电商网站交易付款出现问题，商品依然可以正常浏览。

 

##### 软状态

软状态（Soft State）：一条数据如果存在多个副本，允许副本之间同步的延迟，在较短时间内能够容忍不一致。这个正在同步并且还没有完成同步的状态称为软状态。

由于***\*不要求强一致性\****，所以BASE允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。如，订单的“支付中”、“数据同步中”等状态，待数据最终一致后状态改为“成功”状态。

 

##### 最终一致

最终一致（Eventual Consistency）：强调的是所有的数据更新操作，在经过一段时间的同步之后，最终都能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。如，订单的“支付中”状态，最终会变为“支付成功”或者“支付失败”，使订单状态与实际交易结果打成一致，但需要一定时间的延迟、等待。

 

***\*其核心思想是：\****

***\*即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）\****。

到这里大家再想想，上面TCC方案中的账户设计了一个冻结字段frozen，这里是不是就是 BASE理论中间的软状态呢？

 

最终一致性是相对于强一致性来说的，强一致性是要保证所有的数据都是一致的，是实时同步。

而最终一致性会容忍一小段时间数据的不一致，但过了这段时间以后数据会保证一致。其包含以下几种“一致性”：

###### 因果一致性（Causal Consistency）

如果有两个进程 1 和 2 都对变量 X 进行操作，“进程 1” 写入变量 X，“进程 2”需要读取变量 X，然后用这个 X 来计算 X+2。

这里“进程 1”和“进程 2” 的操作就存在因果关系。“进程 2” 的计算依赖于进程 1 写入的 X，如果没有 X 的值，“进程 2”无法计算。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDBA.tmp.jpg) 

###### 读己之所写（Read Your Writes）

“进程 1”写入变量 X 之后，该进程可以获取自己写入的这个值。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDCA.tmp.jpg) 

###### 会话一致性（Session Consistency）

如果一个会话中实现来读己之所写。一旦数据更新，客户端只要在同一个会话中就可以看到这个更新的值。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDCB.tmp.jpg) 

###### 单调写一致性（Monotonic Write Consistency）

“进程 1”如果有三个操作分别是 1，2，3。“进程 2”有两个操作分别是 1，2。当进程请求系统时，系统会保证按照进程中操作的先后顺序来执行。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDCC.tmp.jpg) 

### 柔性事务

符合BASE理论的分布式解决方案叫做柔性事务。

典型柔性事务方案：

1、TCC（两阶段型、补偿型）

2、可靠消息最终一致性（异步确保型）：消息队列来保证事务的一致性

2.1 非事务型消息中间件：ActiveMQ、RabbitMQ、Kafka

2.1 事务型消息：RocketMQ（阿里）

3、最大努力通知（非可靠消息、定期校对）

## 分类

### 刚性事务

刚性事务（如单一数据库事务）完全遵循 ACID 规范，即数据库事务的四大基本特性。

刚性事务也能够以分布式 CAP 理论中的 CP 事务来作为定义。

### 柔性事务

在电商领域等互联网场景下，传统的事务在数据库性能和处理能力上都遇到了瓶颈。因此，柔性事务被提了出来，柔性事务基于分布式 CAP 理论以及延伸出来的 BASE 理论，相较于数据库事务这一类完全遵循 ACID 的刚性事务来说，柔性事务保证的是 “基本可用，最终一致”。

柔性事务（如分布式事务）为了满足可用性、性能与降级服务的需要，降低一致性（Consistency）与隔离性（Isolation）的要求，遵循 BASE 理论，传统的 ACID 事务对隔离性的要求非常高，在事务执行过程中，必须将所有的资源对象锁定，因此对并发事务的执行极度不友好，柔性事务（比如分布式事务）的理念则是将锁资源对象操作从本地资源对象层面上移至业务逻辑层面，再通过放宽对强一致性要求，以换取系统吞吐量的提升。

此外，虽然柔性事务遵循的是 BASE 理论，但是还需要遵循部分 ACID 规范：

原子性：严格遵循。

一致性：事务完成后的一致性严格遵循；事务中的一致性可适当放宽。

隔离性：并行事务间不可影响；事务中间结果可见性允许安全放宽。

持久性：严格遵循。

 

## 原理

​	在MySQL中，使用分布式事务的应用程序涉及一个或多个资源管理器和一个事务管理器。

​	资源管理器（RM）用于提供通向事务资源的途径。数据库服务器是一种资源管理器，该管理器必须可以提交或回滚由RM管理的事务。例如，多台MySQL数据库作为多台资源管理器或者几台MySQL服务器和几台Oracle服务器作为资源管理器。

​	事务管理器（TM）用于协调作为一个分布式事务一部分的事务。TM与管理每个事务的RMs进行通信。在一个分布式事务中，各个单个事务均是分布式事务的“分支事务”。分布式事务和各分支通过一种命名方法进行标识。

​	

用于执行分布式事务的过程使用两阶段提交，发生时间在由分布式事务的各个分支需要进行的行动已经被执行之后。

​	在第一阶段，所有的分支被预备好。即它们被TM告知要准备提交。通常，这意味着用于管理分支的每个RM会记录对于被稳定保存的分支的行动。分支指示是否它们可以这么做，这些结果被用于第二阶段。

​	在第二阶段，TM告诉RMs是否要提交或回滚。如果在预备分支时，所有的分支指示它们将能够提交，则所有的分支被告知要提交。如果在预备时，有任何分支指示它将不能提交，则所有分支被告知回滚。

## 全局事务（DTP模型）

### 模型

全局事务基于DTP模型实现。DTP是由X/Open组织提出的一种分布式事务模型——X/Open Distributed Transaction Processing Reference Model。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDCD.tmp.jpg) 

它规定了要实现分布式事务，需要三种角色：

AP：Application 应用系统

它就是我们开发的业务系统，在我们开发的过程中，可以使用资源管理器提供的事务接口来实现分布式事务。

TM：Transaction Manager 事务管理器

分布式事务的实现由事务管理器来完成，它会提供分布式事务的操作接口供我们的业务系统调用。这些接口称为TX接口。

事务管理器还管理着所有的资源管理器，通过它们提供的XA接口来同一调度这些资源管理器，以实现分布式事务。

***\*DTP只是一套实现分布式事务的\*******\*规范\*******\*，并没有定义具体如何实现分布式事务，\*******\*TM可以采用2PC、3PC、Paxos等协议实现分布式事务\****。

RM：Resource Manager 资源管理器

能够提供数据服务的对象都可以是资源管理器，比如：数据库、消息中间件、缓存等。大部分场景下，数据库即为分布式事务中的资源管理器。

CommunicationResourceManager（CRM），通信资源管理器控制一个或多个 TM domain 之间分布式应用的通信。

 

资源管理器能够提供单数据库的事务能力，它们通过XA接口，将本数据库的提交、回滚等能力提供给事务管理器调用，以帮助事务管理器实现分布式的事务管理。

***\*XA是DTP模型定义的接口，用于向事务管理器提供该资源管理器(该数据库)的提交、回滚等能力\****。

DTP只是一套实现分布式事务的规范，RM具体的实现是由数据库厂商来完成的。

### XA

#### 背景

我们首先要明白为什么需要保持binog与redo log之前数据的一致性，这里分两个方面来解释：

1、保证binlog里面存在的事务一定在redo log里面存在，也就是binlog里不会比redo log多事务（可以少，因为redo log里面记录的事务可能有部分没有commit，这些事务最终可能会被rollback）。先来看这样一个场景（后面的场景都是假设binlog开启）：在一个AB复制环境下主库crash，然后crash recovery，此时如果binlog里面的事务信息与redo log里面的信息不一致，那么就会出现主库利用redo log进行恢复后，然后binlog部分的内容复制到从库去，然后出现主从数据不一致状态，所以需要保证binlog和redo log两者事务一致性。

2、保证binlog里面事务顺序与redo log事务顺序一致性。这也是很重要的一点，假设两者记录的事务顺序不一致，那么会出现类似于主库事务执行的顺序为ta->tb->tc->td，但是binlog里面记录的是ta->tc->tb->td，binlog复制到从库后导致主从的数据不一致。

 

***\*必要性：\****

保证binlog存在的事务一定在redo log里面存在。***\*主从复制架构中，主机崩溃恢复依赖redo log和binlog，从机数据来源是主机binlog\****。

保证binlog里面事务顺序与redo log事务顺序一致。

***\*解决方案：\****

引入XA协议：

XA是由X/Open组织提出的分布式事务的规范（X代表transaction；A代表accordant）。XA规范主要定义了（全局）事务管理器（TM：Transaction Manager）和（局部）资源管理器（RM：Resource Manager）之间的接口。XA为了实现分布式事务，将事务的提交分成了两个阶段：也就是2PC（two phase commit），XA协议就是通过将事务的提交分为两个阶段来实现分布式事务。

prepare阶段：

持锁prepare_commit_mutex

write/sync redo log

undo设置为prepared状态

commit阶段：

write/sync binlog

innodb commit，写入commit标记，释放prepare_commit_mutex锁

说明：

1、以binlog写入与否作为事务提交成功与否的标志

2、由于prepare_commit_mutex锁存在，保证binlog和redo log之间顺序一致，但是却导致每个事物都需要一个fsync操作，导致性能急剧下降。

 

 

#### 概述

​	XA事务中需要有一个事务协调器来保证所有的事务参与者都完成了准备工作（第一阶段）。如果协调器收到所有的参与者都准备好的消息，就会告诉所有的事务都可以提交了，这是第二阶段。MySQL在这个XA事务过程中扮演一个参与者的角色，而不是协调者。

 

在给定客户端连接的上下文中，XA事务和本地（非XA）事务是互斥的。例如，如果XA START已发出已开始XA事务，则在提交或回滚XA事务之前无法启动本地事务。相反，如果已启动本地事务 START TRANSACTION，则在提交或回滚事务之前，不能使用任何XA语句。

MySQL数据库的主备数据库的同步，通过Binlog的复制完成。而Binlog是MySQL数据库内部XA事务的协调者，并且MySQL数据库为binlog做了优化——binlog不写prepare日志，只写commit日志。
	所有的参与节点prepare完成，在进行xa commit前crash。crash recover如果选择commit此事务。由于binlog在prepare阶段未写，因此主库中看来，此分布式事务最终提交了，但是此事务的操作并未写到binlog中，因此也就未能成功复制到备库，从而导致主备库数据不一致的情况出现。
	而crash recover如果选rollback, 那么就会出现全局不一致（该分布式事务对应的节点，部分已经提交，无法回滚，而部分节点回滚。最终导致同一分布式事务，在各参与节点，最终状态不一致）。
	针对这个问题，可选的替代方案有：

（1）不使用主从复制进行备份，而是直接使用xa事务实现同步写来作为备份；

（2）将PREPARE成功的事务写日志，但并不是写在二进制日志中，而是写在每个对应分布式事务的单独文件中。

 

#### 分类	

实际上，在MySQL中有两种XA事务。一方面，MySQL可以参与到外部的分布式事务中；另一方面，还可以通过XA事务来协调存储引擎和二进制日志。

##### 内部XA事务

内部XA事务用于同一实例下跨多引擎事务，由Binlog作为协调者，比如在一个存储引擎提交时，需要将提交信息写入二进制日志，这就是一个分布式内部XA事务，只不过二进制日志的参与者是MySQL本身。

Binlog作为内部XA的协调者，在binlog中出现的内部xid，在crash recover时，由binlog负责提交。(这是因为，binlog不进行prepare，只进行commit，因此在binlog中出现的内部xid，一定能够保证其在底层各存储引擎中已经完成prepare)。

###### preapre阶段

第一阶段，事务管理器向所有涉及到的数据库服务器发出prepare“准备提交”请求，数据库收到请求后执行数据修改和日志记录等处理，处理完成只是把事务的状态改为“可以提交”，然后把结果返回给事务管理器。

 

###### commit阶段

事务管理器收到回应后进入第二阶段，如果在第一阶段内有任何一个数据库的操作发生了错误，或者事务管理器收不到某个数据库的回应，则认为事务失败，回撤所有数据库的事务。数据库服务器收不到第二阶段的确认请求消息，也会把“可以提交”的事务回撤。如果第一阶段中所有数据库都提交成功，那么事务管理向数据库服务器发出“确认提交”请求，数据库服务器把事务的“可以提交”状态改为“提交完成”状态，然后返回应答。

 

##### 外部XA事务

外部XA用于跨多个MySQL实例的分布式事务，需要应用层作为协调者，通俗的说就是比如我们在PHP中写代码，那么PHP书写的逻辑就是协调者。应用层负责决定提交还是回滚，崩溃时的悬挂事务。MySQL数据库外部XA可以用在分布式数据库代理层，实现对MySQL数据库的分布式事务支持，例如开源的代理工具：网易的DDB，淘宝的TDDL等等。

对于“外部XA”，MySQL服务器充当资源管理器，客户端程序充当事务管理器。对于“内部XA”，MySQL服务器中的存储引擎充当RM，而服务器本身充当TM。针对宕机后提交悬挂事务没有记录binlog继而导致主从数据不一致问题，可以将PREPARE成功的事务写日志，但并不是写在二进制日志中，而是写在每个对应分布式事务的单独文件中。

#### 性能

XA事务的性能很差，建议采用高性能的消息中间件处理分布式系统间的数据交互，以达到数据最终一致性。

注：虽然MySQL本身有XA实现分布式事务，但是GoldenDB等分布式数据库并不直接采用这种方案，原因是有并发等诸多弊端，但是可以参考其实现原理做改进。

#### 语法

​	分布式事务（XA事务）的SQL语法主要包括：

​	XA {START|BEGIN} xid {JOIN|RESUME}

​	XA END xid [SUSPEND[FOR MIGRATE]]

​	XA PREPARE xid

​	XA COMMIT xid [ONE PHASE]

​	XA ROLLBACK xid

​	XA RECOVER

 

## 方案

业界目前主流的分布式事务解决方案主要有：多阶段提交方案（2PC、3PC）、补偿事务（TCC）和消息事务（主要是RocketMQ，基本思想也是多阶段提交方案，并且基于中间提供件轮询和重试，其他消息队列中间件并没有实现分布式事务）。这些方案的原理在此处不展开，目前网络中相应资料比较多，小结一下它们的特点：

***\*多阶段提交方案\*******\*：\****常见的有二阶段和三阶段提交事务，需要额外的资源管理器来协调事务，数据一致性强，但是实现方案比较复杂，对性能的牺牲比较大（主要是需要对资源锁定，等待所有事务提交才能解锁），不适用于高并发的场景，目前比较知名的有阿里开源的fescar。

***\*补偿事务\*******\*：\****一般也叫TCC，因为每个事务操作都需要提供三个操作尝试（Try）、确认（Confirm）和补偿/撤销（Cancel），数据一致性的强度比多阶段提交方案低，但是实现的复杂度会有所降低，比较明显的缺陷是每个业务事务需要实现三组操作，有可能出现过多的补偿方案的代码；另外有很多场景TCC是不合适的。

***\*消息事务：\****这里只谈RocketMQ的实现，一个事务的执行流程包括：发送预消息、执行本地事务、确认消息发送成功。它的消息中间件存储了下游无法消费成功的消息，并且不断重试推送下游消费消息，而生产者（上游）需要提供一个check接口，用于检查成功发送预消息但是未确认最终消息发送状态的事务的状态。

 

分布式事务的解决方案有如下几种：

全局事务/两阶段提交(2PC)

基于可靠消息服务的分布式事务/基于RocketMQ

补偿事务TCC

最大努力通知

 

### 单阶段原子提交（1APC）

单阶段原子提交协议（one-phase atomic commit protocol，1APC）是最简单的一种原子提交协议，它通过设置一个协调者并让它不断地向所有参与者发送提交（commit）或放弃（abort）事务的请求，直到所有参与者确认已执行完相应的操作。

1APC协议的优点是简单易用，对一些事务不复杂的场景比较合适，但在复杂事务场景则显得捉襟见肘，因为该协议不允许任何服务器节点单方面放弃事务，事务的放弃必须由协调者来发起，这个设计会导致很多问题：首先因为只有一次通信，协调者并不会收集所有参与者的本地事务执行的情况，所以协调者决定提交还是放弃事务只基于自己的判断，在参与者执行事务期间可能会遇到错误从而导致最终事务未能真正提交，错误一般与事务的并发控制有关，比如事务执行期间对资源对象加锁，遇到死锁，需要放弃事务从而解开死锁，而协调者并不知道，因此在发起下一个请求之前，客户端完全不知道事务已被放弃。另一种情况就是利用乐观并发控制机制访问资源对象，某一个服务器节点的验证失败将导致事务被放弃，而协调者完全不知情。

 

### 两阶段提交（2PC）

#### 背景

两阶段提交协议（two-phase commit protocol, 2PC）的设计初衷是为了解决 1APC 不允许任意一个服务器节点自行放弃它自己的那部分本地事务的痛点，2PC 允许任何一个参与者自行决定要不要放弃它的本地事务，而由于原子提交协议的约束，任意一个本地事务被放弃将导致整个分布式事务也必须放弃掉。

#### 概述

##### 2PL/2PC

2PL，两阶段加锁协议：主要用于单机事务中的一致性与隔离性。

2PC，两阶段提交协议：主要用于分布式事务。

 

***\*什么时候加锁？\****

在对记录更新操作或者(select for update、lock in share model)时，会对记录加锁(有共享锁、排它锁、意向锁、gap锁、nextkey锁等等)。

 

##### XA

​	XA规范描述了全局的事务管理器与局部的资源管理器之间的接口。XA规范的目的是允许多个资源（如数据库，应用服务器，消息队列，等等）在同一事务中访问，这样可以使ACID属性跨越应用程序而保持有效。

2PC又叫XA Transaction，MySQL从5.5版本开始支持，Oracle7开始支持。XA使用两阶段提交（2PC）来保证所有资源同时提交或回滚任何特定的事务。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDDE.tmp.jpg) 

#### 原理

两阶段提交协议（two-phase commit protocol）的设计出发点是允许任何一个参与者自行放弃它自己的那部分事务。由于事务原子性的要求，如果部分事务被放弃，那么整个分布式事务也必须被放弃。

在该协议的第一个阶段，每个参与者投票表决该事务是放弃还是提交，一旦参与者要求提交事务，那么就不允许放弃该事务。因此，在一个参与者要求提交事务之前，它必须保证最终能够执行分布式事务中自己的那部分，即使该参与者出现故障而被中途替换掉。

一个事务的参与者如果最终能提交事务，那么可以说参与者处于事务的准备好（prepared）状态。为了保证能够提交，每个参与者必须将事务中所有发生改变的对象以及自身的状态（prepared）保存到持久性存储中。

在该协议的第二个阶段，事务的每个参与者执行最终统一的决定。如果任何一个参与者投票放弃事务，那么最终的决定是放弃事务。如果所有的参与者都投票提交事务，那么最终的决定是提交事务。

问题在于，要保证每个参与者都投票，并且达成一个共同的决定。在无故障时，该协议相当简单。但是，协议必须在出现各种故障（例如服务器崩溃，消息丢失或服务暂时无法通信）时能够正常工作。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDDF.tmp.jpg) 

##### 解释一

***\*正常情况：\****

为了实现两阶段提交协议，分布式事务中的协调者和参与者通常按照下面的接口进行通信：

canCommit（trans），协调者询问参与者是否可以提交事务，参与者回复自己的投票结果。

doCommit（trans），协调者告诉参与者提交它的那部分事务。

doAbort（trans），协调者告诉参与者放弃它的那部分事务。

haveCommitted（trans, participant），参与者用该操作向协调者确认它提交了事务。

getDecision（trans），当参与者在投Yes票后一段时间内未收到应答时，参与者用该操作向协调者询问事务的投票表决结果。该操作用于从服务器崩溃或从消息延迟中恢复。

 

***\*阶段一（投票阶段）：\****

协调者向分布式事务的所有参与者发送canCommit？请求

当参与者收到canCommit请求后，它向协调者回复自己的投票（Yes/No）。

在投Yes票之前，它在持久性存储中保存所有对象，准备提交。如果投No票，参与者立即放弃。

***\*阶段二（提交阶段）：\****

协调者收集所有的投票（包括它自己的投票）。

如果不存在故障并且所有的投票都是Yes时，那么协调者将决定提交事务并向所有参与者发送doCommit请求

否则，协调者决定放弃该事务，并向所有投Yes票的参与者发送doAbort请求

投Yes票的等待者等待协调者发送的doCommit或者doAbort请求。一旦参与者接收到任何一种请求消息，它将根据该请求放弃或者提交事务。如果请求是提交事务，那么他还要向协调者发送一个haveCommitted来确认事务已经提交。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDE0.tmp.jpg) 

***\*一方出现故障：\****

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDF0.tmp.jpg) 

##### 解释二

2PC（2：两阶段，P：准备阶段，C：提交阶段）即两阶段提交协议，分为两个阶段：

​	**第一阶段（提交请求阶段**prepare phase**）：**

1、协调者节点向所有参与者节点发送prepare消息，询问是否可以执行提交操作，并开始等待各参与者节点的响应。

2、参与者节点执行询问发起为止的所有事务操作，并***\*写本地\*******\*u\*******\*ndo/\*******\*r\*******\*edo日志\****，此时事务没有提交。（undo日志是记录修改前的数据，用于数据库回滚，redo日志是记录修改后的数据，用于提交事务后写入数据文件）

3、各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个"同意"消息；如果参与者节点的事务操作实际执行失败，则它返回一个"中止"消息。

**第二阶段 (提交执行阶段commit** **phase****)：**

如果协调者（事务管理器）收到了参与者的执行失败或者超时消息时，直接给每个参与者发送回滚（rollback）消息；否则，发行提交commit消息；参与者根据协调者（事务管理器）的指令执行提交或者回滚操作，并释放事务处理过程中使用的锁资源。注意：必须在最后阶段释放锁资源。

成功，当协调者节点从所有参与者节点获得的相应消息都为"同意"时：

1、协调者节点向所有参与者节点发出"正式提交"的请求。

2、参与者节点正式完成操作，并释放在整个事务期间内占用的资源。

3、参与者节点向协调者节点发送"完成"消息。

4、协调者节点收到所有参与者节点反馈的"完成"消息后，完成事务。

成功情况：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDF1.tmp.jpg) 

 

失败，如果任一参与者节点在第一阶段返回的响应消息为"终止"，或者协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：

1、协调者节点向所有参与者节点发出"回滚操作"的请求。

2、参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。

3、参与者节点向协调者节点发送"回滚完成"消息。

4、协调者节点收到所有参与者节点反馈的"回滚完成"消息后，取消事务。

失败情况：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDF2.tmp.jpg) 

有时候，第二阶段也被称作完成阶段，因为无论结果怎样，协调者都必须在此阶段结束当前事务。

#### 故障

在分布式事务中执行的过程中，可能出现磁盘故障，进程崩溃以及消息的丢失，超时等。

 

两阶段提交是一种***\*达成共识的协议\****，在该系统中，如果进程崩溃，那么是不可能达成共识的。但是，两阶段提交却是在这些条件下达成了共识，这是由于进程的崩溃被屏蔽，崩溃的进程被一个新的进程取代，新进程的状态根据持久性存储中保存的信息和其他进程拥有的信息来设定。

 

##### 模型

Lampson提出过一个分布式事务的故障模型，包括了硬盘故障、服务器故障以及通信故障。该故障模型声称：可以保证算法在出现故障时正确工作，但是对于不可预见的灾难性故障则不能正确处理。尽管会出现错误，但是可以在发生不正确行为之前发现并处理这些错误。Lampson的故障模型包括以下故障：

1、对持久性存储的***\*写操作可能发生故障\****（或因为写操作无效或因为写入错误的值）。例如，将数据写到错误的磁盘块被认为是灾难性故障。文件存储可能损坏。在持久性存储中读数据时可根据校验和来判断数据块是否损坏。

2、***\*服务器可能偶尔崩溃\****。当一个崩溃的服务器由一个新进程取代后，它的可变内存被重置，崩溃之前的数据均丢失。此后新进程执行一个可恢复过程，根据持久存储中的信息以及从其他进程获得的信息设置对象的值，包括两阶段提交协议有关对象的值。当一个处理器出现故障时，服务器也会崩溃，这样它就不会发送错误的信息或将错误的值写入持久存储，即它不会产生随机故障。服务器崩溃可能出现在任何时候，特别是在恢复时也可能出现。

3、***\*消息传递可能有任意长的延迟\****。消息可能丢失、重复或者损坏。接收方（通过校验和）能够检测到受损消息。未发现的受损消息和伪造的消息可能会导致灾难性故障。

利用这个关于持久性存储、处理器和通信的故障模型能够设计出一个可靠系统，该系统的组件可对付任何单一故障，并提供一个简单的故障模型。特别是，可靠存储（stable storage）可以在出现一个write操作故障或者进程崩溃的情况下提供原子写操作。它是通过将每一个数据块复制到两个磁盘上实现的。此时一个write操作用于两个磁盘块，在一个磁盘出现故障的前提下，另一个好的磁盘也可以提供正确数据。可靠处理器（stable processor）使用可靠存储，用于在崩溃之后恢复对象。可通过可靠的远程过程调用机制来屏蔽通信错误。

 

**两阶段提交协议的超时**

在两阶段协议的不同阶段，协调者或参与者都会遇到这种场景：不能处理它的那部分协议，直到接收到下一个请求或应答为止。

首先考虑这样的情形：某个投票者投Yes票并等待协调者发回最终决定，即告诉它是提交事务还是放弃事务。这样参与者的结果是不确定（uncertain）的，它在协调者处得到投票结果之前不能进行进一步处理。参与者不能单方面决定下一步做什么，同时该事务使用的对象也不能释放以用于其他事物。参与者向协调者发出getDecision请求来获取事务的结果，直到收到应答时，才能进入两阶段协议的第二阶段。

同理，如果协调者发生故障，那么参与者将不能获得协定，直到协调者被替代为止，这可能导致不确定状态的参与者长时间的延迟。

不依赖协调者获取最终决定的方法是通过参与者协作来获得决定。这种策略的优点是可以在协调者出故障时使用。

##### 处理

当参与者发生故障的时候：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDF3.tmp.jpg) 

当协调者发生故障的时候：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDDF4.tmp.jpg) 

#### 性能

假设一切运转正常，即协调者参与者不出现故障，通信也正常时，有N个参与者的两阶段提交协议需要N个canCommit消息和应答，然后再有N个doCommit消息。这样消息开销和3N成正比，时间开销是3次消息往返。由于协议在没有haveCommitted消息时仍可以正常运作（它们的作用只是通知服务器删除过时的协调者消息），因此在估计协议开销上，不将haveCommitted消息计算在内。

 

在最坏的情况下，两阶段提交协议在执行过程中可能出现任意多次服务器和通信故障。尽管协议不能指定协议完成的时间限制，但它能正确处理连续故障（服务崩溃或者消息丢失），并保证最终完成。

##### 网络I/O开销

假设两阶段提交过程一切运行正常，即协调者和参与者都不出现崩溃和重启，网络通信也都正常。那么假设有一个协调者和 N 个参与者，两阶段提交过程中将会发送如下的消息：

任意一个参与者从 working 状态进入 prepared 状态并发送 Prepared 消息给协调者，1 条消息。

协调者收到消息后，向其他参与者发送 canCommit? 请求消息，N - 1 条消息。

收到 canCommit? 消息的参与者各自回复协调者投票消息，N - 1 条消息。

协调者统计投票情况之后，发送 doCommit 消息给其他参与者，N 条消息。

所以，事务发起者在经过 4 条网络消息延迟之后确认该分布式事务已被提交，而整个过程共计发送 3N - 1 条网络消息（因为 haveCommitted 在 2PC 仅仅是用于最后通知协调者而已，属于可有可无的一次网络消息，2PC 在该消息缺省的情况下也能正常运行，因此 haveCommitted 一般不计入网络延迟成本中）。

在实践中一般是由协调者来发起事务，如果考虑这种情况的话，事务发起者 -- 协调者在经过 3 条网络消息延迟之后确认该分布式事务已经被提交，而整个过程实际发送的网络消息则变成 3N 条。

 

总而言之，两阶段提交协议的网络通信开销和集群节点的数量成 3 倍正比。

 

##### 本地存储设备I/O开销

基于两阶段提交协议的基本假设之一：每个节点会通过日志来记录在本地执行的操作，以便在节点发生故障并重启节点之后能利用日志恢复到故障前的状态，因此两阶段提交过程中除了网络 I/O 的开销之外，还有本地存储设备 I/O 的开销：

发起事务的参与者执行本地事务，1 次写操作。

其余参与者执行各自的本地事务，N - 1 次写操作。

协调者统计投票结果并决定提交事务，1 次写操作。

所以事务发起者在经过 3 次本地存储设备 I/O 延迟之后确认该事务已被提交，整个过程总计有 N + 1 次本地存储设备 I/O，而如果由协调者来发起事务的话，则还是需要 N + 1 次本地存储设备 I/O，但是只需要经过 2 次本地存储设备 I/O 延迟即可确认事务已被提交。

 

##### 恢复

在分布式事务中，所有的参与者节点都可能发生故障，所以我们需要保证在该故障节点恢复时发生的一切都和分布式事务 T 的全局决策保持一致。节点在恢复的时候会读取 T 的最后一个本地日志记录并作出相应的操作：

如果 T 的最后一条日志记录是 <commit T>，那么说明协调者在节点发生故障时的全局决策是提交 T，根据本地事务所使用的日志方式，在该节点上可能需要执行 redo T。

如果 T 的最后一条日志记录是 <abort T>，那么说明协调者在节点发生故障时的全局决策是中止 T，根据本地事务所使用的日志方式，在该节点上可能需要执行 undo T。

如果 T 的最后一条日志记录是 <don't commit T>，则和第 2 中情况类似，执行 undo T。

如果 T 的最后一条日志记录是 <ready T>，这种情况比较麻烦，因为恢复节点无法确认在它故障之后协调者发出的最终全局决策是什么，因此它必须要和集群中其余至少一个节点取得联系，询问 T 的最终结果是什么：恢复节点先尝试询问协调者，如果此时协调者正在工作，则告知恢复节点 T 的最终结果，如果是提交就执行 redo T，中止就执行 undo T；如果协调者因故不在工作，则恢复节点可以要求其他某一个参与者节点去查看本地日志以找出 T 的最终结果并告知恢复节点。在最坏的情况下，恢复节点无法和集群中其他所有节点取得联系，这时恢复节点只能阻塞等待，直至得知 T 的最终结果是提交还是中止。

如果本地日志中没有记录任何关于 T 在两阶段提交过程中的操作，那么根据前面的两阶段提交流程可知恢复节点还没来得及回复协调者的 canCommit? 请求消息就发生了故障，因此根据两阶段算法，恢复节点只能执行 undo T。

 

 

#### 特点

##### 优点

尽量保证了数据的强一致性，适合对数据强一致性要求很高的关键领域。

##### 缺点

主要缺点包括：

**1、*****\*协调者\****存在***\*单点故障\****（如果协调者出现故障，则某些参与者将一直无法收到提交或回滚的消息）。

由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）

2、***\*参与者\****存在***\*阻塞问题\****，参与者将协议消息发送给协调器后，它将阻塞直到收到提交或回滚，只能依赖协调者的超时机制。

当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。

3、可能存在***\*数据不一致\****（协调者向所有参与者发送提交请求，中间有网络问题，可能导致部分参与者节点没有成功提交事务）。

在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这会导致只有一部分参与者接受到了commit请求。

而在这部分参与者接到commit请求之后就会执行commit操作。但是其他部分未接到commit请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据不一致性的现象。

此外，该方案实现复杂，***\*牺牲了可用性，对性能影响较大，不适合高并发高性能的场景\****，如果分布式系统跨接口调用，目前.NET还没有实现方案。

***\*基于两阶段提交的下分布式事物，这类方案因为需要资源的全局锁定，导致性能极差\****，因此衍生了消息最终一致性、TCC、柔性事务等方案。

 

***\*两阶段提交无法解决的问题\*******\*：\****

当协调者出错，同时参与者也出错时，两阶段无法保证事务执行的完整性。

考虑协调者在发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。

那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。

 

#### 解决方案

https://www.cnblogs.com/dalianpai/p/12443676.html

##### XA方案

###### 背景

在生产环境的MySQL架构部署中，为了降低单点压力，通常会根据业务的特征情况，对数据进行分库分表，将数据拆分存储在不同的数据库实例中。由于多节点的存在，原来的本地事务已经不能支持此时的分布式应用场景。MySQL为我们提供了分布式事务解决方案-XA事务。

XA事务支持当前仅限于InnoDB存储引擎。XA支持分布式事务，即允许多个单独的事务资源参与全局事务的能力。事务资源通常是RDBMS，但可能是其他类型的资源。全局事务涉及多个事务本身的操作，但所有操作必须作为一个整体单元成功完成，或者全部作为一个整体单元回滚。

参考：

[https://mp.weixin.qq.com/s?__biz=MzU3NTcyNDc3OA==&mid=2247483834&idx=1&sn=d76b497e70025f9893fb4e97c4c3051d&chksm=fd1f8c3fca6805298ad1452901eaf0221c7157e0c9f89cea3bcfcd15c0aa2f7bf828cce2055d&mpshare=1&scene=24&srcid=0203pzzMo8U1Gb3SNBSOL8Ya&sharer_sharetime=1612282454956&sharer_shareid=33f795d236f19ac7c128b2e279563f84#rd](#rd)

###### 概述

2PC的传统方案是在数据库层面实现的，如Oracle、MySQL都支持2PC协议，为了统一标准减少行业内不必要的对接成本，需要制定标准化的处理模型及接口标准，国际开放标准组织Open Group定义了分布式事务处理模型DTP（Distributed Transaction Processing Reference Model）。

 

XA规范描述了全局的事务管理器与局部的资源管理器之间的接口。XA规范的目的是允许多个资源（如数据库，应用服务器，消息队列，等等）在同一事务中访问，这样可以使ACID属性跨越应用程序而保持有效。

XA使用两阶段提交（2PC）来保证所有资源同时提交或回滚任何特定的事务。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE05.tmp.jpg) 

​	执行流程如下：

1、 应用程序（AP）持有用户库和积分库两个数据源。

2、 应用程序（AP）通过TM通知用户库RM新增用户，同时通知积分库RM为该用户新增积分，RM此时并未提交事务，此时用户和积分资源锁定。

3、 TM收到执行回复，只要有一方失败则分别向其他RM发起回滚事务，回滚完毕，资源锁释放；

4、 TM收到执行回复，全部成功，此时向所有RM发起提交事务，提交完毕，资源锁释放。

DTP模型定义如下角色：

AP（Application Program）：即应用程序，可以理解为使用DTP分布式事务的程序。

RM（Resource Manager）：即资源管理器，可以理解为事务的参与者，一般情况下是指一个数据库实例，通过资源管理器对数据库进行控制，资源管理器控制着分支事务。

​	TM（Transacation Manager）：事务管理器，负责协调和管理事务，事务管理器控制着全局事务，管理事务生命周期，并协调各个RM。全局事务是指分布式事务处理环境中，需要操作多个数据库共同完成一个工作，这个工作即使一个全局事务。

​	DTP模型定义TM和RM之间通讯的接口规范叫***\*XA\****，简单理解为数据库提供的2PC接口协议，基于数据库的XA协议来实现2PC又称为XA方案。

​	以上三个角色之间交互方式如下：

1、 TM向AP提供应用程序编程接口，AP通过TM提交即回滚事务；

2、 TM交易中间件通过XA接口来通知RM数据库事务的开始、结束以及提交、回滚等。

###### 总结

整个2PC的事务流程涉及到三个角色AP、RM、TM。AP指的是使用2PC分布式事务的应用程序；RM指的是资源管理器，它控制着分支事务；TM指的是事务管理器，它控制着整个全局事务。

1、 在准备阶段RM执行实际的业务操作，但不提交事务，资源锁定；

2、 在提交阶段TM会接受RM在准备阶段的执行回复，只要有一个RM执行失败，TM会通知所有RM执行回滚操作，否则，TM将会通知所有RM提交该事务，提交阶段结束资源锁释放。

XA方案的问题：

1、 需要本地数据库支持XA协议；

2、 资源锁需要等到两个阶段结束才释放，性能较差。

##### Seata方案

##### Saga模式

#### 总结

​	两阶段提交这种解决方案属于***\*牺牲了一部分可用性来换取一致性\****。在实现方面，在.NET中，可以借助TransactionScop提供的API来编程实现分布式系统中的两阶段提交，比如WCF中就有实现这部分功能。不过在多个服务器之间，需要依赖于DTC来完成事务一致性，Windows下微软有MSDTC服务，Linux就悲催了。

​	TransactionScop默认不能用于异步方法之间事务一直，因为事务上下文是存储于当前线程中的，所以如果是在异步方法，需要显式地传递事务上下文。

 

**应用：**

​	在该分布式事务解决方案中，数据节点作为分布式事务参与者，负责保证自身数据操作的本地事务满足ACID属性，计算节点作为分布式事务协调者协调多个数据节点完成整个事务的控制，同时将全局事务状态记录在相应的全局事务管理单元中。

​	在该方案中，分布式事务与普通事务的区别在于所有的表中增加了gtid隐含列，该列在分布式事务中存放该全局事务ID（每个分布式写事务都会获取一个全局唯一且递增的整型值），在执行完所有的SQL操作后，所有的数据节点统一进行commit操作，如果有的存储节点commit提交失败，所有数据节点通过解析binlog来回滚事务。

分布式数据库OceanBase采用的是两阶段提交，但是并不会产生不一致的问题，因为它采用了Paxos协议，可以保证有可用的副本可以实现回滚操作，这是常规的数据库架构无法实现的。

​	

### 三阶段提交（3PC）

#### 概述

二阶段提交是解决分布式事务问题的重要理论基础，但也存在着明显的问题：

1、阻塞问题，参与者将协议消息发送给协调器后，它将阻塞直到收到提交或回滚，只能依赖协调者的超时机制

2、协调者单点问题，如果协调者出现故障，则某些参与者将一直无法收到提交或回滚的消息。

为了解决二阶段提交出现的问题，又有了三阶段提交（Three-phase commit）：

解决阻塞问题：将2PC中的第一阶段一分为二，提供了一个CanCommit阶段，此阶段并不锁定资源，这样可以大幅降低了阻塞概率

解决单点问题：在参与者这边也引入了超时机制。

 

​	三阶段提交（3PC）是二阶段提交的升级版本，包括预备阶段、准备阶段、提交阶段。在二阶段基础上，默认事务提交，从而减少数据不一致。

三阶段提交协议在协调者和参与者中都引入超时机制，并且把两阶段提交协议的第一个阶段分成了两步：询问，然后再锁资源，最后真正提交。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE06.tmp.jpg) 

#### 原理

1、canCommit阶段

3PC的canCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回yes响应，否则返回no响应

2、preCommit阶段

协调者根据参与者canCommit阶段的响应来决定是否可以继续事务的preCommit操作。根据响应情况，有下面两种可能：

a) 协调者从所有参与者得到的反馈都是yes：

那么进行事务的预执行，协调者向所有参与者发送preCommit请求，并进入prepared阶段。参与者和接收到preCommit请求后会执行事务操作，并将undo和redo信息记录到事务日志中。如果一个参与者成功地执行了事务操作，则返回ACK响应，同时开始等待最终指令

b) 协调者从所有参与者得到的反馈有一个是No或是等待超时之后协调者都没收到响应:

那么就要中断事务，协调者向所有的参与者发送abort请求。参与者在收到来自协调者的abort请求，或超时后仍未收到协调者请求，执行事务中断。

3、doCommit阶段

协调者根据参与者preCommit阶段的响应来决定是否可以继续事务的doCommit操作。根据响应情况，有下面两种可能：

 

a) 协调者从参与者得到了ACK的反馈：

协调者接收到参与者发送的ACK响应，那么它将从预提交状态进入到提交状态，并向所有参与者发送doCommit请求。参与者接收到doCommit请求后，执行正式的事务提交，并在完成事务提交之后释放所有事务资源，并向协调者发送haveCommitted的ACK响应。那么协调者收到这个ACK响应之后，完成任务。

b) 协调者从参与者没有得到ACK的反馈, 也可能是接收者发送的不是ACK响应，也可能是响应超时：

执行事务中断。

#### 故障

#### 特点

##### 优点

PreCommit是一个缓冲，保证了在最后提交阶段之前各参与节点的状态是一致的。

注：这种PreCommit的设置解决了两阶段中协调者和参与者都发生故障时数据不一致的问题，即在PreCommit的时候就将这种情况处理了。

##### 缺点

可能导致数据不一致：

如果进入PreCommit后，Coordinator发出的是abort请求，假设只有一个Cohort收到并进行了abort操作，

而其他对于系统状态未知的Cohort会根据3PC选择继续Commit，此时系统状态发生不一致性。

 

***\*替代方案：\****

目前还有一种重要的算法就是Paxos算法，Zookeeper采用的就是Paxos算法的改进。

#### 性能

#### 总结

### 补偿事务（TCC）

TCC事务机制相对于传统事务机制（X/Open XA），其特征在于它不依赖资源管理器(RM)对XA的支持，而是***\*通过对（由业务系统提供的）业务逻辑的调度来实现分布式事务\****。

TCC属于业务有侵入的（这个需要业务层面编写大量代码控制事务的各个阶段）。

对于业务系统中一个特定的业务逻辑S，其对外提供服务时，必须接受一些不确定性，即对业务逻辑执行的一次调用仅是一个临时性操作，调用它的消费方服务M保留了后续的取消权。如果M认为全局事务应该rollback，它会要求取消之前的临时性操作，这就对应S的一个取消操作。而当M认为全局事务应该commit时，它会放弃之前临时性操作的取消权，这对应S的一个确认操作。 每一个初步操作，最终都会被确认或取消。因此，针对一个具体的业务服务，TCC事务机制需要业务系统提供三段业务逻辑：初步操作Try、确认操作Confirm、取消操作Cancel。

在传统事务机制中，业务逻辑的执行和事务的处理，是在不同的阶段由不同的部件来处理的：业务逻辑部分访问资源实现数据存储，其处理是由业务系统负责；事务处理部分通过协调资源管理器以实现事务管理，其处理由事务管理器来负责。二者没有太多交互的地方，所以，传统事务管理器的事务处理逻辑，仅需要着眼于事务完成（commit/rollback）阶段，而不必关注业务执行阶段。而在TCC事务机制中的业务逻辑和事务处理，其关系就错综复杂：业务逻辑（Try/Confirm/Cancel）阶段涉及所参与资源事务的commit/rollback；全局事务commit/rollback时又涉及到业务逻辑（Try/Confirm/Cancel）的执行。

 

蚂蚁金服大部分业务系统均采用TCC的方式接入分布式事务，但设计TCC服务时要遵循大量设计规范，这无疑对用户提了非常高的要求；
	为了简化用户接入分布式事务的门槛，蚂蚁金服的分布式事务框架（SOFA-DTX）推出了FMT（Framework-managed transactions）模式和XA模式，这两种模式均不需要用户实现TCC服务，用户只需要关注自身业务SQL便可；
	DTX的三种模式：TCC、FMT和XA相互之间是功能互补，相辅相成的，形成了蚂蚁金服完善的分布式事务解决方案。
	SOFA-DTX全面覆盖金融场景，金融级容灾保障、提供丰富的接入模式并且使用简洁易于接入；目前已经应用在支付宝、网上银行、蚂蚁财富、芝麻信用、南京银行等项目中。

 

#### 概述

TCC即为Try Confirm Cancel（预处理，确认，撤销），它属于***\*补偿型分布式事务\****。

补偿交易，其核心思想是：***\*针对每个操作，都要注册一个与其对应的补偿操作\****。一般来说操作本身和其补偿（撤销）操作会在一个事务里完成。

当其后续操作失败后，需要按相反顺序完成前面注册的所有撤销操作。

 

TCC（Try-Confirm-Cancel）实际上是***\*服务化的两阶段提交协议\****，业务开发者需要实现这三个服务接口，第一阶段服务由业务代码编排来调用 Try 接口进行资源预留，所有参与者的 Try 接口都成功了，事务管理器会提交事务，并调用每个参与者的 Confirm 接口真正提交业务操作，否则调用每个参与者的 Cancel 接口回滚事务。

##### 2PC

***\*跟2PC比，\*******\*它\*******\*的核心价值应该是少了锁资源的代价\****。流程也相对简单一点。但实际操作中，补偿操作不太好定义，其中间状态处理也会比较棘手（可以通过全局事务ID实现回滚）。

注：***\*两阶段和三阶段耗时的部分在于等待各个节点反馈信息，如果某个节点延时则需要一直等待，性能差。TCC假设大多数的写都不会超时，不去等待所有节点返回再提交，而是发下去就各自提交，最后出现了rollback，业务层再在最后阶段统一处理。这样如果不出现回滚，则速度很快，就算出现了超时，也在最后阶段处理\****。

 

一个分布式的全局事务，整体是两阶段提交的模型。全局事务是由若干分支事务组成的，分支事务要满足两阶段提交的模型要求，即需要每个分支事务都具备自己的：

1、一阶段prepare 行为

2、二阶段commit或rollback行为

TCC模式，不依赖于底层数据资源的事务支持：

1、一阶段prepare行为：调用自定义的prepare逻辑。

2、二阶段commit行为：调用自定义的commit逻辑。

3、二阶段rollback行为：调用自定义的rollback逻辑。

所谓TCC模式，是指支持把自定义的分支事务纳入到全局事务的管理中。

注：可以这样理解，两阶段本身是基于底层的redo/undo去实现事务的ACID，但是TCC不是基于此，而是业务控制事务什么时候提交，什么时候回滚，怎么回滚（利用GTID），底层执行的是对应业务下发的commit/rollback语句。

##### XA

和XA协议的区别：

1、XA是数据库层面实现的协议，TCC是业务层面实现的框架

2、XA是两阶段提交，是悲观的，TCC在业务层面是乐观的，全局不满足条件（有提交失败）才会回滚

##### 实现思想

TCC解决分布式事物的思路是，一个大事务拆解成多个小事务。

TCC要求每个分支事务实现三个操作：预处理Try、确认Confirm、撤销Cancel。Try操作做业务检查及资源预留，Confirm做业务确认操作，Cancel实现一个与Try相反的操作即回滚操作。TM首先发起所有的分支事务的try操作，任何一个分支事务的try操作执行失败，TM将会发起所有分支事务的cancel操作，若try操作全部成功，TM将会发起所有分支事务的confirm操作，其中confirm/cancel操作若执行失败，TM会进行重试。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE07.tmp.jpg) 

***\*分支事务执行成功：\****

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE18.tmp.jpg) 

​	***\*分支事务执行失败：\****

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE19.tmp.jpg) 

 

接入TCC前，业务操作只需要一步就能完成，但是在接入TCC之后，需要考虑如何将其分成2阶段完成，把资源的检查和预留放在一阶段的Try操作中进行，把真正的业务操作的执行放在二阶段的Confirm操作中进行；

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE1A.tmp.jpg) 

TCC服务要保证第一阶段Try操作成功之后，二阶段Confirm操作一定能成功。

 

#### 原理

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE1B.tmp.jpg) 

比如跨银行转账的时候，要涉及到两个银行的分布式事务，如果用TCC方案来实现，思路是这样的；

1、Try阶段：先把两个银行账户中的资金给它冻结住就不让操作了

2、Confirm阶段：执行实际的转账操作，A银行账户的资金扣减，B银行账户的资金增加

3、Cancel阶段：如果任何一个银行的操作执行失败，那么就需要回滚进行补偿，就是比如A银行账户如果已经扣减了，但是B银行账户资金增加失败了，那么就得把A银行账户资金给加回去。

另一种解释：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE2B.tmp.jpg) 

顾名思义，TCC实现分布式事务一共有三个步骤：

1、Try：尝试待执行的业务

这个过程并未执行业务，只是完成所有业务的***\*一致性检查及资源预留（隔离）\****，并***\*锁定和预留好执行所需的全部资源\****。它和后续的confirm一起才能真正构成一个完整的业务逻辑。

注：主要检测资源是否可用，例如检查账户余额是否足够，缓存，数据库，队列是否可用等等，并不执行具体的逻辑。

2、Confirm：执行业务

这个过程真正开始执行业务，由于Try阶段已经完成了一致性检查，因此本过程直接执行，而***\*不做任何检查\****。并且在执行的过程中，会使用到Try阶段预留的业务资源。通常，采用TCC则认为Confirm阶段是不会出错的，即：只要try成功，Confirm一定成功若confirm阶段真的出错了，需要引入重试机制或人工处理。

3、Cancel：取消执行的业务

若业务执行失败，则进入Cancel阶段，它会释放所有占用的业务资源，并回滚Confirm阶段执行的操作。

采用TCC则认为cancel阶段也一定是成功的，若cancel阶段真的出错了，需要引入重试机制或人工处理。

 

***\*拓展：TM事务管理器\****

TM事务管理器可以实现为独立的服务，也可以让全局事务发起方充当TM的角色，TM独立出来是为了称为共用组件，是为了考虑系统结构和软件的复用。

TM在发起全局事务时生成全部事务记录，全局事务ID贯穿整个分布式事务调用链条，用来记录事务上下文、追踪和记录状态，由于confirm和cancel失败需要进行重试，因此需要实现为幂等，幂等性是指同一个操作无论请求多少次，其结果都相同。

 

**TCC全局事务必须基于RM本地事务来实现全局事务**

TCC服务是由Try/Confirm/Cancel业务构成的，

其Try/Confirm/Cancel业务在执行时，会访问资源管理器（Resource Manager，下文简称RM）来存取数据。这些存取操作，必须要参与RM本地事务，以使其更改的数据要么都commit，要么都rollback。



|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE2C.tmp.jpg) |

这一点不难理解，考虑一下如下场景：



假设图中的服务B没有基于RM本地事务（以RDBS为例，可通过设置auto-commit为true来模拟），那么一旦[B:Try]操作中途执行失败，TCC事务框架后续决定回滚全局事务时，该[B:Cancel]则需要判断[B:Try]中哪些操作已经写到DB、哪些操作还没有写到DB：假设[B:Try]业务有5个写库操作，[B:Cancel]业务则需要逐个判断这5个操作是否生效，并将生效的操作执行反向操作。

不幸的是，由于[B:Cancel]业务也有n（0<=n<=5）个反向的写库操作，此时一旦[B:Cancel]也中途出错，则后续的[B:Cancel]执行任务更加繁重。因为，相比第一次[B:Cancel]操作，后续的[B:Cancel]操作还需要判断先前的[B:Cancel]操作的n（0<=n<=5）个写库中哪几个已经执行、哪几个还没有执行，这就涉及到了幂等性问题。而对幂等性的保障，又很可能还需要涉及额外的写库操作，该写库操作又会因为没有RM本地事务的支持而存在类似问题。可想而知，如果不基于RM本地事务，TCC事务框架是无法有效的管理TCC全局事务的。

反之，基于RM本地事务的TCC事务，这种情况则会很容易处理：[B:Try]操作中途执行失败，TCC事务框架将其参与RM本地事务直接rollback即可。后续TCC事务框架决定回滚全局事务时，在知道“[B:Try]操作涉及的RM本地事务已经rollback”的情况下，根本无需执行[B:Cancel]操作。

换句话说，基于RM本地事务实现TCC事务框架时，一个TCC型服务的cancel业务要么执行，要么不执行，不需要考虑部分执行的情况。

 

**TCC事务框架应该提供Confirm/Cancel服务的幂等性保障**

一般认为，服务的幂等性，是指针对同一个服务的多次(n>1)请求和对它的单次(n=1)请求，二者具有相同的副作用。

在TCC事务模型中，Confirm/Cancel业务可能会被重复调用，其原因很多。比如，全局事务在提交/回滚时会调用各TCC服务的Confirm/Cancel业务逻辑。执行这些Confirm/Cancel业务时，可能会出现如网络中断的故障而使得全局事务不能完成。因此，故障恢复机制后续仍然会重新提交/回滚这些未完成的全局事务，这样就会再次调用参与该全局事务的各TCC服务的Confirm/Cancel业务逻辑。

既然Confirm/Cancel业务可能会被多次调用，就需要保障其幂等性。

那么，应该由TCC事务框架来提供幂等性保障？还是应该由业务系统自行来保障幂等性呢？

个人认为，应该是由TCC事务框架来提供幂等性保障。如果仅仅只是极个别服务存在这个问题的话，那么由业务系统来负责也是可以的；然而，这是一类公共问题，毫无疑问，所有TCC服务的Confirm/Cancel业务存在幂等性问题。TCC服务的公共问题应该由TCC事务框架来解决；而且，考虑一下由业务系统来负责幂等性需要考虑的问题，就会发现，这无疑增大了业务系统的复杂度。

 

#### 解决方案

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE2D.tmp.jpg) 

云服务方案：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE2E.tmp.jpg) 

##### tcc-transaction

##### Hmily

##### ByteTCC

##### EasyTransaction

#### 异常

https://mp.weixin.qq.com/s/7fbCbqCOaSMFHQFLA9Oi7Q

 

用户在实现TCC服务时，有以下注意事项：

##### 空回滚

事务协调器在调用TCC服务的一阶段Try操作时，可能会出现因为丢包而导致的网络超时，此时事务协调器会触发二阶段回滚，调用TCC服务的Cancel操作；

TCC服务在未收到Try请求的情况下收到Cancel请求，这种场景被称为空回滚；TCC服务在实现时应当允许空回滚的执行。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE3F.tmp.jpg) 

 

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE40.tmp.jpg) 

​	在没有调用TCC资源Try方法的情况下，调用了二阶段的cancel方法，cancel方法需要识别出这事个空回滚，然后直接返回成功。

​	***\*出现原因\*******\*：\****是当一个分支事务所在的服务宕机或者网络异常，分支事务调用记录为失败，这个时候其实是没有执行try阶段，当故障恢复后，分布式事务进行回滚则会调用二阶段的cancel方法，从而形成空回滚。

​	***\*解决思路\*******\*：\****要识别出这个空回滚。思路就是***\*需要知道一阶段是否执行，如果执行了，就是正常回滚；如果没有执行，那就是空回滚\****。TM在发起全局事务时生成全部事务记录，***\*全局事务ID（gtid）\****贯穿整个分布式事务调用链条。再额外增加一张分支事务记录表，其中有全部事务ID和分支事务ID，第一阶段Try方法里会插入一条记录，表示一阶段执行了。Cancel接口里读取该记录，如果该记录存在，则正常回滚；如果该记录不存在，则是空回滚。

 

##### 幂等

无论是网络数据包重传，还是异常事务的补偿执行，都会导致TCC服务的Try、Confirm或者Cancel操作被重复执行；用户在实现TCC服务时，需要考虑幂等控制，即Try、Confirm、Cancel 执行一次和执行多次的业务结果是一样的。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE41.tmp.jpg) 

 

​	为了保证TCC二阶段提交重试机制不会引发数据不一致，要求TCC的二阶段try、confirm、cancel接口保证幂等，这样不会重复使用或者释放资源。如果幂等控制没有做好，很有可能导致数据不一致等严重问题。

​	解决思路：在上述“分支事务记录”中增加执行状态，每次执行前都查询该状态。

注：比如查阅活跃GTID。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE42.tmp.jpg) 

##### 悬挂

事务协调器在调用TCC服务的一阶段Try操作时，可能会出现因网络拥堵而导致的超时，此时事务协调器会触发二阶段回滚，调用TCC服务的Cancel操作；在此之后，拥堵在网络上的一阶段Try数据包被TCC服务收到，出现了二阶段Cancel请求比一阶段Try请求先执行的情况；

用户在实现TCC服务时，应当允许空回滚，但是要拒绝执行空回滚之后到来的一阶段Try请求。

 

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE53.tmp.jpg) 

​	悬挂就是对于一个分布式事务，其二阶段cancel接口比try接口先执行。

​	出现原因是在RPC调用分支事务try时，先注册分支事务，再执行RPC调用，如果此时RPC调用的网络发生拥堵，通常RPC调用是有超时时间的，RPC超时以后，TM就会通知RM回滚该分布式事务，可能回滚完成后，RPC请求才到达真正参与者真正执行，而一个try方法预留的业务资源，只有该分布式事务才能使用，该分布式事务第一阶段预留的业务资源就再也没有人能够处理了，对于这种情况，我们就称为悬挂，即业务资源预留后没法继续处理。

​	***\*解决思路\*******\*：\****如果二阶段执行完成，那一阶段就不能再继续执行。在执行一阶段事务时判断在该全局事务下，“分支事务记录”表中是否已经有二阶段事务记录，如果有则不执行try。

#### 注意事项

除了上述空回滚、幂等、悬挂问题，TCC还需要考虑：

##### 业务数据可见性控制

TCC服务的一阶段Try操作会做资源的预留，在二阶段操作执行之前，如果其他事务需要读取被预留的资源数据，那么处于中间状态的业务数据该如何向用户展示，需要业务在实现时考虑清楚；通常的设计原则是“宁可不展示、少展示，也不多展示、错展示”。

 

##### 业务数据并发访问控制

TCC服务的一阶段Try操作预留资源之后，在二阶段操作执行之前，预留的资源都不会被释放；如果此时其他分布式事务修改这些业务资源，会出现分布式事务的并发问题；

用户在实现TCC服务时，需要考虑业务数据的并发控制，尽量将逻辑锁粒度降到最低，以最大限度的提高分布式事务的并发性。

 

实现TCC需要关注以下几个方面：

1、TCC模式在于服务层面而非数据库层面

2、TCC模式依赖于各服务正确实现Try、Confirm、Cancel和timeout处理机制

3、TCC模式最少通信次数为2n（n=服务数量）

4、不是所有业务模型都适合使用TCC，比如发邮件业务根本就不需要预留资源

5、需要良好地设计服务的日志、人工处理流程/机制，便于异常情况的处理

 

#### 特点

##### 优点

没有单独的准备（prepare）阶段，try操作兼具资源操作与准备能力；

Try操作可以灵活选择业务资源的锁定粒度。

##### 缺点

1、对业务的侵入性较大，所有业务逻辑都要有反向操作

2、只能提供最终一致性，不能提供强一致性，处理过程中数据存在短暂不一致

3、最终一致性，且不存在回滚机制，某些情况下部分独立的子事务由于数据校验或其他原因无法成功实施时，导致子过程不断重试并不断失败，必须人为干预才能解决。

较高的开发成本。

成本包括：

1、实现TCC操作的成本；

2、业务活动结束时confirm或cancel操作的执行成本；

3、业务活动日志成本。

 

综上，该方案使用范围：

1、强隔离性、严格一致性要求的业务活动；

2、适用于执行时间较短的业务。

 

#### 实例

下面以一个转账的例子来解释下TCC实现分布式事务的过程。

假设用户A用他的账户余额给用户B发一个100元的红包，并且余额系统和红包系统是两个独立的系统。

**Try**

创建一条转账流水，并将流水的状态设为交易中

将用户A的账户中扣除100元（预留业务资源）

Try成功之后，便进入Confirm阶段

Try过程发生任何异常，均进入Cancel阶段

**Confirm**

向B用户的红包账户中增加100元

将流水的状态设为交易已完成

Confirm过程发生任何异常，均进入Cancel阶段

Confirm过程执行成功，则该事务结束

**Cancel**

将用户A的账户增加100元

将流水的状态设为交易失败

在传统事务机制中，业务逻辑的执行和事务的处理，是在不同的阶段由不同的部件来完成的：业务逻辑部分访问资源实现数据存储，其处理是由业务系统负责；事务处理部分通过协调资源管理器以实现事务管理，其处理由事务管理器来负责。二者没有太多交互的地方，所以，传统事务管理器的事务处理逻辑，仅需要着眼于事务完成（commit/rollback）阶段，而不必关注业务执行阶段。

 

还是以转账的例子为例，在跨银行进行转账的时候，需要涉及到两个银行的分布式事物，从A银行向B银行转1块，如果用TCC方案来实现：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE54.tmp.jpg) 

大概思路就是这样的：

1、Try阶段：先把A银行账户先冻结1块，B银行账户中的资金给预加1块。

2、Confirm阶段：执行实际的转账操作，A银行账户的资金扣减1块，B银行账户的资金增加1块。

3、Cancel阶段：如果任何一个银行的操作执行失败，那么就需要回滚进行补偿，就是比如A银行账户如果已经扣减了，但是B银行账户资金增加失败了，那么就得把A银行账户资金给加回去。

 

#### 适用场景

这种方案说实话几乎很少有人使用，我们用的也比较少，但是也有使用的场景。

因为这个事务回滚实际上是严重依赖于你自己写代码来回滚和补偿了，会造成补偿代码巨大，非常之恶心。

比如说我们，一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，我们会用TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性，在资金上不允许出现问题。

比较适合的场景：除非你是真的一致性要求太高，是你系统中核心之核心的场景，比如常见的就是资金类的场景，那你可以用TCC方案了。

你需要自己编写大量的业务逻辑，自己判断一个事务中的各个环节是否ok，不ok就执行补偿/回滚代码。

而且最好是你的各个业务执行的时间都比较短。

但是说实话，一般尽量别这么搞，自己手写回滚逻辑，或者是补偿逻辑，实在太恶心了，那个业务代码很难维护。

### Saga事务模型

#### 原理

Saga是一种***\*补偿协议\****，在Saga模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。

分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE55.tmp.jpg) 

Saga模式下分布式事务通常是由事件驱动的，各个参与者之间是异步执行的，Saga模式是一种长事务解决方案。

#### 特点

##### 优点

一阶段提交本地数据库事务，无锁，高性能；

参与者可以采用事务驱动异步执行，高吞吐；

补偿服务即正向服务的“反向”，易于理解，易于实现。

##### 缺点

Saga模式由于一阶段已经提交本地数据库事务，且没有进行“预留”动作，所以不能保证隔离性。

 

### TX-LCN

### 可靠消息最终一致性

#### 概述

​	可靠消息最终一致性方案是指当事务发起方执行完成本地事务后并发出一条消息，事务参与方（消息消费者）一定能够接受消息并处理事务成功，该方案强调的是只要消息发送给事务参与方最终事务要达到一致。

​	事务发起方（消费生产方）将消息发送给消息中间件，事务参与方从消息中间件接受消息，事务发起方和消息中间件之间，事务参与方（消息消费方）和消息中间件之间都是通过网络通信，由于网络通信的不确定性会导致分布式事务问题。

因此可靠消息最终一致性方案要解决以下几个问题：

1、本地事务与消息发送的原子性问题

本地事务与消息发送的原子性问题即，事务发起方在本地事务执行成功后消息必须发出去，否则就丢弃消息。即实现本地事务和消息发送的原子性，要么成功，要么都失败。本地事务与消息发送的原子性问题是实现可靠消息最终一致性方案的关键问题。

如果发送MQ消息失败，就会抛出异常，导致数据库事务回滚，这样看似没有问题。但是，如果是超时异常，但MQ其实已经正常发送了，同样会导致不一致。

2、事务参与方接收消息的可靠性

事务参与方必须能够从消息队列接收到消息，如果接收消息失败可以重复接收消息。

3、消息重复消费问题

由于网络问题的存在，若某一个消费节点超时但是消费成功，此时消息中间件会重复投递此消息，就导致消息的重复消费。要解决消息重复消费的问题就要实现事物参与方的方法幂等性。

#### 原理

整个流程图如下所示：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE65.tmp.jpg) 

我们来解释一下这个方案的大概流程：

1、A系统先发送一个prepared消息到mq，如果这个prepared消息发送失败那么就直接取消操作别执行了，后续操作都不再执行

2、如果这个消息发送成功过了，那么接着执行A系统的本地事务，如果执行失败就告诉mq回滚消息，后续操作都不再执行

3、如果A系统本地事务执行成功，就告诉mq发送确认消息

4、那如果A系统迟迟不发送确认消息呢？

此时mq会自动定时轮询所有prepared消息，然后调用A系统事先提供的接口，通过这个接口反查A系统的上次本地事务是否执行成功

如果成功，就发送确认消息给mq；失败则告诉mq回滚消息（后续操作都不再执行）

5、此时B系统会接收到确认消息，然后执行本地的事务，如果本地事务执行成功则事务正常完成

6、如果系统B的本地事务执行失败了咋办？

基于mq重试咯，mq会自动不断重试直到成功，如果实在是不行，可以发送报警由人工来手工回滚和补偿

#### 特点

##### 优点

这种方案的优点就是可以基于MQ来进行不断重试，最终一定会执行成功的。

因为一般执行失败的原因是网络抖动或者数据库瞬间负载太高，都是暂时性问题。

通过这种方案，99.9%的情况都是可以保证数据最终一致性的，剩下的0.1%出问题的时候，就人工修复数据。

##### 缺点

1、对业务的侵入性比较大，需要将业务逻辑分解成独立异步执行的子过程，且其他业务逻辑要对这种延后的数据更新不敏感

2、可切分性和不敏感性限制了可以实施的操作的多样性和复杂度，对业务功能的开发有较大限制

3、只能提供最终一致性，不提供强一致性，自然无法提供有效地隔离性

4、最终一致性，且不存在回滚机制，在某些情况下部分独立的渍食物由于数据校验或其他原因无法成功实施时，导致子过程不断重试并不断失败，必须认为干预才能解决

注：基于MQ的方案，需要注意消息重复投递，幂等性等问题。

#### 解决方案

基于消息异步处理的方案包括基于数据库消息列表、基于消息队列两种方案，实现思路基本相同，但由于基于数据库消息列表的方案在高并发场景下，仍然存在吞吐量方面的瓶颈，所以目前互联网公司基本都采用基于消息队列的异步处理方案。该方案的设计原理是将分布式事务涉及的过程按照节点和逻辑分解为多个子事务或子过程，每个子事务独立实施，并确保这些独立的子事务一旦成功创建，一定会全部实施成功，不会失败。

基于消息队列的异步事务处理是通过牺牲分布式事务的实时一致性和隔离性，以获得最终一致性为设计目标的。需要对原有业务逻辑进行调整，需要调整的业务可以按照类型划分为三个部分：

1、交易过程。将原来的业务交易逻辑分解为可以满足ACID特性的独立子事务（或称子过程），并将这些独立子事务写入消息队列和数据库的事务登记表中。全部写入成功后就可以认为交易完成，可以开始后继的其他业务逻辑。

2、后继逻辑。后继的其他业务逻辑需要进行相应的调整，以满足这样的一个基本假设，即交易过程已经成功实施，但数据库中的相关数据尚未及时变更，系统要确保最终一定可以成功变更。

3、更新过程。消息队列触发业务实施一个个独立的子事务，收到消息后就会在本地的消息记录表登记，从而保证子事务不丢失。成功执行子事务后就在本地的消息记录表中更新消息状态，从而保证子事务不会重复执行。

基于消息队列的异步事务处理方案能够确保数据的最终一致性，是互联网应用使用较多的一种方法，但是存在诸多风险。

 

##### 本地消息表（异步确保）

考虑这样一种业务场景，系统A调用系统B的退款服务进行退款，系统A更改内部退款状态，接着调用系统C的短信服务通知用户。

 

在这样的一个场景下，由于网络不可靠的必然存在，存在A、B、C三个系统之间一致性的问题。

 

本地表

针对上述场景，设计两张表：退款记录表和短信发送记录表以及相应的补偿Job。

具体实现过程：

1、新增退款记录表，状态为处理中

2、调用系统B的退款服务进行退款

3、更新退款记录状态为对应的状态（成功/失败）

4、如果退款成功，则新增短信发送记录，记录状态为待发送

5、调用系统C的短信服务，发送短信

6、更新短信发送记录为已发送

 

退款补偿Job，查询退款记录表中处理中的记录，调用系统B的退款服务，退款

成功处理：

1、新增短信发送记录，记录状态为待发送

2、调用系统C的短信服务，发送短信

3、更新短信发送记录为已发送

 

短信通知补偿Job，查询短信发送记录中待发送的记录，调用系统C的短信服务：

1、调用系统C的短信服务，发送短信

2、更新短信发送记录为已发送

 

注意：

1、系统B和系统C需要根据调用方传的uuid支持幂等

2、系统A、B、C会出现短暂的不一致，但最终一致

 

##### *MQ事务消息*

可以将其视为两阶段提交消息实现，以确保分布式系统中的最终一致性。事务性消息可确保本地事务的执行和消息的发送可以原子方式执行。

 

但是由于事务消息异步的特性，调用方拿不到消费方的处理结果，适用于不关心对方的返回结果/对方负责保证处理成功。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE66.tmp.jpg) 

针对上述场景，增加两个事务消息的方式解决一致性问题，系统A通过发送事务消息的方式与系统B和系统C进行交互。

 

具体实现过程：

1、发送退款的事务消息

2、新增退款记录，状态为：处理中

3、Commit退款事务消息

 

提供MQ事务callback：

1、退款callback查询：

有退款记录且为处理中则Commit

其他则Rollback

2、发送短信callback查询：

有退款记录且成功则Commit

其他则Rollback

 

退款同步Job，查询退款记录表中处理中的记录，调用系统B的退款查询接口同步状态，其中退款成功处理：

1、发送短信的事务消息

2、更新退款记录为成功

3、Commit短信事务消息

 

###### 消息队列

由于分布式事务存在严重的性能问题，在设计高并发服务的时候，往往通过其他途径来解决数据一致性问题。

举例来讲，你在北京很有名的姚记炒肝点了炒肝并付了钱后，他们并不会直接把你点的炒肝给你，而是给你一张小票，然后让你拿着小票到出货区排队去取。为什么他们要将付钱和取货两个动作分开呢？原因很多，其中一个很重要的原因是为了使他们接待能力增强（并发量更高）。

还是回到我们的问题，只要这张小票在，你最终是能拿到炒肝的。同理转账服务也是如此，当支付宝账户扣除1万后，我们只要生成一个凭证（消息）即可，这个凭证（消息）上写着“让余额宝账户增加 1万”，只要这个凭证（消息）能可靠保存，我们最终是可以拿着这个凭证（消息）让余额宝账户增加1万的，即我们能依靠这个凭证（消息）完成最终一致性。

 

这样我们上述的转账就变成了如下过程：

支付宝在扣款事务提交之前，向消息队列发送消息。此时的消息队列只记录消息，而并没有将消息发往余额宝。

当支付宝扣款事务提交成功，向消息队列发送确认。在得到确认的指令后，消息队列向该消息发往余额宝。

当支付宝扣款事务提交失败，向消息队列发送取消。在得到取消的指令后，消息队列取消该消息，该消息将不会被发送。

对于那么未确认的消息，需要消息队列去支付宝系统查询这个消息的状态，并进行更新。（因为支付宝可能在扣款事务提交成功后挂掉，此时消息的状态未被更新为：“确认发送“。从而导致消息不能被发送。）

 

###### 重复投递

还有一个严重的问题是消息重复投递，以我们支付宝转账到余额宝为例，如果相同的消息被重复投递两次，那么我们余额宝账户将会增加2万而不是1万了。

###### RocketMQ

这种方案，跟上面的独立消息服务一致，这里直接去掉独立服务，只利用消息队列来实现，也就是阿里的 RocketMQ 。

流程图如下：



|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE67.tmp.jpg) |

这里的整个流程跟上面基于消息服务是一致的。这里就不过多阐述，具体代码实现请参考 ：https://www.jianshu.com/p/453c6e7ff81c[5] ，写得非常好。



 

针对这里的可靠消息最终一致性方案来说，我们说的可靠是指保证消息一定能发送到消息中间件里面去，保证这里可靠。

对于下游的系统来说，消费不成功，一般来说就是采取失败重试，重试多次不成功，那么就记录日志，后续人工介入来进行处理。所以这里得强调一下，后面的系统，一定要处理 幂等，重试，日志 这几个东西。

如果是对于资金类的业务，后续系统回滚了以后，得想办法去通知前面的系统也进行回滚，或者是发送报警由人工来手工回滚和补偿。

#### 适用场景

这个方案的使用还是比较广，目前国内互联网公司大都是基于这种思路的。

### 最大努力通知（定期校对）

#### 概述

#### 原理

整个流程图如下所示：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE78.tmp.jpg) 

这个方案的大致流程：

1、系统A本地事务执行完之后，发送个消息到MQ

2、这里会有个专门消费MQ的最大努力通知服务，这个服务会消费MQ，然后写入数据库中记录下来，或者是放入个内存队列。接着调用系统B的接口

3、假如系统B执行成功就万事ok了，但是如果系统B执行失败了呢？

那么此时最大努力通知服务就定时尝试重新调用系统B，反复N次，最后还是不行就放弃。

 

最大努力通知也被称为定期校对，其实在方案二中已经包含，这里再单独介绍，主要是为了知识体系的完整性。这种方案也需要消息中间件的参与，其过程如下：

上游系统在完成任务后，向消息中间件同步地发送一条消息，确保消息中间件成功持久化这条消息，然后上游系统可以去做别的事情了；

消息中间件收到消息后负责将该消息同步投递给相应的下游系统，并触发下游系统的任务执行；

当下游系统处理成功后，向消息中间件反馈确认应答，消息中间件便可以将该条消息删除，从而该事务完成。



|      |                                                              |
| ---- | ------------------------------------------------------------ |
|      | ![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE79.tmp.jpg) |

上面是一个理想化的过程，但在实际场景中，往往会出现如下几种意外情况：



消息中间件向下游系统投递消息失败

上游系统向消息中间件发送消息失败

对于第一种情况，消息中间件具有重试机制，我们可以在消息中间件中设置消息的重试次数和重试时间间隔，对于网络不稳定导致的消息投递失败的情况，往往重试几次后消息便可以成功投递，如果超过了重试的上限仍然投递失败，那么消息中间件不再投递该消息，而是记录在失败消息表中，消息中间件需要提供失败消息的查询接口，下游系统会定期查询失败消息，并将其消费，这就是所谓的“定期校对”。

如果重复投递和定期校对都不能解决问题，往往是因为下游系统出现了严重的错误，此时就需要人工干预。

对于第二种情况，需要在上游系统中建立消息重发机制。可以在上游系统建立一张本地消息表，并将 任务处理过程 和 向本地消息表中插入消息 这两个步骤放在一个本地事务中完成。如果向本地消息表插入消息失败，那么就会触发回滚，之前的任务处理结果就会被取消。如果这量步都执行成功，那么该本地事务就完成了。接下来会有一个专门的消息发送者不断地发送本地消息表中的消息，如果发送失败它会返回重试。当然，也要给消息发送者设置重试的上限，一般而言，达到重试上限仍然发送失败，那就意味着消息中间件出现严重的问题，此时也只有人工干预才能解决问题。

对于不支持事务型消息的消息中间件，如果要实现分布式事务的话，就可以采用这种方式。它能够通过重试机制+定期校对实现分布式事务，但相比于第二种方案，它达到数据一致性的周期较长，而且还需要在上游系统中实现消息重试发布机制，以确保消息成功发布给消息中间件，这无疑增加了业务系统的开发成本，使得业务系统不够纯粹，并且这些额外的业务逻辑无疑会占用业务系统的硬件资源，从而影响性能。

因此，尽量选择支持事务型消息的消息中间件来实现分布式事务，如RocketMQ。

 

#### 对比

可靠消息最终一致性方案可以保证的是只要系统A的事务完成，通过不停（无限次）重试来保证系统B的事务总会完成。

但是最大努力方案就不同，如果系统B本地事务执行失败了，那么它会重试N次后就不再重试，系统B的本地事务可能就不会完成了。

至于你想控制它究竟有“多努力”，这个需要结合自己的业务来配置。

比如对于电商系统，在下完订单后发短信通知用户下单成功的业务场景中，下单正常完成，但是到了发短信的这个环节由于短信服务暂时有点问题，导致重试了3次还是失败。

那么此时就不再尝试发送短信，因为在这个场景中我们认为3次就已经算是尽了“最大努力”了。

简单总结：就是在指定的重试次数内，如果能执行成功那么皆大欢喜，如果超过了最大重试次数就放弃，不再进行重试。

 

#### 使用场景

一般用在不太重要的业务操作中，就是那种完成的话是锦上添花，但失败的话对我也没有什么坏影响的场景。

比如上边提到的电商中的部分通知短信，就比较适合使用这种最大努力通知方案来做分布式事务的保证。

 

### Seata方案

https://mp.weixin.qq.com/s/8JPpVCVxB5fuz2F0fcBtwA

https://seata.io/zh-cn/docs/overview/what-is-seata.html

#### 概述

​	Seata是由阿里中间件团队发起的开源项目Fescar，后改名Seata，它是一个开源的分布式事务框架（属于SOFA的一个项目）。

​	传统的2PC的问题在于Seata中得到了解决，它通过对本地关系数据库的分支事务的协调来驱动完成全局事务，是工作在应用层的中间件。主要优点是性能较好，且不长时间占用连接资源，它以高效并且对业务零入侵的方式解决微服务场景下面临的分布式事务问题，它目标***\*提供AT模式（AsyncTransaction即2PC）及TCC模式的分布式事务解决方案\****。

注：AT模式主要从数据分片的角度，关注多DB访问的数据一致性问题，TCC模式主要关注功能扩展，保证多资源访问的数据一致性。

Seata TCC与TCC补偿事务不一样。

 

#### 架构

如下图所示，Seata 中有三大模块，分别是 TM、RM 和 TC。其中 TM 和 RM 是作为 Seata 的客户端与业务系统集成在一起，TC 作为 Seata 的服务端独立部署。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE7A.tmp.jpg) 

在 Seata 中，分布式事务的执行流程：

1、TM 开启分布式事务（TM 向 TC 注册全局事务记录）；

2、按业务场景，编排数据库、服务等事务内资源（RM 向 TC 汇报资源准备状态 ）；

3、TM 结束分布式事务，事务一阶段结束（TM 通知 TC 提交/回滚分布式事务）；

4、TC 汇总事务信息，决定分布式事务是提交还是回滚；

5、TC 通知所有 RM 提交/回滚 资源，事务二阶段结束；

#### 原理

​	***\*Seata设计思想：\****

​	Seata的设计目标其一是对业务无侵入，因此从业务无侵入的2PC方案着手，在传统2PC的基础上演进，并解决2PC方案面临的问题。

​	Seata把一个分布式事务理解成一个包含了若干个分支事务的全局事务。全局事务的职责是协调其下管辖的分支事务达成一致，要么一起成功提交，要么一起失败回滚、此外，通常分支事务本身就是一个关系数据库的本地事务。

​	与传统2PC的模型类似，Seata定义了3个组件来协议分布式事务的处理过程：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE8A.tmp.jpg) 

​	TC（Transaction Coordinator）：事务协调者，它是独立的中间件，需要独立部署运行，它维护全局事务的运行状态，接收TM指令发起全局事务的提交与回滚，负责与RM通信协调各个分布式事务的提交或回滚。注：与XA方案相比，多了一个TC。

​	TM（Transaction Manager）：事务管理器，TM需要嵌入到应用程序中工作，它负责开启一个全局事务，并最终向TC发起全局提交或全局回滚指令。

​	RM（Resource Manager）：控制分支事务，负责分支注册、状态汇报，并接收事务协调器TC的指令，驱动分支（本地）事务的提交和回滚。

具体过程：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE8B.tmp.jpg) 

具体的执行流程如下：

1、用户服务的TM向TC申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的XID。

2、用户服务的RM向TC注册分支事务，该分支事务在用户服务执行新增用户逻辑（事务已提交，锁已经释放，XA方案第一阶段事务未提交），并将其纳入XID对应全局事务的管辖。

3、用户服务执行分支事务，向用户表插入一条记录。

4、逻辑执行到远程调用积分服务时（XID在微服务调用链路的上下文中传播）。积分服务的RM向TC注册分支事务，该分支事务执行增加积分的逻辑，并将其纳入XID对应全局事务的管辖。

5、积分服务执行分支事务，向积分记录表插入一条记录，执行完毕后，返回用户服务。

6、用户服务分支事务执行完毕。

7、TM向TC发起针对XID的全局提交或回滚决议。

8、TC调度XID下管辖的全部分支事务完成提交或回滚请求。

注：GoldenDB采用Seata TCC方式（可理解为一阶段+补偿事务）。

 

2PC与Seata 2PC：

https://blog.csdn.net/linhaibing009/article/details/102728974

https://www.sohu.com/a/336224977_673711

在架构层次方面，传统2PC方案的RM实际上是在数据库层，RM本质上就是数据库本身，通过XA协议实现，而Seata的RM是以jar包的形式作为中间件层部署在应用程序这一侧的。

两阶段提交方面，传统2PC无论第二阶段的决议是commit还是rollback，事务性资源的锁都要保持到phase2完成才释放，而Seata的做法是在phase1就将本地事物提交，这样就省去phase2持锁的时间，整体提高效率。

 

#### 解决方案

Seata会有4种分布式事务解决方案，分别是AT模式、TCC模式、Saga模式和XA模式。

##### AT/2PC

AT 模式是一种***\*无侵入\****的分布式事务解决方案。在AT模式下，用户只需关注自己的“业务SQL”，用户的 “业务 SQL” 作为一阶段，Seata框架会自动生成事务的二阶段提交和回滚操作。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE8C.tmp.jpg) 

AT 模式如何做到对业务的无侵入 ：

***\*一阶段：\****

在一阶段，Seata会拦截“业务SQL”，首先解析SQL语义，找到“业务SQL”要更新的业务数据，在业务数据被更新前，将其保存成“before image”，然后执行“业务SQL”更新业务数据，在业务数据更新之后，再将其保存成“after image”，最后生成行锁。以上操作全部在一个数据库事务内完成，这样保证了一阶段操作的原子性。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE9D.tmp.jpg) 

***\*二阶段提交：\****

二阶段如果是提交的话，因为“业务SQL”在一阶段已经提交至数据库， 所以Seata框架只需将一阶段保存的快照数据和行锁删掉，完成数据清理即可。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE9E.tmp.jpg) 

***\*二阶段回滚：\****

二阶段如果是回滚的话，Seata就需要回滚一阶段已经执行的“业务SQL”，还原业务数据。回滚方式便是用“before image”还原业务数据；但在还原前要首先要校验脏写，对比“数据库当前业务数据”和“after image”，如果两份数据完全一致就说明没有脏写，可以还原业务数据，如果不一致就说明有脏写，出现脏写就需要转人工处理。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDE9F.tmp.jpg) 

AT模式的一阶段、二阶段提交和回滚均由Seata框架自动生成，用户只需编写“业务 SQL”，便能轻松接入分布式事务，AT 模式是一种对业务无任何侵入的分布式事务解决方案。

 

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEB0.tmp.jpg) 

把DB当作RM（resource）。

##### TCC

蚂蚁金服大部分业务系统均采用TCC的方式接入分布式事务，但设计TCC服务时要遵循大量设计规范，这无疑对用户提了非常高的要求；
	为了简化用户接入分布式事务的门槛，蚂蚁金服的分布式事务框架（SOFA-DTX）推出了FMT（Framework-managed transactions）模式和XA模式，这两种模式均不需要用户实现TCC服务，用户只需要关注自身业务SQL便可；
	DTX的三种模式：TCC、FMT和XA相互之间是功能互补，相辅相成的，形成了蚂蚁金服完善的分布式事务解决方案。
	SOFA-DTX全面覆盖金融场景，金融级容灾保障、提供丰富的接入模式并且使用简洁易于接入；目前已经应用在支付宝、网上银行、蚂蚁财富、芝麻信用、南京银行等项目中。

 

2019 年 3 月份，Seata开源了TCC模式，该模式由蚂蚁金服贡献。TCC模式需要用户根据自己的业务场景实现Try、Confirm和Cancel三个操作；事务发起方在一阶段执行Try方式，在二阶段提交执行Confirm方法，二阶段回滚执行Cancel方法。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEB1.tmp.jpg) 

TCC 三个方法描述：

Try：资源的检测和预留；

Confirm：执行的业务操作提交；要求 Try 成功 Confirm 一定要能成功；

Cancel：预留资源释放；

1 TCC 设计 - 业务模型分 2 阶段设计：

用户接入 TCC ，最重要的是考虑如何将自己的业务模型拆成两阶段来实现。以“扣钱”场景为例，在接入 TCC 前，对 A 账户的扣钱，只需一条更新账户余额的 SQL 便能完成；但是在接入 TCC 之后，用户就需要考虑如何将原来一步就能完成的扣钱操作，拆成两阶段，实现成三个方法，并且保证一阶段 Try  成功的话 二阶段 Confirm 一定能成功。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEB2.tmp.jpg)

如上图所示，Try 方法作为一阶段准备方法，需要做资源的检查和预留。在扣钱场景下，Try 要做的事情是就是检查账户余额是否充足，预留转账资金，预留的方式就是冻结 A 账户的 转账资金。Try 方法执行之后，账号 A 余额虽然还是 100，但是其中 30 元已经被冻结了，不能被其他事务使用。二阶段 Confirm 方法执行真正的扣钱操作。Confirm 会使用 Try 阶段冻结的资金，执行账号扣款。Confirm 方法执行之后，账号 A 在一阶段中冻结的 30 元已经被扣除，账号 A 余额变成 70 元 。如果二阶段是回滚的话，就需要在 Cancel 方法内释放一阶段 Try 冻结的 30 元，使账号 A 的回到初始状态，100 元全部可用。用户接入 TCC 模式，最重要的事情就是考虑如何将业务模型拆成 2 阶段，实现成 TCC 的 3 个方法，并且保证 Try 成功 Confirm 一定能成功。相对于 AT 模式，TCC 模式对业务代码有一定的侵入性，但是 TCC 模式无 AT 模式的全局行锁，TCC 性能会比 AT 模式高很多。	2 TCC 设计 - 允许空回滚：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEB3.tmp.jpg) 

Cancel 接口设计时需要允许空回滚。在 Try 接口因为丢包时没有收到，事务管理器会触发回滚，这时会触发 Cancel 接口，这时 Cancel 执行时发现没有对应的事务 xid 或主键时，需要返回回滚成功。让事务服务管理器认为已回滚，否则会不断重试，而 Cancel 又没有对应的业务数据可以进行回滚。

3 TCC 设计 - 防悬挂控制：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEC3.tmp.jpg) 

悬挂的意思是：Cancel 比 Try 接口先执行，出现的原因是 Try 由于网络拥堵而超时，事务管理器生成回滚，触发 Cancel 接口，而最终又收到了 Try 接口调用，但是 Cancel 比 Try 先到。按照前面允许空回滚的逻辑，回滚会返回成功，事务管理器认为事务已回滚成功，则此时的 Try 接口不应该执行，否则会产生数据不一致，所以我们在 Cancel 空回滚返回成功之前先记录该条事务 xid 或业务主键，标识这条记录已经回滚过，Try 接口先检查这条事务xid或业务主键如果已经标记为回滚成功过，则不执行 Try 的业务操作。

4 TCC 设计 - 幂等控制：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEC4.tmp.jpg) 

幂等性的意思是：对同一个系统，使用同样的条件，一次请求和重复的多次请求对系统资源的影响是一致的。因为网络抖动或拥堵可能会超时，事务管理器会对资源进行重试操作，所以很可能一个业务操作会被重复调用，为了不因为重复调用而多次占用资源，需要对服务设计时进行幂等控制，通常我们可以用事务 xid 或业务主键判重来控制。

 

由于传统2PC的弊端较多，性能很差，引入TCC方案：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEC5.tmp.jpg) 

两阶段设计：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDED6.tmp.jpg) 

注：confirm阶段已经真正提交事事务。

##### Saga

Saga 模式是 Seata 即将开源的长事务解决方案，将由蚂蚁金服主要贡献，预计于八月底发布。在 Saga 模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDED7.tmp.jpg) 

Saga 模式下分布式事务通常是由事件驱动的，各个参与者之间是异步执行的，Saga 模式是一种长事务解决方案。

1 Saga 模式使用场景

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDED8.tmp.jpg) 

Saga 模式适用于业务流程长且需要保证事务最终一致性的业务系统，Saga 模式一阶段就会提交本地事务，无锁、长流程情况下可以保证性能。事务参与者可能是其它公司的服务或者是遗留系统的服务，无法进行改造和提供 TCC 要求的接口，可以使用 Saga 模式。

Saga模式的优势是：

一阶段提交本地数据库事务，无锁，高性能；

参与者可以采用事务驱动异步执行，高吞吐；

补偿服务即正向服务的“反向”，易于理解，易于实现；

缺点：Saga 模式由于一阶段已经提交本地数据库事务，且没有进行“预留”动作，所以不能保证隔离性。后续会讲到对于缺乏隔离性的应对措施。

2 基于状态机引擎的 Saga 实现

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDED9.tmp.jpg) 

目前 Saga 的实现一般也两种，一种是通过事件驱动架构实现，一种是基于注解加拦截器拦截业务的正向服务实现。Seata 目前是采用事件驱动的机制来实现的，Seata 实现了一个状态机，可以编排服务的调用流程及正向服务的补偿服务，生成一个 json 文件定义的状态图，状态机引擎驱动到这个图的运行，当发生异常的时候状态机触发回滚，逐个执行补偿服务。当然在什么情况下触发回滚用户是可以自定义决定的。该状态机可以实现服务编排的需求，它支持单项选择、并发、异步、子状态机调用、参数转换、参数映射、服务执行状态判断、异常捕获等功能。

3 状态机引擎原理

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEEA.tmp.jpg) 

该状态机引擎的基本原理是，它基于事件驱动架构，每个步骤都是异步执行的，步骤与步骤之间通过事件队列流转，极大的提高系统吞吐量。每个步骤执行时会记录事务日志，用于出现异常时回滚时使用，事务日志会记录在与业务表所在的数据库内，提高性能。

4 状态机引擎设计

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEEB.tmp.jpg) 

该状态机引擎分成了三层架构的设计，最底层是“事件驱动”层，实现了 EventBus 和消费事件的线程池，是一个 Pub-Sub 的架构。第二层是“流程控制器”层，它实现了一个极简的流程引擎框架，它驱动一个“空”的流程执行，“空”的意思是指它不关心流程节点做什么事情，它只执行每个节点的 process 方法，然后执行 route 方法流转到下一个节点。这是一个通用框架，基于这两层，开发者可以实现任何流程引擎。最上层是“状态机引擎”层，它实现了每种状态节点的“行为”及“路由”逻辑代码，提供 API 和状态图仓库，同时还有一些其它组件，比如表达式语言、逻辑计算器、流水生成器、拦截器、配置管理、事务日志记录等。

5 Saga 服务设计经验

和TCC类似，Saga的正向服务与反向服务也需求遵循以下设计原则：

1）Saga 服务设计 - 允许空补偿

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEEC.tmp.jpg) 

2）Saga 服务设计 - 防悬挂控制

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEED.tmp.jpg) 

3）Saga 服务设计 - 幂等控制

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEFD.tmp.jpg) 

4）Saga 设计 - 自定义事务恢复策略

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEFE.tmp.jpg) 

前面讲到 Saga 模式不保证事务的隔离性，在极端情况下可能出现脏写。比如在分布式事务未提交的情况下，前一个服务的数据被修改了，而后面的服务发生了异常需要进行回滚，可能由于前面服务的数据被修改后无法进行补偿操作。这时的一种处理办法可以是“重试”继续往前完成这个分布式事务。由于整个业务流程是由状态机编排的，即使是事后恢复也可以继续往前重试。所以用户可以根据业务特点配置该流程的事务处理策略是优先“回滚”还是“重试”，当事务超时的时候，Server 端会根据这个策略不断进行重试。

由于 Saga 不保证隔离性，所以我们在业务设计的时候需要做到“宁可长款，不可短款”的原则，长款是指在出现差错的时候站在我方的角度钱多了的情况，钱少了则是短款，因为如果长款可以给客户退款，而短款则可能钱追不回来了，也就是说在业务设计的时候，一定是先扣客户帐再入帐，如果因为隔离性问题造成覆盖更新，也不会出现钱少了的情况。

6 基于注解和拦截器的 Saga 实现

还有一种 Saga 的实现是基于注解+拦截器的实现，Seata 目前没有实现，可以看上面的伪代码来理解一下，one 方法上定义了 @SagaCompensable 的注解，用于定义 one 方法的补偿方法是 compensateOne 方法。然后在业务流程代码 processA 方法上定义 @SagaTransactional 注解，启动 Saga 分布式事务，通过拦截器拦截每个正向方法当出现异常的时候触发回滚操作，调用正向方法的补偿方法。

7 两种 Saga 实现优劣对比两种 Saga 的实现各有缺点，下面表格是一个对比：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDEFF.tmp.jpg) 

状态机引擎的最大优势是可以通过事件驱动的方法异步执行提高系统吞吐，可以实现服务编排需求，在 Saga 模式缺乏隔离性的情况下，可以多一种“向前重试”的事情恢复策略。注解加拦截器的的最大优势是，开发简单、学习成本低。

##### XA

seata 的 XA 模式是利用分支事务中数据库对 XA 协议的支持来实现的。我们看一下 seata 官网的介绍：

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDF00.tmp.jpg) 

从上面的图可以看到，seata XA 模式的流程跟其他模式一样：

1、TM 开启全局事务

2、RM 向 TC 注册分支事务

3、RM 向 TC 报告分支事务状态

4、TC 向 RM 发送 commit/rollback 请求

5、TM 结束全局事务

 

#### 总结

本文先回顾了分布式事务产生的背景及理论基础，然后重点讲解了Seata分布式事务的原理以及三种模式（AT、TCC、Saga）的分布式事务实现。

Seata的定位是分布式事全场景解决方案，未来还会有XA模式的分布式事务实现，每种模式都有它的适用场景：

AT 模式是无侵入的分布式事务解决方案，适用于不希望对业务进行改造的场景，几乎0学习成本。

TCC模式是高性能分布式事务解决方案，适用于核心系统等对性能有很高要求的场景。

Saga模式是长事务解决方案，适用于业务流程长且需要保证事务最终一致性的业务系统，Saga模式一阶段就会提交本地事务，无锁，长流程情况下可以保证性能，多用于渠道层、集成层业务系统。事务参与者可能是其它公司的服务或者是遗留系统的服务，无法进行改造和提供 TCC要求的接口，也可以使用Saga模式。

 

### 共识算法

#### Paxos

#### Raft

# 分布式数据库实践

## TDSQL

分布式事务，就是一个数据库事务在多个数据库实例上面执行，并且多个实例上面都执
行了写入（insert/update/delete）操作。实现分布式事务处理的最大难点，就是在多个数据库实例上面实现统一的数据库事务的ACID保障，而这里面最重要的算法就是两阶段提交算法。分布式事务能力理论虽然很早就被提出，而业内实际工程化实现和大规模业务验证的
产品还较少。 

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDF11.tmp.jpg) 

TDSQL支持分布事务，可以为银行转账、电商交易等业务提供有效支持。当然，分布式事务处理的开销会比单机架构事务处理开销要大一些，使用分布式事务会导致系统TPS降低，事务提交延时增大。而腾讯TDSQL通过多种优化，提供了高于开源XA（分布式事务简称）的性能。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDF12.tmp.jpg) 

由于理论上，一个事务不会操作全部分片，仅操作1~2个分片（如转账业务），再加上TDSQL的MPP架构的原因，因此一个分布式实例多个分片的分布式事务性能可以叠加。

![img](file:///C:\Users\大力\AppData\Local\Temp\ksohtml\wpsDF13.tmp.jpg) 

所以是否使用分布式事务要根据实际应用需求来定。数据量非常大或者数据访问负载非
常高时，分布式事务会大大降低应用开发难度，TDSQL每个事务的查询语句的写法与使用单机架构实例完全相同，且获得事务的ACID保障。对于涉及跨分片的分布式事务，我们建议业务开发时，平衡性能和开发难度的关系，或将事务拆解，巧妙设计或引入一些等待机制，以优化用户体验。 

## OceanBase

## TiDB

## GoldenDB

### 事务控制

引入全局事务管理组件，负责全局事务的管理。

### 并发控制

采用基于锁和快照（分布式MVCC）的方式实现加锁和无锁两种方式的并发控制。

 

***\*高并发：\****

全局事务管理单元GTM高性能机制：多线程批量申请、释放、查询，横向扩展。

注：轻量级设计，计算节点组提交，GTM组合并，多集群部署，单套GTM集群性能260万TPS。

 

***\*高可用：\****

处理过程中GTM失败，该如何处理？

1、每个GTID创建和释放都有持久化日志

2、GTM由一主多备节点构成高可用集群

3、由元数据节点发起主备切换，并通知所有的计算节点

### 一致性检查

***\*一致性检查：\****

可以定期执行脚本检查一致性。